{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FpAFduYWbqjH"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPAsdaASAWXzX0UJE3L/6MQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emirdemic/Learning-TensorFlow/blob/main/TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW4TltI3ZTTk"
      },
      "source": [
        "# **TensorFlow Tutorial**\n",
        "\n",
        "\n",
        "\n",
        "This notebook contains practices and notes from Daniel Bourke's 14 hours long tutorial on TensorFlow 2.0. This notebook is separated into different parts in accordance to how Daniel's video is split. \n",
        "\n",
        "Note that this notebook also contains some trivial theory and/or code, but I've decided to insert that as well since I wanted the notebook to be as representative of the tutorial as possible.\n",
        "\n",
        "If you want to run some chunk of code, please run all the code included in that section.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W__oxrb8cS1_"
      },
      "source": [
        "## Introduction to DL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Adb-jnSaES1"
      },
      "source": [
        "### Deap Learning\n",
        "\n",
        "\n",
        "Deep learning is a type of machine learning based on artificial neural networks in which multiple layers of processing are used to extract progressively higher level features from data. \n",
        "\n",
        "So what is the difference between a traditional programming and machine learning programmings? In a traditional programming, we have some inputs, then we establish some rules in order to get the output. However, in machine learning, we start with inputs and the ideal outputs and then we try to find some rules between inputs and outputs. How do we find those rules? Well, we use machine learning algorithms such as linear regression, logistic regression, SVM, etc. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpAFduYWbqjH"
      },
      "source": [
        "### Why Should We Use Deep learning?\n",
        "\n",
        "For complex problems, thinking about all the rules is nearly impossible. Furthermore, when we take into account that those rule might change in different situations, it becomes impossible to solve some problems using traditional programming paradigms. However, if we can build a simple rule-based system that doesn't require deep learning, then don't use deep learning. If a problem is completely deterministic with a finite set of rules, deep learning is a over-kill or could even underperform in comparison to a traditional programming paradigm. \n",
        "\n",
        "Deep learning is useful when we have problems with long lists of rules, when we are continually chaning environments, or when we want to discover insights within large collections of data.\n",
        "\n",
        "In which situations *deep learning* is typically not that good for? The first one is when we need explainability of our model. Futhermore, deep learning is probably not a best option when the traditional approach is a better option, when errors are unacceptable, or when we don't have much data. \n",
        "<br></br>\n",
        "So, when to use traditional ML algorithms and when to use DL algorithms? Traditional ML algorithms are often the best choice for structured data, while DL algorithms often outperform traditional ML algorithms on unstructured data (pictures, videos, sentences, etc.). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6wFK_L7rWDC"
      },
      "source": [
        "### What are Neural Networks?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PYKDD9-jsfc"
      },
      "source": [
        "A neural network is a network or circuit of neurons, or in a modern sense, an artificial neural network composed of artificial neurons or nodes. \n",
        "<br></br>\n",
        "\n",
        "<div style=\"text-align:center\"><img src=\"https://www.nicepng.com/png/detail/880-8805864_neural-networks-are-a-set-of-algorithms-which.png\" /></div>\n",
        "\n",
        "\n",
        "In the picture above, the first column represent the input data, while the last column represent the output. Everything in between those columns are *hideen layers*. Each node in a hidden layer is an activation of combination of nodes in the previous layer. \n",
        "\n",
        "What does that mean? Let's say that in this example, we have four input variables. All those four input variables are combined in order to get the first node of the first hidden layer, as well as the second, third and fourth node of the first hidden layer.\n",
        "\n",
        "How do we combine nodes from the previous layer? We use a simple linear combination. For example, the linear combination for the first node in the first hidden layer is given by:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "z_{1}^{[1]} = w_{1}^{[1]T}x + b_{1}^{[1]}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $w_{1}^{[1]T}$ is the vector with adequate weights, $x$ are features from the previous layer, and $b_{1}^{[1]}$ is the bias for that node. In this notation, subscripts refer to the specific node, while the superscripts refer to the specific hidden layer. After we get the linear combination, we need to have some kind of *activation function* in order to approximate more complicated function. If we do not apply some activation function, our neural network will always approcimate linear functions regardless of the number of hidden layers.\n",
        "\n",
        "Some popular choices for activation functions are sigmoid function, hyperbolic tangent function, rectified lienar unit (ReLU), and leaky rectified linear unit (LReLU):\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "sigmoid = \\frac{1}{1 + e^{-z}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "<br>\n",
        "$$\n",
        "\\begin{aligned}\n",
        "hyperbolic = \\frac{e^z - e^{-z}}{e^z + e^{-z}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "<br>\n",
        "$$\n",
        "\\begin{aligned}\n",
        "ReLU = max(0, z)\n",
        "\\end{aligned}\n",
        "$$\n",
        "<br>\n",
        "$$\n",
        "\\begin{aligned}\n",
        "LReLU = max(0.01 * z, z)\n",
        "\\end{aligned}\n",
        "$$\n",
        "<br>\n",
        "After we choose a specific activation function, all that we need to do for the specific node of the specific hidden layer is to calculate:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "a_{1}^{[1]} = g(z)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where *g* is the activation function. After that, we do the same calculation for each node of the first hidden layer and we get the activation of the first hidden layer. Now, combinations of activations of the first hidden layers are inputs for the second layer, and so on until we get to the final layer - the output layer.\n",
        "\n",
        "Having that in mind, the first thing that we would be tempted to do is to create a `for loop` in order to calculate the activations of the first hidden layer. However, that would be computationally inefficient since we can combine all nodes of one hidden layer, weights, and biases into a matrix representation which significantly speeds up our process. In this case, the activation of one *whole* hidden layer $l$ is given by:\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "A^{[l]} = g(W^{[l]}A^{l-1} + b^{[l]})\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where superscript $l$ refers to the specific hidden layer, and $A^{l-1}$ are the activations from the previous layer. This means that we have only one computation per one hidden layer, instead of $n$ computations, where $n$ is the number of nodes in a hidden layer. \n",
        "\n",
        "In order to train a neural network, we firstly initiate some random values for $W^{[l]}$ and $b^{[l]}$, and go through the first step of *forward propagation*, until we come to the final output. This means that we will go through the process of calcualting the activation of each hidden layer with some randomly intitiated numbers until we come to the output, i.e. until we produce some numbers as the output. Since (in supervised learning) our data already has the correct output values, we can compare the predictions of our neural network with the correct output values and determine how bad is our neural network. We formalize how bad the neural network is by defining a *loss function* which entirely depends on the nature of the problem. For example, if our output is a binary variable, then we model output with Bernoulli distribution and apply Maximum Likelihood Estimation which gives us:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "L(\\hat{y}, y) = -(ylog\\hat{y} + (1-y)log(1-\\hat{y}))\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Now we have a way to formalize the error of our neural network. Now, in order to improve our neural network, we would apply a *gradient descent algorithm* which changes weights and biases so that the loss function is smaller. The gradient descent algorithm is not that complicated, although it is really elegant. However, I am not going to show it here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2tF-H0muVj2"
      },
      "source": [
        "### What is DL Actually Used For?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-jfcQfouYYQ"
      },
      "source": [
        "Let's take a look at some common deep learning use cases. \n",
        "Some of them are recommendation systems, language translations, computer vision, speech recognition, natural language processing, etc. Language translation and speech recognition are oftern referred to as *sequence to sequence* problems. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxKH1ol7wlZE"
      },
      "source": [
        "## Introduction to TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t4iK2m5wrOo"
      },
      "source": [
        "### What is TensorFlow? What are Tensors?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igzewRtRw8Z4"
      },
      "source": [
        "TensorFlow (TF) is end-to-end platform for machine learning. We can write fast deep learning code in Python and run it on GPU. With TF we are also able to access many pre-built deep learning models. Furthermore, it offers a whole stack: preprocessing data, model data, and deploy the model in your application. In the end, TF was originally designed and used in-house by Google and is now open-source. \n",
        "<br></br>\n",
        "What exactly is a tensor? In mathematics, a tensor is an algebraic object that describes a relationship between sets of algebraic objects related to a vector space. Objects that tensors may map between include vectors and scalars, and even other tensors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ZeSrbo0qT-"
      },
      "source": [
        "A TF workflow typically includes:\n",
        "\n",
        "\n",
        "1.   Getting data ready\n",
        "2.   Building or picking a pretrained model\n",
        "3.   Fitting the model to the data and making predictions\n",
        "4.   Evaluating the model\n",
        "5.   Improving the model through the experimentation\n",
        "6.   Saving and reloading trained models \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJyI4vxC1CRk"
      },
      "source": [
        "## Tensors in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRNzDzru2VTl"
      },
      "source": [
        "In this part, we are going to cover some of the most fundamental concepts of tensors using TensorFlow. \n",
        "\n",
        "More specifically, this part will cover:\n",
        "* Introduction to tensors\n",
        "* Getting information from tensors\n",
        "* Maniuplating tensors\n",
        "* Tensors and NumPy\n",
        "* Using @tf.function\n",
        "* Using GPUs with TensorFlow (or TPUs)\n",
        "* A few exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OExcAoxQ2gdY"
      },
      "source": [
        "### Introduction to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNUS_rEy3QxP",
        "outputId": "6eae24c9-ee22-4224-97b3-bdc7162add54"
      },
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6n-6vr93h93",
        "outputId": "51e0d139-837f-4ed9-d85d-8af49fb8e04b"
      },
      "source": [
        "# Create tensor with tf.constant()\n",
        "scalar = tf.constant(7)\n",
        "print(scalar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(7, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVhscXJo3ykn",
        "outputId": "f35a71fe-ac66-419a-b654-ec81b028da09"
      },
      "source": [
        "# Check the number of dimensions of a tensor\n",
        "print(\"Dimensions of scalar:\\n\", scalar.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensions of scalar:\n",
            " 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyksXL134R-e",
        "outputId": "0a6baeea-1aae-4c82-8edf-c7bb7a41fabb"
      },
      "source": [
        "# Create a vector\n",
        "vector = tf.constant([1, 2, 3, 4, 5])\n",
        "print(\"Vector:\\n\", vector)\n",
        "print(\"\\nDimensions:\\n\", vector.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector:\n",
            " tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n",
            "\n",
            "Dimensions:\n",
            " 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs-f20YG4fQH",
        "outputId": "93e50b11-00d4-4551-f911-a509ac678123"
      },
      "source": [
        "# Create a matrix\n",
        "matrix = tf.constant([\n",
        "                      [1, 2, 3, 4, 5], \n",
        "                      [3, 4, 5, 6, 7]\n",
        "                      ]\n",
        "                     )\n",
        "print(\"Matrix:\\n\", matrix)\n",
        "print(\"\\nDimensions:\\n\", matrix.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix:\n",
            " tf.Tensor(\n",
            "[[1 2 3 4 5]\n",
            " [3 4 5 6 7]], shape=(2, 5), dtype=int32)\n",
            "\n",
            "Dimensions:\n",
            " 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFtNTPYL4zXY",
        "outputId": "0184ccbd-6fa5-4870-8c71-c1d8cb4934b6"
      },
      "source": [
        "# Let's formally use args of tf.constant()\n",
        "matrix1 = tf.constant(value = [[1, 2, 3, 4], [2, 2, 2, 2]], dtype = tf.float16)\n",
        "print(\"Matrix:\\n\", matrix1)\n",
        "print(\"\\nDimensions:\\n\", matrix1.ndim)\n",
        "print(\"\\nType:\\n\", matrix1.dtype)\n",
        "print(\"\\nShape:\\n\", matrix1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix:\n",
            " tf.Tensor(\n",
            "[[1. 2. 3. 4.]\n",
            " [2. 2. 2. 2.]], shape=(2, 4), dtype=float16)\n",
            "\n",
            "Dimensions:\n",
            " 2\n",
            "\n",
            "Type:\n",
            " <dtype: 'float16'>\n",
            "\n",
            "Shape:\n",
            " (2, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjTaG5yK5dJk",
        "outputId": "b261ebb4-6c1c-4b67-b045-4bf84ade0987"
      },
      "source": [
        "tensor = tf.constant([[\n",
        "                       [1, 2, 3], \n",
        "                       [4, 5, 6]], \n",
        "                      [[7, 8, 9], \n",
        "                       [10, 11, 12]],\n",
        "                      [[13, 14, 15], \n",
        "                       [16, 17, 18]]] ,dtype = tf.float16)\n",
        "print(\"Tensor:\\n\", tensor)\n",
        "print(\"\\nDimensions:\\n\", tensor.ndim)\n",
        "print(\"\\nShape:\\n\", tensor.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor:\n",
            " tf.Tensor(\n",
            "[[[ 1.  2.  3.]\n",
            "  [ 4.  5.  6.]]\n",
            "\n",
            " [[ 7.  8.  9.]\n",
            "  [10. 11. 12.]]\n",
            "\n",
            " [[13. 14. 15.]\n",
            "  [16. 17. 18.]]], shape=(3, 2, 3), dtype=float16)\n",
            "\n",
            "Dimensions:\n",
            " 3\n",
            "\n",
            "Shape:\n",
            " (3, 2, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV_H-Eme6Tos"
      },
      "source": [
        "What have we created so far?\n",
        "* Scalar: a single number\n",
        "* Vector: a number with direction\n",
        "* Matrix: a 2-dimensional array of numbers\n",
        "* Tensor: an n-dimensional array of numbers (where $n\\ge 0$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W6brOEW75YQ"
      },
      "source": [
        "### Creating Tensors with tf.Variable()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMJZYWbg7mLu",
        "outputId": "3b2b1816-bbb6-4561-9b9f-9bbda10d2933"
      },
      "source": [
        "# So far, we have created tensors with tf.constant(), but we can do it with tf.Variable() as well\n",
        "# The difference between tf.Variable() and tf.constant() is that tf.Variable() creates a changeable tensor\n",
        "changeable_tensor = tf.Variable([10, 7])\n",
        "unchangeable_tensor = tf.constant([10, 7])\n",
        "print(changeable_tensor)\n",
        "print(unchangeable_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7], dtype=int32)>\n",
            "tf.Tensor([10  7], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n03IcMA_8bVA",
        "outputId": "7d9573c6-29ef-4a39-96b7-d183d0415a17"
      },
      "source": [
        "# Try to change one of the elements in our changeable tensor\n",
        "try:\n",
        "  changeable_tensor[0].assign(99)\n",
        "  print('Changing value was successful')\n",
        "  print(changeable_tensor)\n",
        "except:\n",
        "  print('Changing value was not succesful')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Changing value was successful\n",
            "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([99,  7], dtype=int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzhZncCz8yj-",
        "outputId": "40dc0669-3908-4321-dd28-448babb24655"
      },
      "source": [
        "# Now let's try to change value in unchangeable tensor\n",
        "try:\n",
        "  unchangeable_tensor[0].assign(99)\n",
        "  print('Changing value was successful')\n",
        "  print(unchangeable_tensor)\n",
        "except Exception as e:\n",
        "  print('Changing value was not succesful')\n",
        "  print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Changing value was not succesful\n",
            "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj9eRs8W9Yln"
      },
      "source": [
        "### Creating Random Tensors "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR_CFLtX9CYl"
      },
      "source": [
        "Random tensors are tensors of some arbitrary size which contain random numbers. We need random tensors when initializing weights and biasis in neural networks (or, more generally, in any other machine learning algorithm which requires some beginning random numbers). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZN-0uMV3dvR",
        "outputId": "b344be93-ffef-4c06-9618-40f27aa8955b"
      },
      "source": [
        "# Let's create two random (but same) tensors\n",
        "random1 = tf.random.Generator.from_seed(42) # set seed for reproducibility\n",
        "random1 = random1.normal(shape = (3, 2))\n",
        "print(random1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.7565803  -0.06854702]\n",
            " [ 0.07595026 -1.2573844 ]\n",
            " [-0.23193763 -1.8107855 ]], shape=(3, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjuQkEeW5oox",
        "outputId": "e389a1e2-f2bb-47a4-b38f-4b93a785fe4a"
      },
      "source": [
        "random_2 = tf.random.Generator.from_seed(41)\n",
        "random_2 = random_2.normal(shape = (3, 2))\n",
        "print(random_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.31662667 -1.4391748 ]\n",
            " [ 0.58923835 -1.4268045 ]\n",
            " [-0.7565803  -0.06854702]], shape=(3, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMJeERMJ6GUX",
        "outputId": "a3cd6c2e-f306-4162-f8de-500a1d1c4b9d"
      },
      "source": [
        "# Are they equal?\n",
        "print(random1 == random_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[False False]\n",
            " [False False]\n",
            " [False False]], shape=(3, 2), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfF9zjcs6cKW",
        "outputId": "43f0a185-df9c-4051-d3db-ea4dc7bb595f"
      },
      "source": [
        "# What if we want to shuffle the order of rows?\n",
        "tf.random.set_seed(42) # setting a general? seed\n",
        "print(tf.random.shuffle(random1)) # It doesn't shuffle inplace, you have to assign to a variable\n",
        "print(\"\\n\", random1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.07595026 -1.2573844 ]\n",
            " [-0.23193763 -1.8107855 ]\n",
            " [-0.7565803  -0.06854702]], shape=(3, 2), dtype=float32)\n",
            "\n",
            " tf.Tensor(\n",
            "[[-0.7565803  -0.06854702]\n",
            " [ 0.07595026 -1.2573844 ]\n",
            " [-0.23193763 -1.8107855 ]], shape=(3, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X94BXpnJ6vcu",
        "outputId": "02f4106b-7e25-4603-dc34-6663d6b5e5ff"
      },
      "source": [
        "# Creating a transpose of a tensor\n",
        "print(tf.transpose(random1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.7565803   0.07595026 -0.23193763]\n",
            " [-0.06854702 -1.2573844  -1.8107855 ]], shape=(2, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhYKDTPx_V9i"
      },
      "source": [
        "### Other Ways to Create Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SL5rwbf_c1K",
        "outputId": "e4053a5b-dc3e-42e6-f4cd-87ed00a830a4"
      },
      "source": [
        "np_x = np.random.normal(size = (5, 5))\n",
        "print(np_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.61376625  0.17567101 -0.37463976 -0.57743222 -1.25069587]\n",
            " [-0.76320526  1.50980614 -1.25074362 -0.33863673  0.40279063]\n",
            " [-0.5509734   0.39784563 -1.95222535 -1.28737578 -0.20740423]\n",
            " [-0.56241199  1.31378423  0.91515086  0.07982129  1.28257355]\n",
            " [ 0.58298645  0.82893871  0.04984181 -1.62783812 -1.41289967]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLH34KxX_ic6",
        "outputId": "3effcc26-5be8-496d-bd1c-059a2b16c2dd"
      },
      "source": [
        "tensor_np = tf.convert_to_tensor(np_x)\n",
        "print(tensor_np)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.61376625  0.17567101 -0.37463976 -0.57743222 -1.25069587]\n",
            " [-0.76320526  1.50980614 -1.25074362 -0.33863673  0.40279063]\n",
            " [-0.5509734   0.39784563 -1.95222535 -1.28737578 -0.20740423]\n",
            " [-0.56241199  1.31378423  0.91515086  0.07982129  1.28257355]\n",
            " [ 0.58298645  0.82893871  0.04984181 -1.62783812 -1.41289967]], shape=(5, 5), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXJnhJnrB0rz"
      },
      "source": [
        "> But you can also just input NumPy array into tf.constant() or tf.Variable()!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq9VBGZv_z9i",
        "outputId": "873b21d7-1e89-44cd-8772-be5ed1802cf4"
      },
      "source": [
        "ones = tf.ones(shape = (7, 6), dtype = tf.int32)\n",
        "zeros = tf.zeros(shape = (3, 3), dtype = tf.int16)\n",
        "print(\"Tensor of ones:\\n\", ones)\n",
        "print(\"\\nTensor of zeros:\\n\", zeros)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor of ones:\n",
            " tf.Tensor(\n",
            "[[1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]], shape=(7, 6), dtype=int32)\n",
            "\n",
            "Tensor of zeros:\n",
            " tf.Tensor(\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]], shape=(3, 3), dtype=int16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdBGqgy9AqW9"
      },
      "source": [
        "> The main difference between NumPy arrays and TensorFlow tensors is that tensors can be run on a GPU (much faster for numerical computing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dZk7avkBKF3"
      },
      "source": [
        "### Getting Information from Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeKrt_1BDOJv"
      },
      "source": [
        "The most frequently used information from tensors are:\n",
        "* shape\n",
        "* rank (n of dimensinos)\n",
        "* axis or dimension\n",
        "* size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnRqr_1iEQIF"
      },
      "source": [
        "tensor_A = tf.constant([\n",
        "                        [1, 2, 3, 4],\n",
        "                        [3, 2, 2, 2],\n",
        "                        [3, 2, 1, 3],\n",
        "                        [5, 4, 3, 2]\n",
        "                        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "difCmsx5EYm0",
        "outputId": "ce79fbf1-21a0-4faa-e19c-d033d5a20c9c"
      },
      "source": [
        "print('Shape of tensor:', tensor_A.shape)\n",
        "print('Rank of tensor:', tensor_A.ndim)\n",
        "print('Size of tensor:', tf.size(tensor_A))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of tensor: (4, 4)\n",
            "Rank of tensor: 2\n",
            "Size of tensor: tf.Tensor(16, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC7kJCY9ElOE",
        "outputId": "ab441cdc-9c4d-4c7d-d840-130fb13d387d"
      },
      "source": [
        "print('The first column:')\n",
        "print(tensor_A[:, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The first column:\n",
            "tf.Tensor([1 3 3 5], shape=(4,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pvSu0XpFVBc",
        "outputId": "ccc59c24-43b4-4ba4-b133-217a0ce60553"
      },
      "source": [
        "# Get various attributes of our tensor\n",
        "print(\"Datatype of every element:\", tensor_A.dtype)\n",
        "print(\"Number of dimensions:\", tensor_A.ndim)\n",
        "print(\"The size of tensor:\", tf.size(tensor_A))\n",
        "print(\"The shape of tensor:\", tensor_A.shape)\n",
        "print(\"Elements along 0 axis:\", tensor_A.shape[0])\n",
        "print(\"Elements along 1 axis:\", tensor_A.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datatype of every element: <dtype: 'int32'>\n",
            "Number of dimensions: 2\n",
            "The size of tensor: tf.Tensor(16, shape=(), dtype=int32)\n",
            "The shape of tensor: (4, 4)\n",
            "Elements along 0 axis: 4\n",
            "Elements along 1 axis: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buPnfGknMuNE"
      },
      "source": [
        "### Indexing Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJlraNG9MLQB"
      },
      "source": [
        "> Tensors can be indexed just like NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyLoeH3b-Lhy",
        "outputId": "b07e14c3-eb1c-4ae9-d137-2646cafdd585"
      },
      "source": [
        "# Get the first 2 elements of each dimension\n",
        "print(tensor_A[:2, :2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 2]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV61vpDK-V1q",
        "outputId": "5eb4d2cf-5210-4327-e4c0-336a31ef49e1"
      },
      "source": [
        "# Get the first element from each dimencion from each index except for the final one\n",
        "print(tensor_A[:1, :])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[1 2 3 4]], shape=(1, 4), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCQm5tH6-zQB",
        "outputId": "6bbf1b64-e47a-433b-8fa8-5b2de251a780"
      },
      "source": [
        "# Let's create a rank 2 tensor (2 dimensions)\n",
        "rank_2_tensor = tf.constant(np.random.normal(size = (3, 4)))\n",
        "print(rank_2_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 1.1199121  -0.77232915 -0.00597473 -0.02029698]\n",
            " [-0.64639537 -0.43004214  2.32853803 -0.65769914]\n",
            " [ 0.59995455  0.79706359  0.51199312  0.26268593]], shape=(3, 4), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnEueHSe_9la",
        "outputId": "8aaffa34-83cd-407e-ede3-77cda10fc5bf"
      },
      "source": [
        "# Get the last item of each row of our tensor\n",
        "print(rank_2_tensor[:, -1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([-0.02029698 -0.65769914  0.26268593], shape=(3,), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SXpHQGtAJHT",
        "outputId": "91de6233-16ec-4e18-90dd-f664a4b1f956"
      },
      "source": [
        "# Add in extra dimension to our rank 2 tensor\n",
        "rank_3_tensor = rank_2_tensor[..., tf.newaxis] # three dots mean include all other axes\n",
        "print(rank_3_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 1.1199121 ]\n",
            "  [-0.77232915]\n",
            "  [-0.00597473]\n",
            "  [-0.02029698]]\n",
            "\n",
            " [[-0.64639537]\n",
            "  [-0.43004214]\n",
            "  [ 2.32853803]\n",
            "  [-0.65769914]]\n",
            "\n",
            " [[ 0.59995455]\n",
            "  [ 0.79706359]\n",
            "  [ 0.51199312]\n",
            "  [ 0.26268593]]], shape=(3, 4, 1), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khbfM-ZlJuAB",
        "outputId": "3f683fe9-7b6a-4c2b-95c8-5cc5030c9750"
      },
      "source": [
        "# Alternative to tf.newaxis\n",
        "tf.expand_dims(rank_2_tensor, axis = - 1) # expand on final axis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4, 1), dtype=float64, numpy=\n",
              "array([[[ 1.1199121 ],\n",
              "        [-0.77232915],\n",
              "        [-0.00597473],\n",
              "        [-0.02029698]],\n",
              "\n",
              "       [[-0.64639537],\n",
              "        [-0.43004214],\n",
              "        [ 2.32853803],\n",
              "        [-0.65769914]],\n",
              "\n",
              "       [[ 0.59995455],\n",
              "        [ 0.79706359],\n",
              "        [ 0.51199312],\n",
              "        [ 0.26268593]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iaJox-LKHsX",
        "outputId": "408a7287-477a-4d05-a328-d14043d2ddf5"
      },
      "source": [
        "tf.expand_dims(rank_2_tensor, axis = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3, 4), dtype=float64, numpy=\n",
              "array([[[ 1.1199121 , -0.77232915, -0.00597473, -0.02029698],\n",
              "        [-0.64639537, -0.43004214,  2.32853803, -0.65769914],\n",
              "        [ 0.59995455,  0.79706359,  0.51199312,  0.26268593]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-bvO3TvKU1Z"
      },
      "source": [
        "Note that the numbers always stay the same, but the shape of a tensor is changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56icp9QuKk09"
      },
      "source": [
        "### Tensor Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wWPResf5vle"
      },
      "source": [
        "**Basic Operations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqNiN_tF52jc",
        "outputId": "9a2e6086-54bb-4a5d-88cf-b41aa1369ca3"
      },
      "source": [
        "# We can add values to a tensor using the addition operators\n",
        "tensor = tf.constant(np.arange(10), shape = (2, 5))\n",
        "print(tensor)\n",
        "print('Addition')\n",
        "print(tensor + 10) # the original tensor is not changed, we didn't assign the values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0 1 2 3 4]\n",
            " [5 6 7 8 9]], shape=(2, 5), dtype=int64)\n",
            "Addition\n",
            "tf.Tensor(\n",
            "[[10 11 12 13 14]\n",
            " [15 16 17 18 19]], shape=(2, 5), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPHfM-KN6ABt",
        "outputId": "3a78eb75-9579-47b4-8d7d-f76999800127"
      },
      "source": [
        "# Multiplication\n",
        "print(tensor * 7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  7 14 21 28]\n",
            " [35 42 49 56 63]], shape=(2, 5), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAGXrFgN6Tf0",
        "outputId": "8e4530e1-ac7d-459c-e2e6-312dfb8fe5b2"
      },
      "source": [
        "# Substraction\n",
        "print(tensor - 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-5 -4 -3 -2 -1]\n",
            " [ 0  1  2  3  4]], shape=(2, 5), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdjDUy2N6XAF",
        "outputId": "bc3df3cc-a60d-4b06-80b7-47b673170110"
      },
      "source": [
        "# We can also use TensorFlow functions for addition, substraction, division and multiplication (like in NumPy)\n",
        "print('Multiplication')\n",
        "print(tf.multiply(tensor, 5))\n",
        "print('Addition')\n",
        "print(tf.add(tensor, 10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multiplication\n",
            "tf.Tensor(\n",
            "[[ 0  5 10 15 20]\n",
            " [25 30 35 40 45]], shape=(2, 5), dtype=int64)\n",
            "Addition\n",
            "tf.Tensor(\n",
            "[[10 11 12 13 14]\n",
            " [15 16 17 18 19]], shape=(2, 5), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krxZ8dQM6fsF"
      },
      "source": [
        "**Matrix Multiplication**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaGJ0xv7688j",
        "outputId": "9a78c570-42cc-4326-ab20-b6ca8a5c857e"
      },
      "source": [
        "# Matrix multiplication\n",
        "A = tf.constant([[3, 2, 2], [3, 1, 7]])\n",
        "B = tf.constant([[1, 2], [3, 3], [4, 5]])\n",
        "print(tf.linalg.matmul(A, B))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[17 22]\n",
            " [34 44]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUt2z_XC7esc"
      },
      "source": [
        "As a quick reminder, in order to multiply matrices, the first matrix should be \n",
        "$A^{m_{*}n}$, while the second should be $B^{n_{*}p}$. The resulting matrix is then of shape $m*p$.\n",
        "\n",
        "There are multiple ways to multiply matrices. One of them is to use dot product of rows of first matrix and columns of the second matrix. In other words, for matrices $A \\in {\\rm I\\!R}^{m*n}, B \\in {\\rm I\\!R}^{n*p}$, the elements $c_{ij}$ of the product $ C=AB \\in  {\\rm I\\!R}^{m*p}$ are computed as:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "c_{ij} = \\sum_{l = 1}^{n}a_{il}b_{lj}\\\\\n",
        "i = 1, ..., m\\\\ \n",
        "j = 1, ..., k\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrY5mR1P9wwh",
        "outputId": "886e7a4e-d547-4038-b2a7-dd84f23dad9c"
      },
      "source": [
        "# Python has operator @ for matrix multiplication, but it is slower\n",
        "print(A@B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[17 22]\n",
            " [34 44]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iXPgHxq91Hi"
      },
      "source": [
        "Let's find a inverse of a matrix. Remember that only square matrices can have regular inverses, but not all of them will actually have it. Rectangular matrices (more frequent than square matrices in practice) have pseudo-inverse. \n",
        "First of all, let's define the regular inverse of a matrix:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "AA^{-1} = I\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "In other words, the matrix multiplied by its inverse gives us the identity matrix, i.e. we are back to the beginning. In other words, if we multiply some vector with a matrix, and then multiply it with the matrix inverse, we get to the starting point. The inverse of a matrix can be found using different algorithms, but the most simple one is Gaussian elimination.\n",
        "\n",
        "Now, as we have said, rectangular matrices do not have regular inverse. For them, we often use *Moore-Penrose pseudo-inverse*, which is $(A^{T}A)^{-1}A^{T}$. How do we get that? Well, let's consider a linear equation given by $Ax = b$. We get to the pseudo-inverse by doing a bit of algebra:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "Ax = b \\iff A^{T}Ax = A^{T}b \\iff x = (A^{T}A)^{-1}A^{T}b\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This equation is actually used to get the optimal parameters for linear regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n36WS0gCLb9",
        "outputId": "158405ee-bc90-4203-8afb-59ae96793daa"
      },
      "source": [
        "A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[3, 2, 2],\n",
              "       [3, 1, 7]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1Idr-XI_hug",
        "outputId": "c32cfcd2-24f4-4c4f-bbb1-05bd4f8986c4"
      },
      "source": [
        "# Finding the inverse of a matrix\n",
        "# You must have float32 or float64 dtypes, cannot be calculated on int dtypes\n",
        "A = tf.constant([\n",
        "                 [1, 0, 2, 0], \n",
        "                 [1, 1, 0, 0],\n",
        "                 [1, 2, 0, 1],\n",
        "                 [1, 1, 1, 1]\n",
        "                 ], \n",
        "                dtype = tf.float32\n",
        "                )\n",
        "\n",
        "print(tf.linalg.inv(A))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-1.  2. -2.  2.]\n",
            " [ 1. -1.  2. -2.]\n",
            " [ 1. -1.  1. -1.]\n",
            " [-1.  0. -1.  2.]], shape=(4, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_0QZdozCHnu",
        "outputId": "b0bdda4e-10dc-47c7-a975-a47afa86b57d"
      },
      "source": [
        "# Now let's get pseudo-inverse with the tf.linalg.pinv() functino\n",
        "A = tf.constant([\n",
        "                 [1, 0, 1, 2],\n",
        "                 [1, 1, 0, 0],\n",
        "                 [1, 2, 0, 1]\n",
        "                 ],\n",
        "                dtype = tf.float64)\n",
        "\n",
        "print(tf.linalg.pinv(A))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.25        1.25       -0.58333333]\n",
            " [-0.25       -0.25        0.58333333]\n",
            " [ 0.25        0.25       -0.25      ]\n",
            " [ 0.25       -0.75        0.41666667]], shape=(4, 3), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-PqrLOGDXht"
      },
      "source": [
        "In a nutshell, we can perform matrix multiplication using:\n",
        "\n",
        "\n",
        "*   `tf.matmul()`\n",
        "*   `tf.tensordot()`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmyq8FXcgxoO"
      },
      "source": [
        "### Changing the Datatype of a Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDM8IJ6mE_nK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d7f8d1-f258-4997-b1c1-ad0ef62f77af"
      },
      "source": [
        "B = tf.constant([1, 3]) # if we populate the function with integers, dtype will be int32\n",
        "print(B.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<dtype: 'int32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLwbAeuAg3jZ",
        "outputId": "102092c3-4fc1-4671-b74b-7beeb813d8be"
      },
      "source": [
        "# Let's change it to int16 (reduced precision)\n",
        "B = tf.cast(B, dtype = tf.int16)\n",
        "print(B.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<dtype: 'int16'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCHuT4hOhm1M",
        "outputId": "5474689d-0d55-4eb0-a507-ed94867928d8"
      },
      "source": [
        "# Change from int16 to float32\n",
        "B = tf.cast(B, dtype = tf.float32)\n",
        "print(B.numpy(), B.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 3.] <dtype: 'float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBbCnp4oiOkU"
      },
      "source": [
        "### Aggregating Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KrevdBsjOtj"
      },
      "source": [
        "Aggregating tensors means condensing them from multiple values down to a smaller amount of values.\n",
        "\n",
        "*   Get the minimum\n",
        "*   Get the maximum\n",
        "*   Get the mean\n",
        "*   Get the sum\n",
        "*   Get the variance\n",
        "*   Get the standard deviation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNc5Eembh-9t",
        "outputId": "ab47cbfa-9d1a-4914-8c27-21b8f8469542"
      },
      "source": [
        "# Get the absolute values\n",
        "D = tf.constant([-7, -10, -3], dtype = tf.float16)\n",
        "print(tf.abs(D))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 7. 10.  3.], shape=(3,), dtype=float16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpQgnME_jhLp",
        "outputId": "5833734d-071e-4731-a302-f4c7c1566868"
      },
      "source": [
        "# Aggregation measures\n",
        "# TF puts reduce_ before the actual agg measure\n",
        "D = tf.constant(np.random.normal(size = (10, 30)))\n",
        "print('Minimum value:', tf.reduce_min(D, axis = 1))\n",
        "print('\\mMaximum value:', tf.reduce_max(D, axis = 1))\n",
        "print('\\mMean value:', tf.reduce_mean(D, axis = 1))\n",
        "print('\\mSum:', tf.reduce_sum(D, axis = 1))\n",
        "print('\\nStandard deviation:', tf.math.reduce_std(D, axis = 1))\n",
        "print('\\nVariance:', tf.math.reduce_variance(D, axis = 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum value: tf.Tensor(\n",
            "[-2.17696675 -2.47799107 -1.89561998 -2.64350557 -2.39673651 -2.53152494\n",
            " -2.87685239 -2.35533785 -1.82363282 -2.83924328], shape=(10,), dtype=float64)\n",
            "\\mMaximum value: tf.Tensor(\n",
            "[1.97744048 1.62590541 1.68575292 2.30097726 2.13002513 1.70544056\n",
            " 2.89826085 2.22187413 2.43368277 2.65404179], shape=(10,), dtype=float64)\n",
            "\\mMean value: tf.Tensor(\n",
            "[ 0.06484969 -0.20251058 -0.14801486 -0.12010113 -0.01909641  0.2058323\n",
            " -0.08053196 -0.10432362  0.02662925  0.0316522 ], shape=(10,), dtype=float64)\n",
            "\\mSum: tf.Tensor(\n",
            "[ 1.94549081 -6.07531731 -4.44044589 -3.60303376 -0.57289234  6.17496896\n",
            " -2.41595869 -3.12970873  0.79887754  0.94956612], shape=(10,), dtype=float64)\n",
            "\n",
            "Standard deviation: tf.Tensor(\n",
            "[0.96806799 0.94715972 0.93983136 1.18008852 1.12927685 0.93201016\n",
            " 1.1897983  1.05433726 0.95927192 1.34017171], shape=(10,), dtype=float64)\n",
            "\n",
            "Variance: tf.Tensor(\n",
            "[0.93715562 0.89711153 0.88328298 1.39260891 1.27526619 0.86864293\n",
            " 1.41562    1.11162705 0.92020261 1.79606021], shape=(10,), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJJFnisCmJcL"
      },
      "source": [
        "### Indices of Minimum and Maximum; Squeezing a Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEQBU2u6kCLz",
        "outputId": "0c996256-4781-442b-e893-703378af0a12"
      },
      "source": [
        "x = tf.constant([3, 2, 1, 5, 4, 2], dtype = tf.float16)\n",
        "print ('Index of minimum:', tf.argmin(x))\n",
        "print('The minimum value:', x[tf.argmin(x)])\n",
        "print('\\nIndex of maximum:', tf.argmax(x))\n",
        "print('The maximum value:', x[tf.argmax(x)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index of minimum: tf.Tensor(2, shape=(), dtype=int64)\n",
            "The minimum value: tf.Tensor(1.0, shape=(), dtype=float16)\n",
            "\n",
            "Index of maximum: tf.Tensor(3, shape=(), dtype=int64)\n",
            "The maximum value: tf.Tensor(5.0, shape=(), dtype=float16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyO-ujFen4qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1147daca-f46b-4735-f8df-bb9e70128e91"
      },
      "source": [
        "# Squeezing a tensor - removes dimensions of size 1 from tensor!\n",
        "x = tf.constant([3, 2, 1, 4, 2, 1], shape = (6, 1, 1, 1, 1))\n",
        "print(x.ndim)\n",
        "print(tf.squeeze(x))\n",
        "print(tf.squeeze(x).ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "tf.Tensor([3 2 1 4 2 1], shape=(6,), dtype=int32)\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQwByCs3reSI"
      },
      "source": [
        "### One-Hot Encoding with Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn82XQitq4YT",
        "outputId": "f7c047c4-96c0-4096-f33b-35cab3fb9f8d"
      },
      "source": [
        "# We need to define indices of values which will take values of 1 in each row\n",
        "some_list = [0, 1, 2, 1, 3, 2, 3, 0] \n",
        "tf.one_hot(some_list, depth = 4) # depth is the number of unique values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8, 4), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3BaIG9isNHa",
        "outputId": "6b37b46c-c081-4564-ed60-e52ee20abe41"
      },
      "source": [
        "# Specify custom values for one hot encoding, but you'll rarely use this\n",
        "tf.one_hot(some_list, depth = 4, on_value = 'huehue', off_value = 'auau')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8, 4), dtype=string, numpy=\n",
              "array([[b'huehue', b'auau', b'auau', b'auau'],\n",
              "       [b'auau', b'huehue', b'auau', b'auau'],\n",
              "       [b'auau', b'auau', b'huehue', b'auau'],\n",
              "       [b'auau', b'huehue', b'auau', b'auau'],\n",
              "       [b'auau', b'auau', b'auau', b'huehue'],\n",
              "       [b'auau', b'auau', b'huehue', b'auau'],\n",
              "       [b'auau', b'auau', b'auau', b'huehue'],\n",
              "       [b'huehue', b'auau', b'auau', b'auau']], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1ZvLqBCtBQk"
      },
      "source": [
        "### Square, log, Square Root"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAq6EbxysgEB",
        "outputId": "c8f0bfc3-c659-4526-a237-36ac290dae24"
      },
      "source": [
        "h = tf.range(1, 10, dtype = tf.float32)\n",
        "print(h)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1. 2. 3. 4. 5. 6. 7. 8. 9.], shape=(9,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkbGtAVOtIOA",
        "outputId": "7e58a9f2-c397-44ad-bd35-9118db2f7313"
      },
      "source": [
        "print('Squared:', tf.square(h))\n",
        "print('\\nSquare root:', tf.math.sqrt(h))\n",
        "print('\\nLog:', tf.math.log(h))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Squared: tf.Tensor([ 1.  4.  9. 16. 25. 36. 49. 64. 81.], shape=(9,), dtype=float32)\n",
            "\n",
            "Square root: tf.Tensor(\n",
            "[0.99999994 1.4142134  1.7320508  1.9999999  2.236068   2.4494896\n",
            " 2.6457512  2.8284268  3.        ], shape=(9,), dtype=float32)\n",
            "\n",
            "Log: tf.Tensor(\n",
            "[0.        0.6931472 1.0986123 1.3862944 1.609438  1.7917595 1.9459102\n",
            " 2.0794415 2.1972246], shape=(9,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFDHBCWzt9kJ"
      },
      "source": [
        "### Tensors and NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At8uYDSNuFPf"
      },
      "source": [
        "> TensorFlow interacts beautifully and naturally with NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DTlyWYLtL83",
        "outputId": "b5cf6541-91d8-4850-dd8a-3b81af71246c"
      },
      "source": [
        "# Create a tensor directly from a NumPy array\n",
        "print(tf.constant(np.arange(12, dtype = np.float32)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.], shape=(12,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K33HezwTuMXP",
        "outputId": "84b6a8a1-d558-4606-ce36-e1f41790c42a"
      },
      "source": [
        "# Convert a tensor into a NumPy array\n",
        "x = tf.constant([1, 3, 2])\n",
        "x.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCQc_cEWvTVe"
      },
      "source": [
        "---------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bp4lmLTvVZZ"
      },
      "source": [
        "## Neural Networks for Regression Problems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzwXgUtIwK9A"
      },
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF0OLx-2crO_"
      },
      "source": [
        "x = np.random.normal(size = 15)\n",
        "y = 0.56*x + 3.85 + np.random.normal(size = 15, scale = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NF-Jab7tcyMi",
        "outputId": "f84901bb-07b5-4434-9703-e9607b11ece0"
      },
      "source": [
        "plt.scatter(x, y);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcb_V7MBc7BA",
        "outputId": "526b9fdd-4938-4180-d2d5-66723ad812c1"
      },
      "source": [
        "# Let's take a look at input and output shapes\n",
        "print('Shape of x:', np.shape(x))\n",
        "print('Shape of y:', np.shape(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x: (15,)\n",
            "Shape of y: (15,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezAASEvVfYDc",
        "outputId": "dd7b9b57-f706-438a-d1c7-fe61357953d6"
      },
      "source": [
        "x = tf.constant(x)\n",
        "y = tf.constant(y)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15,), dtype=float64, numpy=\n",
              "array([ 1.17301847, -0.42344108, -1.31660825,  0.92662454, -1.68854425,\n",
              "       -0.36206493, -1.10371814,  1.88256795, -1.49147019,  1.76330934,\n",
              "       -0.87385565, -0.14716105, -0.18162683, -0.3598732 ,  1.86973568])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H340jvJNg2Bj"
      },
      "source": [
        "### Steps in Modelling with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZpDQBQ0giCB"
      },
      "source": [
        "We have a few steps in modelling the relationship between input and output variables. The steps are:\n",
        "\n",
        "\n",
        "1.   Create a model - define the input, hidden, and output layers\n",
        "2.   Compile a model - define the loss function, the optimizer, and evaluation metric\n",
        "3.   Fitting a model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5v2dTLWgosJ",
        "outputId": "9f3a0b26-293a-4691-b374-04e4a20c597c"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the sequential API\n",
        "model = tf.keras.Sequential(\n",
        "    layers = [tf.keras.layers.Dense(1)]  # the output layer, outputs one number\n",
        "    )\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.mse, \n",
        "    optimizer = tf.keras.optimizers.SGD(), \n",
        "    metrics = ['mse']\n",
        "    )\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(x, y, epochs = 10) # ten runs through the dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 13.9868 - mse: 13.9868\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.4366 - mse: 13.4366\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.9083 - mse: 12.9083\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.4010 - mse: 12.4010\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.9138 - mse: 11.9138\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.4460 - mse: 11.4460\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9968 - mse: 10.9968\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.5655 - mse: 10.5655\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.1513 - mse: 10.1513\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7535 - mse: 9.7535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f559b6f6d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt7bk9HIuHSz",
        "outputId": "31b83a30-209f-4143-c99c-8d2728e6b836"
      },
      "source": [
        "model.predict(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f559b66acb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.3056273 ],\n",
              "       [ 0.45499268],\n",
              "       [-0.02090973],\n",
              "       [ 1.1743424 ],\n",
              "       [-0.21908683],\n",
              "       [ 0.4876955 ],\n",
              "       [ 0.09252357],\n",
              "       [ 1.6836936 ],\n",
              "       [-0.11408067],\n",
              "       [ 1.6201496 ],\n",
              "       [ 0.21500021],\n",
              "       [ 0.6022018 ],\n",
              "       [ 0.5838375 ],\n",
              "       [ 0.4888633 ],\n",
              "       [ 1.6768563 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkquIZb020dn"
      },
      "source": [
        "### Improving the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1lZ5i-L5mux"
      },
      "source": [
        "The previous model was not that good - predictions were significantly off. However, we can improve the model by adding new hidden layers, apply different activation functions, increasing the number of epochs, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf_cUqgq3FbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4f24cd-af42-4bf1-8c05-54c2694adcfc"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(100, activation = 'relu')) # First hidden layes has 100 neurons\n",
        "model.add(tf.keras.layers.Dense(50, activation = 'relu')) # The second hidden layer has 50 neurons\n",
        "model.add(tf.keras.layers.Dense(50, activation = 'relu')) # The third hidden layer has 30 neurons\n",
        "model.add(tf.keras.layers.Dense(1)) # default activation is linear activation\n",
        "\n",
        "# adam optimizer; you can experiment with learning rate as well\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'mse', metrics = ['mse', 'mae']) \n",
        "\n",
        "model.fit(x, y, epochs = 1000) # 1000 epochs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 1s 612ms/step - loss: 14.0184 - mse: 14.0184 - mae: 3.6909\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.7477 - mse: 13.7477 - mae: 3.6520\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.4972 - mse: 13.4972 - mae: 3.6159\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.2579 - mse: 13.2579 - mae: 3.5807\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.0226 - mse: 13.0226 - mae: 3.5457\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.7876 - mse: 12.7876 - mae: 3.5108\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.5538 - mse: 12.5538 - mae: 3.4756\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.3221 - mse: 12.3221 - mae: 3.4403\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.0872 - mse: 12.0872 - mae: 3.4040\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.8532 - mse: 11.8532 - mae: 3.3675\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.6172 - mse: 11.6172 - mae: 3.3304\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.3763 - mse: 11.3763 - mae: 3.2921\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.1261 - mse: 11.1261 - mae: 3.2519\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.8686 - mse: 10.8686 - mae: 3.2102\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.6083 - mse: 10.6083 - mae: 3.1675\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.3381 - mse: 10.3381 - mae: 3.1225\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.0574 - mse: 10.0574 - mae: 3.0751\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.7651 - mse: 9.7651 - mae: 3.0245\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4636 - mse: 9.4636 - mae: 2.9712\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1527 - mse: 9.1527 - mae: 2.9149\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8277 - mse: 8.8277 - mae: 2.8549\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.4928 - mse: 8.4928 - mae: 2.7914\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.1460 - mse: 8.1460 - mae: 2.7236\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7907 - mse: 7.7907 - mae: 2.6517\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4285 - mse: 7.4285 - mae: 2.5757\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0583 - mse: 7.0583 - mae: 2.4950\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6821 - mse: 6.6821 - mae: 2.4094\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.2985 - mse: 6.2985 - mae: 2.3181\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9134 - mse: 5.9134 - mae: 2.2215\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5298 - mse: 5.5298 - mae: 2.1186\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.1532 - mse: 5.1532 - mae: 2.0274\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.7867 - mse: 4.7867 - mae: 1.9487\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.4330 - mse: 4.4330 - mae: 1.8776\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0977 - mse: 4.0977 - mae: 1.8035\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.7845 - mse: 3.7845 - mae: 1.7264\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4974 - mse: 3.4974 - mae: 1.6467\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.2407 - mse: 3.2407 - mae: 1.5738\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0171 - mse: 3.0171 - mae: 1.5118\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8293 - mse: 2.8293 - mae: 1.4480\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6791 - mse: 2.6791 - mae: 1.3831\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5661 - mse: 2.5661 - mae: 1.3175\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4874 - mse: 2.4874 - mae: 1.2922\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4387 - mse: 2.4387 - mae: 1.2915\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4135 - mse: 2.4135 - mae: 1.2884\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4043 - mse: 2.4043 - mae: 1.3090\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4018 - mse: 2.4018 - mae: 1.3289\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4002 - mse: 2.4002 - mae: 1.3421\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3911 - mse: 2.3911 - mae: 1.3476\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3706 - mse: 2.3706 - mae: 1.3459\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3362 - mse: 2.3362 - mae: 1.3374\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2891 - mse: 2.2891 - mae: 1.3226\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.2342 - mse: 2.2342 - mae: 1.3087\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1723 - mse: 2.1723 - mae: 1.2901\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.1052 - mse: 2.1052 - mae: 1.2666\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0359 - mse: 2.0359 - mae: 1.2396\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9654 - mse: 1.9654 - mae: 1.2154\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8957 - mse: 1.8957 - mae: 1.1890\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8294 - mse: 1.8294 - mae: 1.1638\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7710 - mse: 1.7710 - mae: 1.1414\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7183 - mse: 1.7183 - mae: 1.1239\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6701 - mse: 1.6701 - mae: 1.1089\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6257 - mse: 1.6257 - mae: 1.0936\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5852 - mse: 1.5852 - mae: 1.0782\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5474 - mse: 1.5474 - mae: 1.0630\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5115 - mse: 1.5115 - mae: 1.0479\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4765 - mse: 1.4765 - mae: 1.0333\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4417 - mse: 1.4417 - mae: 1.0189\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4065 - mse: 1.4065 - mae: 1.0046\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3704 - mse: 1.3704 - mae: 0.9904\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3333 - mse: 1.3333 - mae: 0.9760\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2951 - mse: 1.2951 - mae: 0.9614\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2565 - mse: 1.2565 - mae: 0.9468\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2175 - mse: 1.2175 - mae: 0.9321\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1787 - mse: 1.1787 - mae: 0.9174\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1403 - mse: 1.1403 - mae: 0.9025\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1030 - mse: 1.1030 - mae: 0.8877\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0670 - mse: 1.0670 - mae: 0.8730\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0324 - mse: 1.0324 - mae: 0.8583\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9988 - mse: 0.9988 - mae: 0.8434\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9665 - mse: 0.9665 - mae: 0.8284\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9353 - mse: 0.9353 - mae: 0.8135\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9052 - mse: 0.9052 - mae: 0.7984\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8759 - mse: 0.8759 - mae: 0.7834\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8470 - mse: 0.8470 - mae: 0.7684\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8184 - mse: 0.8184 - mae: 0.7533\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7899 - mse: 0.7899 - mae: 0.7387\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7620 - mse: 0.7620 - mae: 0.7244\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7341 - mse: 0.7341 - mae: 0.7106\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7063 - mse: 0.7063 - mae: 0.6963\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6789 - mse: 0.6789 - mae: 0.6827\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6519 - mse: 0.6519 - mae: 0.6694\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6252 - mse: 0.6252 - mae: 0.6559\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5992 - mse: 0.5992 - mae: 0.6424\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5740 - mse: 0.5740 - mae: 0.6289\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5492 - mse: 0.5492 - mae: 0.6152\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5253 - mse: 0.5253 - mae: 0.6015\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5022 - mse: 0.5022 - mae: 0.5881\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4800 - mse: 0.4800 - mae: 0.5749\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4585 - mse: 0.4585 - mae: 0.5618\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4379 - mse: 0.4379 - mae: 0.5489\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4182 - mse: 0.4182 - mae: 0.5362\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3991 - mse: 0.3991 - mae: 0.5233\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3806 - mse: 0.3806 - mae: 0.5103\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3633 - mse: 0.3633 - mae: 0.4981\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3466 - mse: 0.3466 - mae: 0.4860\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3305 - mse: 0.3305 - mae: 0.4741\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3150 - mse: 0.3150 - mae: 0.4623\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3001 - mse: 0.3001 - mae: 0.4506\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2860 - mse: 0.2860 - mae: 0.4398\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2723 - mse: 0.2723 - mae: 0.4292\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2593 - mse: 0.2593 - mae: 0.4188\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2468 - mse: 0.2468 - mae: 0.4084\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2349 - mse: 0.2349 - mae: 0.3982\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2235 - mse: 0.2235 - mae: 0.3881\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2125 - mse: 0.2125 - mae: 0.3780\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2020 - mse: 0.2020 - mae: 0.3704\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1919 - mse: 0.1919 - mae: 0.3632\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1824 - mse: 0.1824 - mae: 0.3561\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1733 - mse: 0.1733 - mae: 0.3490\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1648 - mse: 0.1648 - mae: 0.3421\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1568 - mse: 0.1568 - mae: 0.3352\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1492 - mse: 0.1492 - mae: 0.3285\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1420 - mse: 0.1420 - mae: 0.3219\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1351 - mse: 0.1351 - mae: 0.3153\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1285 - mse: 0.1285 - mae: 0.3086\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1222 - mse: 0.1222 - mae: 0.3020\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1159 - mse: 0.1159 - mae: 0.2951\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1099 - mse: 0.1099 - mae: 0.2891\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1043 - mse: 0.1043 - mae: 0.2840\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0991 - mse: 0.0991 - mae: 0.2792\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0945 - mse: 0.0945 - mae: 0.2746\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0905 - mse: 0.0905 - mae: 0.2700\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0867 - mse: 0.0867 - mae: 0.2653\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0834 - mse: 0.0834 - mae: 0.2606\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0803 - mse: 0.0803 - mae: 0.2559\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0776 - mse: 0.0776 - mae: 0.2513\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0754 - mse: 0.0754 - mae: 0.2473\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0736 - mse: 0.0736 - mae: 0.2452\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0720 - mse: 0.0720 - mae: 0.2431\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0705 - mse: 0.0705 - mae: 0.2410\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0692 - mse: 0.0692 - mae: 0.2391\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0681 - mse: 0.0681 - mae: 0.2372\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0671 - mse: 0.0671 - mae: 0.2353\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0663 - mse: 0.0663 - mae: 0.2336\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0656 - mse: 0.0656 - mae: 0.2319\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0650 - mse: 0.0650 - mae: 0.2303\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0645 - mse: 0.0645 - mae: 0.2287\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0639 - mse: 0.0639 - mae: 0.2272\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0635 - mse: 0.0635 - mae: 0.2257\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0630 - mse: 0.0630 - mae: 0.2243\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0627 - mse: 0.0627 - mae: 0.2231\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0624 - mse: 0.0624 - mae: 0.2220\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0623 - mse: 0.0623 - mae: 0.2210\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0622 - mse: 0.0622 - mae: 0.2200\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0621 - mse: 0.0621 - mae: 0.2191\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0620 - mse: 0.0620 - mae: 0.2183\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0619 - mse: 0.0619 - mae: 0.2177\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0618 - mse: 0.0618 - mae: 0.2171\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0618 - mse: 0.0618 - mae: 0.2166\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0617 - mse: 0.0617 - mae: 0.2162\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0616 - mse: 0.0616 - mae: 0.2157\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0616 - mse: 0.0616 - mae: 0.2154\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0615 - mse: 0.0615 - mae: 0.2151\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0614 - mse: 0.0614 - mae: 0.2148\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0614 - mse: 0.0614 - mae: 0.2146\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0613 - mse: 0.0613 - mae: 0.2145\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0612 - mse: 0.0612 - mae: 0.2143\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0612 - mse: 0.0612 - mae: 0.2143\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0611 - mse: 0.0611 - mae: 0.2141\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0610 - mse: 0.0610 - mae: 0.2140\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0610 - mse: 0.0610 - mae: 0.2140\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0609 - mse: 0.0609 - mae: 0.2138\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0608 - mse: 0.0608 - mae: 0.2138\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0608 - mse: 0.0608 - mae: 0.2137\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0607 - mse: 0.0607 - mae: 0.2136\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0607 - mse: 0.0607 - mae: 0.2136\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0606 - mse: 0.0606 - mae: 0.2136\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0605 - mse: 0.0605 - mae: 0.2136\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0604 - mse: 0.0604 - mae: 0.2136\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0604 - mse: 0.0604 - mae: 0.2136\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0603 - mse: 0.0603 - mae: 0.2137\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0602 - mse: 0.0602 - mae: 0.2137\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0602 - mse: 0.0602 - mae: 0.2138\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0601 - mse: 0.0601 - mae: 0.2138\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0601 - mse: 0.0601 - mae: 0.2139\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0600 - mse: 0.0600 - mae: 0.2140\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0600 - mse: 0.0600 - mae: 0.2141\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0599 - mse: 0.0599 - mae: 0.2141\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0599 - mse: 0.0599 - mae: 0.2142\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0598 - mse: 0.0598 - mae: 0.2142\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0598 - mse: 0.0598 - mae: 0.2142\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0597 - mse: 0.0597 - mae: 0.2142\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0597 - mse: 0.0597 - mae: 0.2142\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0596 - mse: 0.0596 - mae: 0.2142\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0596 - mse: 0.0596 - mae: 0.2142\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0596 - mse: 0.0596 - mae: 0.2141\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0595 - mse: 0.0595 - mae: 0.2141\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0595 - mse: 0.0595 - mae: 0.2142\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0594 - mse: 0.0594 - mae: 0.2141\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0594 - mse: 0.0594 - mae: 0.2141\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0593 - mse: 0.0593 - mae: 0.2141\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0593 - mse: 0.0593 - mae: 0.2141\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0592 - mse: 0.0592 - mae: 0.2141\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0592 - mse: 0.0592 - mae: 0.2140\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0592 - mse: 0.0592 - mae: 0.2140\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0591 - mse: 0.0591 - mae: 0.2139\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0591 - mse: 0.0591 - mae: 0.2139\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0591 - mse: 0.0591 - mae: 0.2138\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0590 - mse: 0.0590 - mae: 0.2138\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0590 - mse: 0.0590 - mae: 0.2137\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0589 - mse: 0.0589 - mae: 0.2136\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0589 - mse: 0.0589 - mae: 0.2135\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0589 - mse: 0.0589 - mae: 0.2135\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0588 - mse: 0.0588 - mae: 0.2134\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0588 - mse: 0.0588 - mae: 0.2133\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0587 - mse: 0.0587 - mae: 0.2132\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0587 - mse: 0.0587 - mae: 0.2131\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0586 - mse: 0.0586 - mae: 0.2131\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0586 - mse: 0.0586 - mae: 0.2130\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0585 - mse: 0.0585 - mae: 0.2129\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0585 - mse: 0.0585 - mae: 0.2128\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0585 - mse: 0.0585 - mae: 0.2127\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0584 - mse: 0.0584 - mae: 0.2126\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0584 - mse: 0.0584 - mae: 0.2126\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0583 - mse: 0.0583 - mae: 0.2125\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0583 - mse: 0.0583 - mae: 0.2125\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0582 - mse: 0.0582 - mae: 0.2124\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0582 - mse: 0.0582 - mae: 0.2123\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0582 - mse: 0.0582 - mae: 0.2122\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0581 - mse: 0.0581 - mae: 0.2121\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0581 - mse: 0.0581 - mae: 0.2121\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0580 - mse: 0.0580 - mae: 0.2120\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0580 - mse: 0.0580 - mae: 0.2119\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0580 - mse: 0.0580 - mae: 0.2119\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0579 - mse: 0.0579 - mae: 0.2118\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0579 - mse: 0.0579 - mae: 0.2117\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0579 - mse: 0.0579 - mae: 0.2117\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0578 - mse: 0.0578 - mae: 0.2116\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0578 - mse: 0.0578 - mae: 0.2116\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0578 - mse: 0.0578 - mae: 0.2115\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0577 - mse: 0.0577 - mae: 0.2115\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0577 - mse: 0.0577 - mae: 0.2114\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0577 - mse: 0.0577 - mae: 0.2114\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0576 - mse: 0.0576 - mae: 0.2113\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0576 - mse: 0.0576 - mae: 0.2113\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0576 - mse: 0.0576 - mae: 0.2112\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0575 - mse: 0.0575 - mae: 0.2112\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0575 - mse: 0.0575 - mae: 0.2111\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0575 - mse: 0.0575 - mae: 0.2111\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0574 - mse: 0.0574 - mae: 0.2110\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0574 - mse: 0.0574 - mae: 0.2109\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0574 - mse: 0.0574 - mae: 0.2109\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0573 - mse: 0.0573 - mae: 0.2108\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0573 - mse: 0.0573 - mae: 0.2108\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0573 - mse: 0.0573 - mae: 0.2107\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0572 - mse: 0.0572 - mae: 0.2107\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0572 - mse: 0.0572 - mae: 0.2106\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0571 - mse: 0.0571 - mae: 0.2106\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0571 - mse: 0.0571 - mae: 0.2106\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0571 - mse: 0.0571 - mae: 0.2105\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0570 - mse: 0.0570 - mae: 0.2104\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0570 - mse: 0.0570 - mae: 0.2104\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.2103\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.2103\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.2102\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0568 - mse: 0.0568 - mae: 0.2101\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0568 - mse: 0.0568 - mae: 0.2101\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0568 - mse: 0.0568 - mae: 0.2100\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0567 - mse: 0.0567 - mae: 0.2100\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0567 - mse: 0.0567 - mae: 0.2099\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0566 - mse: 0.0566 - mae: 0.2098\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0566 - mse: 0.0566 - mae: 0.2098\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0566 - mse: 0.0566 - mae: 0.2097\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0565 - mse: 0.0565 - mae: 0.2097\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0565 - mse: 0.0565 - mae: 0.2096\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0564 - mse: 0.0564 - mae: 0.2096\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0564 - mse: 0.0564 - mae: 0.2095\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0564 - mse: 0.0564 - mae: 0.2095\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0563 - mse: 0.0563 - mae: 0.2094\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0563 - mse: 0.0563 - mae: 0.2093\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0563 - mse: 0.0563 - mae: 0.2093\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0562 - mse: 0.0562 - mae: 0.2092\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0562 - mse: 0.0562 - mae: 0.2092\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0561 - mse: 0.0561 - mae: 0.2091\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0561 - mse: 0.0561 - mae: 0.2091\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0561 - mse: 0.0561 - mae: 0.2090\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0561 - mse: 0.0561 - mae: 0.2089\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0560 - mse: 0.0560 - mae: 0.2089\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0560 - mse: 0.0560 - mae: 0.2088\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0560 - mse: 0.0560 - mae: 0.2088\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0560 - mse: 0.0560 - mae: 0.2087\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0559 - mse: 0.0559 - mae: 0.2087\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0559 - mse: 0.0559 - mae: 0.2087\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0559 - mse: 0.0559 - mae: 0.2086\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0559 - mse: 0.0559 - mae: 0.2086\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.2086\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.2085\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.2084\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.2084\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0557 - mse: 0.0557 - mae: 0.2083\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0557 - mse: 0.0557 - mae: 0.2083\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0557 - mse: 0.0557 - mae: 0.2082\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0557 - mse: 0.0557 - mae: 0.2082\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.2081\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.2081\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.2080\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.2080\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0555 - mse: 0.0555 - mae: 0.2080\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0555 - mse: 0.0555 - mae: 0.2079\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0555 - mse: 0.0555 - mae: 0.2079\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0555 - mse: 0.0555 - mae: 0.2078\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0554 - mse: 0.0554 - mae: 0.2078\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0554 - mse: 0.0554 - mae: 0.2077\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0554 - mse: 0.0554 - mae: 0.2077\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0554 - mse: 0.0554 - mae: 0.2076\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.2076\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.2075\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.2075\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.2074\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0552 - mse: 0.0552 - mae: 0.2074\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0552 - mse: 0.0552 - mae: 0.2073\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0552 - mse: 0.0552 - mae: 0.2073\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0552 - mse: 0.0552 - mae: 0.2073\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0551 - mse: 0.0551 - mae: 0.2072\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0551 - mse: 0.0551 - mae: 0.2072\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0551 - mse: 0.0551 - mae: 0.2071\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0551 - mse: 0.0551 - mae: 0.2071\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0550 - mse: 0.0550 - mae: 0.2071\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0550 - mse: 0.0550 - mae: 0.2070\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0550 - mse: 0.0550 - mae: 0.2070\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0550 - mse: 0.0550 - mae: 0.2069\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0549 - mse: 0.0549 - mae: 0.2069\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0549 - mse: 0.0549 - mae: 0.2068\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0549 - mse: 0.0549 - mae: 0.2068\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0549 - mse: 0.0549 - mae: 0.2068\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0549 - mse: 0.0549 - mae: 0.2068\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0549 - mse: 0.0549 - mae: 0.2068\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0548 - mse: 0.0548 - mae: 0.2067\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0548 - mse: 0.0548 - mae: 0.2067\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0548 - mse: 0.0548 - mae: 0.2067\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0548 - mse: 0.0548 - mae: 0.2066\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0548 - mse: 0.0548 - mae: 0.2066\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0548 - mse: 0.0548 - mae: 0.2066\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.2066\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.2065\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.2065\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.2065\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.2065\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.2064\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.2065\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.2065\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.2065\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.2065\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.2064\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.2064\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.2063\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.2062\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.2063\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.2063\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.2063\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.2063\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.2062\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.2061\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.2061\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.2060\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.2060\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.2059\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.2059\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0543 - mse: 0.0543 - mae: 0.2058\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0543 - mse: 0.0543 - mae: 0.2058\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0543 - mse: 0.0543 - mae: 0.2058\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0543 - mse: 0.0543 - mae: 0.2057\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0543 - mse: 0.0543 - mae: 0.2057\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0542 - mse: 0.0542 - mae: 0.2057\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0542 - mse: 0.0542 - mae: 0.2057\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0542 - mse: 0.0542 - mae: 0.2057\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0542 - mse: 0.0542 - mae: 0.2056\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.2056\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.2055\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.2054\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.2054\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.2053\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0540 - mse: 0.0540 - mae: 0.2053\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0540 - mse: 0.0540 - mae: 0.2051\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0540 - mse: 0.0540 - mae: 0.2051\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0540 - mse: 0.0540 - mae: 0.2051\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0539 - mse: 0.0539 - mae: 0.2051\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0539 - mse: 0.0539 - mae: 0.2051\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0539 - mse: 0.0539 - mae: 0.2051\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0539 - mse: 0.0539 - mae: 0.2051\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0538 - mse: 0.0538 - mae: 0.2052\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0538 - mse: 0.0538 - mae: 0.2053\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0538 - mse: 0.0538 - mae: 0.2053\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0538 - mse: 0.0538 - mae: 0.2053\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0537 - mse: 0.0537 - mae: 0.2053\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0537 - mse: 0.0537 - mae: 0.2052\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0537 - mse: 0.0537 - mae: 0.2051\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0537 - mse: 0.0537 - mae: 0.2050\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0536 - mse: 0.0536 - mae: 0.2049\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0536 - mse: 0.0536 - mae: 0.2048\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0536 - mse: 0.0536 - mae: 0.2047\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0536 - mse: 0.0536 - mae: 0.2046\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0535 - mse: 0.0535 - mae: 0.2046\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0535 - mse: 0.0535 - mae: 0.2045\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0535 - mse: 0.0535 - mae: 0.2045\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0535 - mse: 0.0535 - mae: 0.2045\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0534 - mse: 0.0534 - mae: 0.2045\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0534 - mse: 0.0534 - mae: 0.2044\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0534 - mse: 0.0534 - mae: 0.2043\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0534 - mse: 0.0534 - mae: 0.2042\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0533 - mse: 0.0533 - mae: 0.2041\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0533 - mse: 0.0533 - mae: 0.2040\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0533 - mse: 0.0533 - mae: 0.2040\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0533 - mse: 0.0533 - mae: 0.2040\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.2041\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.2042\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.2043\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.2043\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.2044\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.2044\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.2043\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.2043\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.2042\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.2041\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.2040\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.2039\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.2039\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.2038\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.2037\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.2036\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.2036\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.2036\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.2037\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.2037\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.2038\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.2039\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.2039\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0529 - mse: 0.0529 - mae: 0.2039\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0529 - mse: 0.0529 - mae: 0.2039\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0529 - mse: 0.0529 - mae: 0.2038\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0529 - mse: 0.0529 - mae: 0.2037\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0529 - mse: 0.0529 - mae: 0.2036\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0529 - mse: 0.0529 - mae: 0.2035\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0529 - mse: 0.0529 - mae: 0.2034\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.2034\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.2033\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.2032\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.2031\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.2030\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.2030\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.2031\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.2032\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.2033\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.2034\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.2034\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.2034\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.2033\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.2033\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.2032\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.2031\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.2030\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.2029\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.2029\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.2028\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.2028\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.2027\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.2026\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.2025\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.2025\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.2025\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.2026\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.2027\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.2027\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.2027\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.2027\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.2027\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.2026\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.2025\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.2025\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.2024\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.2023\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.2023\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.2023\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.2021\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.2020\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.2019\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.2019\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.2020\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.2020\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.2021\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.2022\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.2022\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.2022\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.2021\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.2020\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.2019\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.2018\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.2017\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.2016\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.2016\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.2016\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.2014\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.2014\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.2013\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.2013\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.2014\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.2015\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.2015\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.2016\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.2016\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.2015\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.2015\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.2014\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.2013\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.2012\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.2011\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.2010\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.2010\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.2009\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.2010\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.2010\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.2010\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.2009\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.2009\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.2010\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.2011\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.2011\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.2010\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.2009\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.2008\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.2007\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.2007\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.2007\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.2006\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.2006\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.2006\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.2007\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.2007\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.2006\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0515 - mse: 0.0515 - mae: 0.2006\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0515 - mse: 0.0515 - mae: 0.2005\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0515 - mse: 0.0515 - mae: 0.2005\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0515 - mse: 0.0515 - mae: 0.2005\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0515 - mse: 0.0515 - mae: 0.2005\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0515 - mse: 0.0515 - mae: 0.2005\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0515 - mse: 0.0515 - mae: 0.2004\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.2003\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.2003\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.2003\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.2003\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.2002\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.2002\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.2002\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.2002\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.2002\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.2002\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.2001\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.2001\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.2000\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.2000\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.2000\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.2000\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1999\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1998\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1998\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1998\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1997\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1997\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1997\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1997\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1997\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1997\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1996\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1995\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1995\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1996\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1996\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1996\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1995\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1994\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1993\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1993\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1993\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1994\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1994\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1994\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1993\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1992\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1992\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1992\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1992\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1992\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1991\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1990\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1990\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1989\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1989\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1989\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1989\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1989\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1989\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1988\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1988\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1987\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1986\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1986\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1986\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1987\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1986\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1986\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1985\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1984\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1984\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1985\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1985\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1985\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1984\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1983\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1982\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1983\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1984\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1984\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1983\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1981\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1980\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1980\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1979\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1979\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1980\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1980\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1980\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1979\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1978\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1977\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1978\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1978\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1978\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1976\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1976\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1976\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1976\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1975\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1976\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1976\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1975\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1975\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1974\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1973\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1974\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1975\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1974\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1974\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1973\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1972\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1972\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1972\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1972\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1972\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1972\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1972\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1971\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1971\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1970\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1969\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1969\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1969\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1969\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1968\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1968\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1968\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1968\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1968\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1968\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1968\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1968\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1968\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1967\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1966\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1966\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1965\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1965\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1964\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1964\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1964\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1964\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1964\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1964\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1964\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1964\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1963\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1963\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1962\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1961\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1962\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1961\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1961\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1960\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1960\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1959\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1959\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1960\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1960\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1960\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1959\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1959\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1958\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1957\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1957\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1956\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1956\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1956\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1956\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1956\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1955\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1955\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1955\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1955\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1954\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1954\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1953\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1953\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1953\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1952\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1951\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1951\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1951\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1950\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1951\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1951\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0492 - mse: 0.0492 - mae: 0.1950\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0492 - mse: 0.0492 - mae: 0.1950\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0492 - mse: 0.0492 - mae: 0.1949\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0492 - mse: 0.0492 - mae: 0.1949\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0492 - mse: 0.0492 - mae: 0.1950\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0492 - mse: 0.0492 - mae: 0.1950\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0492 - mse: 0.0492 - mae: 0.1950\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1948\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1947\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1947\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1946\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1947\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1947\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1947\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1947\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1946\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1945\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1945\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1945\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1944\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1943\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1943\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1942\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1942\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1943\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1943\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1943\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1942\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1941\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1941\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1941\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1941\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1940\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1939\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1938\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1937\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1938\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1939\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1938\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1938\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1937\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1937\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1938\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1938\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1938\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1936\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1934\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1934\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1934\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1935\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1935\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1934\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1933\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1932\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1933\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1934\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1934\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1933\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1932\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1930\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1931\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1932\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1932\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1931\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1930\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1929\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1928\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1930\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1930\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1929\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1927\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1925\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1925\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1926\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1926\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0483 - mse: 0.0483 - mae: 0.1926\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0483 - mse: 0.0483 - mae: 0.1925\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0483 - mse: 0.0483 - mae: 0.1924\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0483 - mse: 0.0483 - mae: 0.1924\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0483 - mse: 0.0483 - mae: 0.1925\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0483 - mse: 0.0483 - mae: 0.1925\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0483 - mse: 0.0483 - mae: 0.1924\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0482 - mse: 0.0482 - mae: 0.1923\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0482 - mse: 0.0482 - mae: 0.1921\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0482 - mse: 0.0482 - mae: 0.1922\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0482 - mse: 0.0482 - mae: 0.1922\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0482 - mse: 0.0482 - mae: 0.1922\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0482 - mse: 0.0482 - mae: 0.1921\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0482 - mse: 0.0482 - mae: 0.1920\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0482 - mse: 0.0482 - mae: 0.1919\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1921\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1921\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1920\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1918\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1917\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1917\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1917\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1918\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1917\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1916\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1915\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1917\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1917\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1917\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1916\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1914\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1913\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0479 - mse: 0.0479 - mae: 0.1914\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0479 - mse: 0.0479 - mae: 0.1914\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0479 - mse: 0.0479 - mae: 0.1914\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0479 - mse: 0.0479 - mae: 0.1913\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0479 - mse: 0.0479 - mae: 0.1911\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0479 - mse: 0.0479 - mae: 0.1912\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0479 - mse: 0.0479 - mae: 0.1913\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0479 - mse: 0.0479 - mae: 0.1913\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1912\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1910\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1909\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1910\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1910\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1910\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1910\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1909\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1907\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1908\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1909\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1908\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1906\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1905\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1905\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1906\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1905\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1905\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1904\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1903\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1904\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1905\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1905\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1903\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1901\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1900\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1901\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1902\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1901\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1900\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1899\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1899\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1900\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1900\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1899\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1897\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1899\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1900\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1900\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1899\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1898\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1897\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1895\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1896\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1895\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1894\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1893\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1893\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1893\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1894\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1893\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1892\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1891\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1893\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1893\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1893\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1891\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1889\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1890\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1891\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1890\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1889\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1888\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1889\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1889\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1888\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1886\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1885\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1885\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1886\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1887\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1887\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1885\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1883\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1882\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1884\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1883\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1881\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1881\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1882\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1881\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1881\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1881\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1882\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1882\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1881\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1880\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1878\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1876\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1876\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1877\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1877\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1877\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1876\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1875\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1874\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1874\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1873\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1874\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1875\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1875\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1874\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1873\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1873\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1875\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1876\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1875\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1872\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1870\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1869\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1870\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1870\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1869\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1868\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1867\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1868\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1868\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1866\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1866\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1867\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1868\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1867\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1867\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1865\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1864\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1863\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1863\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1862\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1861\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1860\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1861\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1862\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1861\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1859\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1858\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1859\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1859\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1858\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1858\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1859\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1859\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1859\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1858\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1857\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1856\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1856\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1855\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1855\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1854\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1855\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1855\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1855\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1853\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1852\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1851\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5596e01e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "J_-zYEwT7PZ6",
        "outputId": "a1e85c4a-2480-4868-d930-88c06e5ce3bc"
      },
      "source": [
        "plt.scatter(x, model.predict(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f559b954a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f559d789cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "cV_qBvtw734T",
        "outputId": "46654c1b-920b-42e3-a559-f1066ce2b1c0"
      },
      "source": [
        "plt.scatter(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f559d7fee90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGFCy85D_dTz"
      },
      "source": [
        "### Summarizing and Visualizing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-dxsaWRfSyU"
      },
      "source": [
        "In practice, a typical workflow you'll go through when building neural network is:\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak a model -> \n",
        "fit it -> evaluate it -> tweak a model -> fit it -> evaluate it ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUIkfdecDYjZ"
      },
      "source": [
        "A good way to evaluate model is to visualize it. It's generally a good idea to visualize:\n",
        "*  The data - what data are we working with? What does it look like?\n",
        "*  The model - what does our model look like?\n",
        "*  The training of a model - how does a model perform whilte it learns?\n",
        "*  The predictions o the model - how do the predictions of a model line up against the true values?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "xmhwrT2hgM9e",
        "outputId": "1ef8a732-c3e5-410b-be5b-ef5eb458fe9a"
      },
      "source": [
        "# Let's create a bigger dataset\n",
        "np.random.seed(42)\n",
        "x = np.random.normal(size = 250)\n",
        "y = 5.123 + 1.869 * x + 1.3*np.square(x) + np.random.normal(size = 250, scale = 1.852)\n",
        "plt.scatter(x, y);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KCEnDlgghnw",
        "outputId": "c27dfc62-f465-4f70-d292-cf7443d96779"
      },
      "source": [
        "# Now let's split x and y into training and testing set (let's skip validation set)\n",
        "print('Length of data:', len(x))\n",
        "\n",
        "# Split the data into train and test sets\n",
        "x_train = x[:200] # The first 200 samples \n",
        "x_test = x[200:] # The last 50 samples\n",
        "\n",
        "y_train = y[:200]\n",
        "y_test = y[200:]\n",
        "\n",
        "print('Length of x train:', len(x_train))\n",
        "print('Length of x test:', len(x_test))\n",
        "print('Length of y train:', len(y_train))\n",
        "print('Length of y test:', len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of data: 250\n",
            "Length of x train: 200\n",
            "Length of x test: 50\n",
            "Length of y train: 200\n",
            "Length of y test: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "vkLyUgZiiLOp",
        "outputId": "86226853-d18a-450c-dd9d-935ec92dac13"
      },
      "source": [
        "# Let's plot two sets of data\n",
        "plt.figure(figsize = (10, 7))\n",
        "plt.scatter(x_train, y_train, c = 'b', label = 'Training data')\n",
        "plt.scatter(x_test, y_test, c = 'g', label = 'Testing data')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG7k-nBojzI1"
      },
      "source": [
        "# Let's build a model in order to figure out the relationship between train and test data\n",
        "# Let's first visualize the model itself before fitting it\n",
        "# We need to define the model and build it or fit it\n",
        "# Alternatively, we can specify input_shape argument in the first layer and it will build automatically\n",
        "\n",
        "model = tf.keras.Sequential(name = 'Network1')\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units = 50, \n",
        "        input_shape = [1],  # figure out the input_shape\n",
        "        activation = 'relu', \n",
        "        use_bias = True,\n",
        "        name = 'Layer1'\n",
        "        )\n",
        "    )\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        50, \n",
        "        activation = 'relu', \n",
        "        use_bias = True, \n",
        "        kernel_regularizer = tf.keras.regularizers.L2(),\n",
        "        name = 'Layer2'\n",
        "        )\n",
        "    ) \n",
        "model.add(tf.keras.layers.Dense(1, name = 'Output'))\n",
        "\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.mse, \n",
        "    optimizer = tf.keras.optimizers.Adam(lr = 0.0001), \n",
        "    metrics = ['mse', 'mae']\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFAKfqNlk6CM",
        "outputId": "de4b4a54-edb7-4e7d-d210-d74ae5c051c1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Network1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Layer1 (Dense)               (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "Layer2 (Dense)               (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 2,701\n",
            "Trainable params: 2,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQr73VONlcAm"
      },
      "source": [
        "In the previous table, the total parameters indicates the total number of parameters in the model. Trainable parameters are those the model can update as it trains. Nontrainable parameters aren't updated during training (this is typicall when we bring in already trained parameters from other models during *transfer learning*). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5zjvWl0nX9k",
        "outputId": "03cecdb0-be9b-40b8-b186-e7bc85dc905c"
      },
      "source": [
        "model.fit(x_train, y_train, epochs = 550)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/550\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 49.4863 - mse: 48.9834 - mae: 6.2812\n",
            "Epoch 2/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 48.3097 - mse: 47.8096 - mae: 6.2494\n",
            "Epoch 3/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 47.1746 - mse: 46.6773 - mae: 6.1475\n",
            "Epoch 4/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 47.1112 - mse: 46.6166 - mae: 6.1623\n",
            "Epoch 5/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 48.8526 - mse: 48.3607 - mae: 6.3301\n",
            "Epoch 6/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 48.3671 - mse: 47.8779 - mae: 6.1786\n",
            "Epoch 7/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 47.9566 - mse: 47.4700 - mae: 6.2366\n",
            "Epoch 8/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 49.8618 - mse: 49.3777 - mae: 6.3678\n",
            "Epoch 9/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 49.8964 - mse: 49.4149 - mae: 6.2896\n",
            "Epoch 10/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 49.9040 - mse: 49.4250 - mae: 6.3573\n",
            "Epoch 11/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 43.1848 - mse: 42.7083 - mae: 5.9233\n",
            "Epoch 12/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 45.4011 - mse: 44.9271 - mae: 6.1271\n",
            "Epoch 13/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 49.7125 - mse: 49.2409 - mae: 6.3025\n",
            "Epoch 14/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 47.9103 - mse: 47.4411 - mae: 6.2034\n",
            "Epoch 15/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 44.3411 - mse: 43.8742 - mae: 6.0226\n",
            "Epoch 16/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 44.3482 - mse: 43.8836 - mae: 6.0176\n",
            "Epoch 17/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 47.1672 - mse: 46.7049 - mae: 6.1269\n",
            "Epoch 18/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 48.7662 - mse: 48.3061 - mae: 6.3018\n",
            "Epoch 19/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 47.5497 - mse: 47.0918 - mae: 6.2096\n",
            "Epoch 20/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 47.2559 - mse: 46.8002 - mae: 6.1000\n",
            "Epoch 21/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 43.2479 - mse: 42.7943 - mae: 5.9250\n",
            "Epoch 22/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 46.8725 - mse: 46.4209 - mae: 6.0987\n",
            "Epoch 23/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 46.9744 - mse: 46.5249 - mae: 6.1447\n",
            "Epoch 24/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 48.7642 - mse: 48.3167 - mae: 6.1816\n",
            "Epoch 25/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 43.7771 - mse: 43.3315 - mae: 5.9418\n",
            "Epoch 26/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 44.5045 - mse: 44.0608 - mae: 6.0418\n",
            "Epoch 27/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 42.3623 - mse: 41.9205 - mae: 5.8605\n",
            "Epoch 28/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 43.6307 - mse: 43.1907 - mae: 5.9925\n",
            "Epoch 29/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 47.0278 - mse: 46.5896 - mae: 6.0743\n",
            "Epoch 30/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 44.6571 - mse: 44.2207 - mae: 5.9928\n",
            "Epoch 31/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 47.1850 - mse: 46.7503 - mae: 6.2039\n",
            "Epoch 32/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 42.4183 - mse: 41.9853 - mae: 5.8395\n",
            "Epoch 33/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 42.9452 - mse: 42.5139 - mae: 5.8539\n",
            "Epoch 34/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 42.5823 - mse: 42.1525 - mae: 5.8745\n",
            "Epoch 35/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 43.5378 - mse: 43.1096 - mae: 5.9748\n",
            "Epoch 36/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 42.0098 - mse: 41.5831 - mae: 5.7610\n",
            "Epoch 37/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 40.9915 - mse: 40.5663 - mae: 5.7567\n",
            "Epoch 38/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 42.3559 - mse: 41.9322 - mae: 5.8711\n",
            "Epoch 39/550\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 43.3240 - mse: 42.9017 - mae: 5.8496\n",
            "Epoch 40/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 44.4061 - mse: 43.9851 - mae: 5.9721\n",
            "Epoch 41/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 41.1801 - mse: 40.7604 - mae: 5.8218\n",
            "Epoch 42/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 39.1870 - mse: 38.7686 - mae: 5.7136\n",
            "Epoch 43/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 39.1739 - mse: 38.7567 - mae: 5.6296\n",
            "Epoch 44/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 40.3599 - mse: 39.9439 - mae: 5.7148\n",
            "Epoch 45/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 41.0446 - mse: 40.6298 - mae: 5.7115\n",
            "Epoch 46/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 44.4496 - mse: 44.0360 - mae: 5.9549\n",
            "Epoch 47/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 37.6666 - mse: 37.2540 - mae: 5.5379\n",
            "Epoch 48/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 41.3421 - mse: 40.9305 - mae: 5.7063\n",
            "Epoch 49/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 38.7406 - mse: 38.3300 - mae: 5.6091\n",
            "Epoch 50/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 37.7439 - mse: 37.3343 - mae: 5.5213\n",
            "Epoch 51/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 34.9101 - mse: 34.5014 - mae: 5.3509\n",
            "Epoch 52/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 34.7292 - mse: 34.3214 - mae: 5.2822\n",
            "Epoch 53/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 40.1516 - mse: 39.7448 - mae: 5.7153\n",
            "Epoch 54/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 37.8894 - mse: 37.4834 - mae: 5.5326\n",
            "Epoch 55/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 38.8667 - mse: 38.4614 - mae: 5.5711\n",
            "Epoch 56/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 37.1021 - mse: 36.6976 - mae: 5.5056\n",
            "Epoch 57/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 36.1147 - mse: 35.7110 - mae: 5.3958\n",
            "Epoch 58/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 37.8678 - mse: 37.4649 - mae: 5.4411\n",
            "Epoch 59/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 35.8879 - mse: 35.4856 - mae: 5.3257\n",
            "Epoch 60/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 31.7977 - mse: 31.3960 - mae: 5.0504\n",
            "Epoch 61/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 33.3643 - mse: 32.9633 - mae: 5.1893\n",
            "Epoch 62/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 36.1612 - mse: 35.7608 - mae: 5.4218\n",
            "Epoch 63/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 34.1022 - mse: 33.7023 - mae: 5.1773\n",
            "Epoch 64/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 31.6553 - mse: 31.2559 - mae: 5.0092\n",
            "Epoch 65/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 32.8752 - mse: 32.4764 - mae: 5.1088\n",
            "Epoch 66/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 32.9430 - mse: 32.5447 - mae: 5.1720\n",
            "Epoch 67/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 30.8979 - mse: 30.5000 - mae: 4.9773\n",
            "Epoch 68/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 32.7046 - mse: 32.3071 - mae: 5.0806\n",
            "Epoch 69/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 29.5077 - mse: 29.1106 - mae: 4.8312\n",
            "Epoch 70/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 29.3688 - mse: 28.9721 - mae: 4.8517\n",
            "Epoch 71/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 30.2531 - mse: 29.8568 - mae: 4.9038\n",
            "Epoch 72/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 30.6574 - mse: 30.2615 - mae: 4.9121\n",
            "Epoch 73/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 28.2606 - mse: 27.8650 - mae: 4.7607\n",
            "Epoch 74/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 27.1507 - mse: 26.7554 - mae: 4.6855\n",
            "Epoch 75/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 28.8860 - mse: 28.4910 - mae: 4.7870\n",
            "Epoch 76/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 27.6262 - mse: 27.2315 - mae: 4.6750\n",
            "Epoch 77/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 27.8209 - mse: 27.4264 - mae: 4.6805\n",
            "Epoch 78/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 28.5571 - mse: 28.1628 - mae: 4.7574\n",
            "Epoch 79/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 26.4772 - mse: 26.0832 - mae: 4.5637\n",
            "Epoch 80/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 25.4126 - mse: 25.0188 - mae: 4.4956\n",
            "Epoch 81/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 27.5985 - mse: 27.2049 - mae: 4.6500\n",
            "Epoch 82/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 25.7471 - mse: 25.3535 - mae: 4.4891\n",
            "Epoch 83/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 24.0326 - mse: 23.6392 - mae: 4.3388\n",
            "Epoch 84/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 25.5575 - mse: 25.1642 - mae: 4.4555\n",
            "Epoch 85/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 22.4263 - mse: 22.0331 - mae: 4.1825\n",
            "Epoch 86/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 26.4622 - mse: 26.0691 - mae: 4.5569\n",
            "Epoch 87/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 23.0571 - mse: 22.6639 - mae: 4.2359\n",
            "Epoch 88/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 22.5032 - mse: 22.1101 - mae: 4.1483\n",
            "Epoch 89/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 22.7841 - mse: 22.3910 - mae: 4.2182\n",
            "Epoch 90/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 21.9410 - mse: 21.5479 - mae: 4.1365\n",
            "Epoch 91/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 24.7975 - mse: 24.4044 - mae: 4.3791\n",
            "Epoch 92/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 19.8727 - mse: 19.4795 - mae: 3.8848\n",
            "Epoch 93/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 19.3839 - mse: 18.9907 - mae: 3.8658\n",
            "Epoch 94/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 19.8701 - mse: 19.4768 - mae: 3.9097\n",
            "Epoch 95/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 20.3565 - mse: 19.9632 - mae: 3.9366\n",
            "Epoch 96/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 18.9077 - mse: 18.5143 - mae: 3.8050\n",
            "Epoch 97/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 19.6476 - mse: 19.2540 - mae: 3.8707\n",
            "Epoch 98/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 18.3210 - mse: 17.9272 - mae: 3.7179\n",
            "Epoch 99/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 20.2478 - mse: 19.8537 - mae: 3.9358\n",
            "Epoch 100/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 18.5455 - mse: 18.1512 - mae: 3.7331\n",
            "Epoch 101/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 18.5598 - mse: 18.1653 - mae: 3.7412\n",
            "Epoch 102/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 16.2898 - mse: 15.8952 - mae: 3.4716\n",
            "Epoch 103/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 15.9911 - mse: 15.5963 - mae: 3.4536\n",
            "Epoch 104/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 16.3871 - mse: 15.9921 - mae: 3.5143\n",
            "Epoch 105/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 17.0592 - mse: 16.6640 - mae: 3.6189\n",
            "Epoch 106/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 15.3532 - mse: 14.9578 - mae: 3.3855\n",
            "Epoch 107/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 15.0402 - mse: 14.6445 - mae: 3.3444\n",
            "Epoch 108/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 15.7987 - mse: 15.4028 - mae: 3.4197\n",
            "Epoch 109/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 16.4595 - mse: 16.0633 - mae: 3.4766\n",
            "Epoch 110/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 14.0719 - mse: 13.6755 - mae: 3.1736\n",
            "Epoch 111/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 13.3678 - mse: 12.9711 - mae: 3.0877\n",
            "Epoch 112/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 12.8620 - mse: 12.4651 - mae: 3.0311\n",
            "Epoch 113/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 13.1424 - mse: 12.7453 - mae: 3.0639\n",
            "Epoch 114/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 12.8192 - mse: 12.4218 - mae: 3.0338\n",
            "Epoch 115/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 12.6312 - mse: 12.2335 - mae: 2.9539\n",
            "Epoch 116/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 11.7560 - mse: 11.3581 - mae: 2.9088\n",
            "Epoch 117/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 11.8493 - mse: 11.4512 - mae: 2.8638\n",
            "Epoch 118/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 11.4490 - mse: 11.0506 - mae: 2.8442\n",
            "Epoch 119/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 11.9265 - mse: 11.5278 - mae: 2.8843\n",
            "Epoch 120/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 10.3892 - mse: 9.9902 - mae: 2.7000\n",
            "Epoch 121/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 11.3123 - mse: 10.9130 - mae: 2.8296\n",
            "Epoch 122/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 9.7244 - mse: 9.3248 - mae: 2.5802\n",
            "Epoch 123/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 10.2235 - mse: 9.8237 - mae: 2.6376\n",
            "Epoch 124/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 9.6538 - mse: 9.2537 - mae: 2.5429\n",
            "Epoch 125/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 9.9850 - mse: 9.5847 - mae: 2.5994\n",
            "Epoch 126/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 9.1746 - mse: 8.7740 - mae: 2.5061\n",
            "Epoch 127/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 8.4135 - mse: 8.0126 - mae: 2.3817\n",
            "Epoch 128/550\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 8.7164 - mse: 8.3154 - mae: 2.4276\n",
            "Epoch 129/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 8.2978 - mse: 7.8966 - mae: 2.3556\n",
            "Epoch 130/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 8.7089 - mse: 8.3074 - mae: 2.3946\n",
            "Epoch 131/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 7.7557 - mse: 7.3539 - mae: 2.2305\n",
            "Epoch 132/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 7.7575 - mse: 7.3556 - mae: 2.2541\n",
            "Epoch 133/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 7.3989 - mse: 6.9967 - mae: 2.1765\n",
            "Epoch 134/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 7.0179 - mse: 6.6155 - mae: 2.1034\n",
            "Epoch 135/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 7.2853 - mse: 6.8827 - mae: 2.1285\n",
            "Epoch 136/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 6.9152 - mse: 6.5124 - mae: 2.0847\n",
            "Epoch 137/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 7.7242 - mse: 7.3211 - mae: 2.1957\n",
            "Epoch 138/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 6.7392 - mse: 6.3360 - mae: 2.0648\n",
            "Epoch 139/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 7.1747 - mse: 6.7714 - mae: 2.1197\n",
            "Epoch 140/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 6.2176 - mse: 5.8141 - mae: 1.9354\n",
            "Epoch 141/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 6.3548 - mse: 5.9511 - mae: 1.9848\n",
            "Epoch 142/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 6.6209 - mse: 6.2171 - mae: 2.0145\n",
            "Epoch 143/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 5.7363 - mse: 5.3324 - mae: 1.8340\n",
            "Epoch 144/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 5.7299 - mse: 5.3259 - mae: 1.8538\n",
            "Epoch 145/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 5.8810 - mse: 5.4769 - mae: 1.8784\n",
            "Epoch 146/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 5.2570 - mse: 4.8527 - mae: 1.7194\n",
            "Epoch 147/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 5.3724 - mse: 4.9682 - mae: 1.7667\n",
            "Epoch 148/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.6915 - mse: 5.2873 - mae: 1.8369\n",
            "Epoch 149/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.6402 - mse: 5.2358 - mae: 1.8399\n",
            "Epoch 150/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.9304 - mse: 4.5261 - mae: 1.6830\n",
            "Epoch 151/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 5.2939 - mse: 4.8896 - mae: 1.7423\n",
            "Epoch 152/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.9223 - mse: 4.5180 - mae: 1.6810\n",
            "Epoch 153/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.9964 - mse: 4.5921 - mae: 1.7163\n",
            "Epoch 154/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.8683 - mse: 4.4641 - mae: 1.6593\n",
            "Epoch 155/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.7212 - mse: 4.3170 - mae: 1.6575\n",
            "Epoch 156/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 5.5476 - mse: 5.1435 - mae: 1.8155\n",
            "Epoch 157/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.6668 - mse: 4.2628 - mae: 1.6186\n",
            "Epoch 158/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.6681 - mse: 4.2642 - mae: 1.6048\n",
            "Epoch 159/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.4206 - mse: 4.0167 - mae: 1.5376\n",
            "Epoch 160/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.6815 - mse: 4.2778 - mae: 1.6052\n",
            "Epoch 161/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.6400 - mse: 4.2364 - mae: 1.5938\n",
            "Epoch 162/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.7462 - mse: 4.3428 - mae: 1.6209\n",
            "Epoch 163/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8271 - mse: 3.4239 - mae: 1.4300\n",
            "Epoch 164/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.7240 - mse: 4.3210 - mae: 1.6369\n",
            "Epoch 165/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.4479 - mse: 4.0451 - mae: 1.6038\n",
            "Epoch 166/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.3922 - mse: 3.9896 - mae: 1.5374\n",
            "Epoch 167/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6501 - mse: 3.2479 - mae: 1.3893\n",
            "Epoch 168/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.3717 - mse: 3.9698 - mae: 1.5683\n",
            "Epoch 169/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.4553 - mse: 4.0536 - mae: 1.5860\n",
            "Epoch 170/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.3103 - mse: 3.9090 - mae: 1.5358\n",
            "Epoch 171/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.5001 - mse: 4.0989 - mae: 1.5777\n",
            "Epoch 172/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.0725 - mse: 3.6716 - mae: 1.5187\n",
            "Epoch 173/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.3059 - mse: 3.9053 - mae: 1.5381\n",
            "Epoch 174/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.6390 - mse: 3.2387 - mae: 1.3815\n",
            "Epoch 175/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.8741 - mse: 3.4742 - mae: 1.4512\n",
            "Epoch 176/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9386 - mse: 3.5390 - mae: 1.4603\n",
            "Epoch 177/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.0516 - mse: 3.6523 - mae: 1.4899\n",
            "Epoch 178/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1507 - mse: 3.7516 - mae: 1.5007\n",
            "Epoch 179/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.5052 - mse: 4.1064 - mae: 1.6158\n",
            "Epoch 180/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1871 - mse: 3.7887 - mae: 1.5235\n",
            "Epoch 181/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.7873 - mse: 3.3893 - mae: 1.4504\n",
            "Epoch 182/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.1057 - mse: 3.7080 - mae: 1.4980\n",
            "Epoch 183/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.9912 - mse: 3.5940 - mae: 1.4990\n",
            "Epoch 184/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6036 - mse: 3.2067 - mae: 1.3999\n",
            "Epoch 185/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.0954 - mse: 3.6989 - mae: 1.5243\n",
            "Epoch 186/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.0055 - mse: 3.6094 - mae: 1.4701\n",
            "Epoch 187/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7383 - mse: 3.3425 - mae: 1.4241\n",
            "Epoch 188/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1136 - mse: 3.7182 - mae: 1.4836\n",
            "Epoch 189/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.7385 - mse: 3.3435 - mae: 1.4214\n",
            "Epoch 190/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4732 - mse: 3.0787 - mae: 1.3582\n",
            "Epoch 191/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.0210 - mse: 3.6270 - mae: 1.5112\n",
            "Epoch 192/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9719 - mse: 3.5783 - mae: 1.4920\n",
            "Epoch 193/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.2062 - mse: 3.8131 - mae: 1.5188\n",
            "Epoch 194/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8164 - mse: 3.4236 - mae: 1.4191\n",
            "Epoch 195/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.1432 - mse: 3.7508 - mae: 1.5025\n",
            "Epoch 196/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.1580 - mse: 3.7661 - mae: 1.5400\n",
            "Epoch 197/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1586 - mse: 3.7671 - mae: 1.5086\n",
            "Epoch 198/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.9565 - mse: 3.5654 - mae: 1.4871\n",
            "Epoch 199/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6813 - mse: 3.2907 - mae: 1.4509\n",
            "Epoch 200/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7580 - mse: 3.3679 - mae: 1.4242\n",
            "Epoch 201/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.9862 - mse: 3.5966 - mae: 1.4754\n",
            "Epoch 202/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9343 - mse: 3.5452 - mae: 1.4696\n",
            "Epoch 203/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.7936 - mse: 3.4050 - mae: 1.4340\n",
            "Epoch 204/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.8122 - mse: 3.4239 - mae: 1.4796\n",
            "Epoch 205/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1142 - mse: 3.7264 - mae: 1.5387\n",
            "Epoch 206/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6847 - mse: 3.2974 - mae: 1.4430\n",
            "Epoch 207/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.7020 - mse: 3.3152 - mae: 1.4160\n",
            "Epoch 208/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.8011 - mse: 3.4148 - mae: 1.4687\n",
            "Epoch 209/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9642 - mse: 3.5783 - mae: 1.4730\n",
            "Epoch 210/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1192 - mse: 3.7339 - mae: 1.5283\n",
            "Epoch 211/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.8688 - mse: 3.4840 - mae: 1.4711\n",
            "Epoch 212/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7759 - mse: 3.3916 - mae: 1.4926\n",
            "Epoch 213/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.9820 - mse: 3.5982 - mae: 1.5080\n",
            "Epoch 214/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6193 - mse: 3.2359 - mae: 1.3979\n",
            "Epoch 215/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.6279 - mse: 3.2449 - mae: 1.4065\n",
            "Epoch 216/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7641 - mse: 3.3816 - mae: 1.4277\n",
            "Epoch 217/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.1028 - mse: 3.7207 - mae: 1.5310\n",
            "Epoch 218/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8140 - mse: 3.4323 - mae: 1.4646\n",
            "Epoch 219/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5109 - mse: 3.1296 - mae: 1.4037\n",
            "Epoch 220/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.8996 - mse: 3.5188 - mae: 1.4844\n",
            "Epoch 221/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.5280 - mse: 3.1477 - mae: 1.4040\n",
            "Epoch 222/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1737 - mse: 3.7940 - mae: 1.5623\n",
            "Epoch 223/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.6231 - mse: 3.2439 - mae: 1.4089\n",
            "Epoch 224/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9266 - mse: 3.5479 - mae: 1.5042\n",
            "Epoch 225/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5610 - mse: 3.1828 - mae: 1.4258\n",
            "Epoch 226/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8744 - mse: 3.4967 - mae: 1.4699\n",
            "Epoch 227/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4257 - mse: 3.0486 - mae: 1.3482\n",
            "Epoch 228/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.8717 - mse: 3.4949 - mae: 1.4684\n",
            "Epoch 229/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7924 - mse: 3.4160 - mae: 1.4525\n",
            "Epoch 230/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.9366 - mse: 3.5607 - mae: 1.4793\n",
            "Epoch 231/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9186 - mse: 3.5432 - mae: 1.4912\n",
            "Epoch 232/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7704 - mse: 3.3955 - mae: 1.4423\n",
            "Epoch 233/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.6139 - mse: 3.2395 - mae: 1.4036\n",
            "Epoch 234/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.7954 - mse: 3.4214 - mae: 1.4839\n",
            "Epoch 235/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7313 - mse: 3.3577 - mae: 1.4792\n",
            "Epoch 236/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.5383 - mse: 4.1652 - mae: 1.6144\n",
            "Epoch 237/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7395 - mse: 3.3668 - mae: 1.4452\n",
            "Epoch 238/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8395 - mse: 3.4673 - mae: 1.4774\n",
            "Epoch 239/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9612 - mse: 3.5894 - mae: 1.4862\n",
            "Epoch 240/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2776 - mse: 2.9063 - mae: 1.3631\n",
            "Epoch 241/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.2311 - mse: 3.8601 - mae: 1.5442\n",
            "Epoch 242/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8615 - mse: 3.4909 - mae: 1.4906\n",
            "Epoch 243/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5234 - mse: 3.1533 - mae: 1.4186\n",
            "Epoch 244/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7150 - mse: 3.3452 - mae: 1.4548\n",
            "Epoch 245/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8326 - mse: 3.4632 - mae: 1.4837\n",
            "Epoch 246/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6226 - mse: 3.2536 - mae: 1.4074\n",
            "Epoch 247/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5237 - mse: 3.1551 - mae: 1.4036\n",
            "Epoch 248/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.9700 - mse: 3.6018 - mae: 1.5170\n",
            "Epoch 249/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.9780 - mse: 3.6103 - mae: 1.5289\n",
            "Epoch 250/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9323 - mse: 3.5650 - mae: 1.4764\n",
            "Epoch 251/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6159 - mse: 3.2490 - mae: 1.4052\n",
            "Epoch 252/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7302 - mse: 3.3638 - mae: 1.4648\n",
            "Epoch 253/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7102 - mse: 3.3442 - mae: 1.4260\n",
            "Epoch 254/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7533 - mse: 3.3876 - mae: 1.4735\n",
            "Epoch 255/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8342 - mse: 3.4689 - mae: 1.4739\n",
            "Epoch 256/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8745 - mse: 3.5096 - mae: 1.4879\n",
            "Epoch 257/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7270 - mse: 3.3624 - mae: 1.4658\n",
            "Epoch 258/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5344 - mse: 3.1702 - mae: 1.4167\n",
            "Epoch 259/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7262 - mse: 3.3625 - mae: 1.4736\n",
            "Epoch 260/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8115 - mse: 3.4482 - mae: 1.4965\n",
            "Epoch 261/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1732 - mse: 3.8104 - mae: 1.5810\n",
            "Epoch 262/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5498 - mse: 3.1872 - mae: 1.4347\n",
            "Epoch 263/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5881 - mse: 3.2259 - mae: 1.3973\n",
            "Epoch 264/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.5488 - mse: 3.1870 - mae: 1.3908\n",
            "Epoch 265/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9404 - mse: 3.5790 - mae: 1.4757\n",
            "Epoch 266/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7400 - mse: 3.3789 - mae: 1.4549\n",
            "Epoch 267/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6144 - mse: 3.2537 - mae: 1.4511\n",
            "Epoch 268/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5840 - mse: 3.2237 - mae: 1.4166\n",
            "Epoch 269/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8888 - mse: 3.5287 - mae: 1.5109\n",
            "Epoch 270/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7729 - mse: 3.4131 - mae: 1.4820\n",
            "Epoch 271/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5099 - mse: 3.1505 - mae: 1.4164\n",
            "Epoch 272/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5251 - mse: 3.1661 - mae: 1.4339\n",
            "Epoch 273/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7649 - mse: 3.4062 - mae: 1.4729\n",
            "Epoch 274/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5381 - mse: 3.1797 - mae: 1.4198\n",
            "Epoch 275/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5682 - mse: 3.2102 - mae: 1.4296\n",
            "Epoch 276/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8484 - mse: 3.4907 - mae: 1.4761\n",
            "Epoch 277/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8015 - mse: 3.4441 - mae: 1.4712\n",
            "Epoch 278/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5093 - mse: 3.1523 - mae: 1.4238\n",
            "Epoch 279/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8300 - mse: 3.4733 - mae: 1.4975\n",
            "Epoch 280/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7185 - mse: 3.3622 - mae: 1.4598\n",
            "Epoch 281/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4069 - mse: 3.0508 - mae: 1.3830\n",
            "Epoch 282/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.0543 - mse: 3.6986 - mae: 1.5551\n",
            "Epoch 283/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1885 - mse: 3.8330 - mae: 1.5618\n",
            "Epoch 284/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.8625 - mse: 3.5073 - mae: 1.4883\n",
            "Epoch 285/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.0769 - mse: 3.7221 - mae: 1.5312\n",
            "Epoch 286/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7914 - mse: 3.4370 - mae: 1.4931\n",
            "Epoch 287/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.6359 - mse: 3.2818 - mae: 1.4378\n",
            "Epoch 288/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1420 - mse: 3.7883 - mae: 1.5652\n",
            "Epoch 289/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5693 - mse: 3.2160 - mae: 1.3966\n",
            "Epoch 290/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9549 - mse: 3.6018 - mae: 1.5132\n",
            "Epoch 291/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7263 - mse: 3.3736 - mae: 1.4999\n",
            "Epoch 292/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8553 - mse: 3.5029 - mae: 1.4799\n",
            "Epoch 293/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.6886 - mse: 3.3364 - mae: 1.4209\n",
            "Epoch 294/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.5392 - mse: 3.1874 - mae: 1.4238\n",
            "Epoch 295/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.3896 - mse: 3.0381 - mae: 1.3771\n",
            "Epoch 296/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5717 - mse: 3.2206 - mae: 1.4353\n",
            "Epoch 297/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6286 - mse: 3.2778 - mae: 1.4232\n",
            "Epoch 298/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2213 - mse: 2.8708 - mae: 1.3231\n",
            "Epoch 299/550\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.2167 - mse: 2.8665 - mae: 1.3300\n",
            "Epoch 300/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6932 - mse: 3.3433 - mae: 1.4221\n",
            "Epoch 301/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7720 - mse: 3.4225 - mae: 1.4719\n",
            "Epoch 302/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5199 - mse: 3.1707 - mae: 1.4245\n",
            "Epoch 303/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5673 - mse: 3.2184 - mae: 1.4077\n",
            "Epoch 304/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6486 - mse: 3.3001 - mae: 1.4426\n",
            "Epoch 305/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4774 - mse: 3.1293 - mae: 1.3924\n",
            "Epoch 306/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8552 - mse: 3.5074 - mae: 1.4954\n",
            "Epoch 307/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8459 - mse: 3.4984 - mae: 1.4888\n",
            "Epoch 308/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6090 - mse: 3.2618 - mae: 1.4104\n",
            "Epoch 309/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4916 - mse: 3.1447 - mae: 1.4331\n",
            "Epoch 310/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4872 - mse: 3.1407 - mae: 1.4165\n",
            "Epoch 311/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.3263 - mse: 2.9800 - mae: 1.3698\n",
            "Epoch 312/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9565 - mse: 3.6106 - mae: 1.4842\n",
            "Epoch 313/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.0765 - mse: 3.7308 - mae: 1.5488\n",
            "Epoch 314/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.5774 - mse: 3.2320 - mae: 1.4290\n",
            "Epoch 315/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5065 - mse: 3.1613 - mae: 1.4011\n",
            "Epoch 316/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7015 - mse: 3.3566 - mae: 1.4601\n",
            "Epoch 317/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7774 - mse: 3.4329 - mae: 1.4959\n",
            "Epoch 318/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5526 - mse: 3.2085 - mae: 1.4359\n",
            "Epoch 319/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4665 - mse: 3.1227 - mae: 1.4135\n",
            "Epoch 320/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8785 - mse: 3.5350 - mae: 1.4800\n",
            "Epoch 321/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7147 - mse: 3.3714 - mae: 1.4686\n",
            "Epoch 322/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7156 - mse: 3.3726 - mae: 1.4570\n",
            "Epoch 323/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7977 - mse: 3.4549 - mae: 1.4718\n",
            "Epoch 324/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7194 - mse: 3.3770 - mae: 1.4519\n",
            "Epoch 325/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.3824 - mse: 3.0402 - mae: 1.4021\n",
            "Epoch 326/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9425 - mse: 3.6006 - mae: 1.5066\n",
            "Epoch 327/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4571 - mse: 3.1154 - mae: 1.4198\n",
            "Epoch 328/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5245 - mse: 3.1830 - mae: 1.3994\n",
            "Epoch 329/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.0190 - mse: 3.6778 - mae: 1.5154\n",
            "Epoch 330/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3225 - mse: 2.9817 - mae: 1.3889\n",
            "Epoch 331/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5279 - mse: 3.1873 - mae: 1.4243\n",
            "Epoch 332/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3197 - mse: 2.9794 - mae: 1.3513\n",
            "Epoch 333/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6907 - mse: 3.3507 - mae: 1.4666\n",
            "Epoch 334/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8119 - mse: 3.4722 - mae: 1.4494\n",
            "Epoch 335/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.8275 - mse: 3.4881 - mae: 1.5209\n",
            "Epoch 336/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.4212 - mse: 3.0820 - mae: 1.4088\n",
            "Epoch 337/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5030 - mse: 3.1641 - mae: 1.4031\n",
            "Epoch 338/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4056 - mse: 3.0670 - mae: 1.4097\n",
            "Epoch 339/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9459 - mse: 3.6075 - mae: 1.5066\n",
            "Epoch 340/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5409 - mse: 3.2028 - mae: 1.4247\n",
            "Epoch 341/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.6341 - mse: 3.2962 - mae: 1.4593\n",
            "Epoch 342/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4197 - mse: 3.0819 - mae: 1.4012\n",
            "Epoch 343/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7082 - mse: 3.3706 - mae: 1.4648\n",
            "Epoch 344/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3762 - mse: 3.0389 - mae: 1.3771\n",
            "Epoch 345/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4962 - mse: 3.1591 - mae: 1.3869\n",
            "Epoch 346/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6223 - mse: 3.2854 - mae: 1.4266\n",
            "Epoch 347/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4221 - mse: 3.0856 - mae: 1.3999\n",
            "Epoch 348/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8098 - mse: 3.4736 - mae: 1.4991\n",
            "Epoch 349/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6545 - mse: 3.3186 - mae: 1.4392\n",
            "Epoch 350/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6765 - mse: 3.3409 - mae: 1.4487\n",
            "Epoch 351/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.8598 - mse: 3.5244 - mae: 1.5160\n",
            "Epoch 352/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5898 - mse: 3.2547 - mae: 1.4493\n",
            "Epoch 353/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6813 - mse: 3.3464 - mae: 1.4376\n",
            "Epoch 354/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5364 - mse: 3.2018 - mae: 1.4407\n",
            "Epoch 355/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6101 - mse: 3.2757 - mae: 1.4415\n",
            "Epoch 356/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5689 - mse: 3.2347 - mae: 1.4401\n",
            "Epoch 357/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6469 - mse: 3.3129 - mae: 1.4469\n",
            "Epoch 358/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3016 - mse: 2.9679 - mae: 1.3325\n",
            "Epoch 359/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.6210 - mse: 3.2876 - mae: 1.4450\n",
            "Epoch 360/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4099 - mse: 3.0768 - mae: 1.3972\n",
            "Epoch 361/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.3549 - mse: 3.0221 - mae: 1.3848\n",
            "Epoch 362/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4918 - mse: 3.1594 - mae: 1.4254\n",
            "Epoch 363/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.6145 - mse: 3.2823 - mae: 1.4388\n",
            "Epoch 364/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7709 - mse: 3.4389 - mae: 1.4343\n",
            "Epoch 365/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.7483 - mse: 3.4166 - mae: 1.4720\n",
            "Epoch 366/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8297 - mse: 3.4981 - mae: 1.4692\n",
            "Epoch 367/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4153 - mse: 3.0839 - mae: 1.3979\n",
            "Epoch 368/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5545 - mse: 3.2233 - mae: 1.4232\n",
            "Epoch 369/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4662 - mse: 3.1351 - mae: 1.4461\n",
            "Epoch 370/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8504 - mse: 3.5195 - mae: 1.4850\n",
            "Epoch 371/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5593 - mse: 3.2286 - mae: 1.4236\n",
            "Epoch 372/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1366 - mse: 3.8061 - mae: 1.5789\n",
            "Epoch 373/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3891 - mse: 3.0587 - mae: 1.3810\n",
            "Epoch 374/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.7846 - mse: 3.4542 - mae: 1.4524\n",
            "Epoch 375/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6914 - mse: 3.3614 - mae: 1.4361\n",
            "Epoch 376/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.9050 - mse: 3.5752 - mae: 1.4903\n",
            "Epoch 377/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4849 - mse: 3.1553 - mae: 1.4113\n",
            "Epoch 378/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8728 - mse: 3.5433 - mae: 1.5306\n",
            "Epoch 379/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.7556 - mse: 3.4263 - mae: 1.4767\n",
            "Epoch 380/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5933 - mse: 3.2643 - mae: 1.4108\n",
            "Epoch 381/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6060 - mse: 3.2773 - mae: 1.4213\n",
            "Epoch 382/550\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.8618 - mse: 3.5333 - mae: 1.4894\n",
            "Epoch 383/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6290 - mse: 3.3007 - mae: 1.4373\n",
            "Epoch 384/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5347 - mse: 3.2066 - mae: 1.4282\n",
            "Epoch 385/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2103 - mse: 2.8825 - mae: 1.3548\n",
            "Epoch 386/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.0727 - mse: 3.7452 - mae: 1.5685\n",
            "Epoch 387/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9653 - mse: 3.6380 - mae: 1.5317\n",
            "Epoch 388/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.0065 - mse: 3.6793 - mae: 1.5370\n",
            "Epoch 389/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3103 - mse: 2.9833 - mae: 1.3497\n",
            "Epoch 390/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6779 - mse: 3.3511 - mae: 1.4891\n",
            "Epoch 391/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5800 - mse: 3.2535 - mae: 1.4469\n",
            "Epoch 392/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4542 - mse: 3.1280 - mae: 1.4090\n",
            "Epoch 393/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5394 - mse: 3.2134 - mae: 1.4322\n",
            "Epoch 394/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6199 - mse: 3.2940 - mae: 1.4360\n",
            "Epoch 395/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2179 - mse: 2.8923 - mae: 1.3560\n",
            "Epoch 396/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.6895 - mse: 3.3640 - mae: 1.4864\n",
            "Epoch 397/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5887 - mse: 3.2633 - mae: 1.4468\n",
            "Epoch 398/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.4408 - mse: 3.1155 - mae: 1.4062\n",
            "Epoch 399/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6569 - mse: 3.3319 - mae: 1.4376\n",
            "Epoch 400/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6711 - mse: 3.3464 - mae: 1.4378\n",
            "Epoch 401/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3591 - mse: 3.0345 - mae: 1.4000\n",
            "Epoch 402/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7975 - mse: 3.4732 - mae: 1.4689\n",
            "Epoch 403/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6121 - mse: 3.2881 - mae: 1.4869\n",
            "Epoch 404/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3039 - mse: 2.9801 - mae: 1.3962\n",
            "Epoch 405/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7466 - mse: 3.4231 - mae: 1.4839\n",
            "Epoch 406/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.8018 - mse: 3.4784 - mae: 1.4323\n",
            "Epoch 407/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6986 - mse: 3.3754 - mae: 1.4554\n",
            "Epoch 408/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5145 - mse: 3.1915 - mae: 1.4087\n",
            "Epoch 409/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.1683 - mse: 2.8454 - mae: 1.3354\n",
            "Epoch 410/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3311 - mse: 3.0084 - mae: 1.3901\n",
            "Epoch 411/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4299 - mse: 3.1075 - mae: 1.4239\n",
            "Epoch 412/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6623 - mse: 3.3401 - mae: 1.4790\n",
            "Epoch 413/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4063 - mse: 3.0844 - mae: 1.3731\n",
            "Epoch 414/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.3972 - mse: 3.0755 - mae: 1.3979\n",
            "Epoch 415/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4190 - mse: 3.0977 - mae: 1.4166\n",
            "Epoch 416/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7043 - mse: 3.3833 - mae: 1.4748\n",
            "Epoch 417/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4753 - mse: 3.1546 - mae: 1.4363\n",
            "Epoch 418/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6296 - mse: 3.3091 - mae: 1.4750\n",
            "Epoch 419/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6200 - mse: 3.2998 - mae: 1.4189\n",
            "Epoch 420/550\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.9536 - mse: 3.6336 - mae: 1.5103\n",
            "Epoch 421/550\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.4249 - mse: 3.1051 - mae: 1.4195\n",
            "Epoch 422/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4472 - mse: 3.1276 - mae: 1.4030\n",
            "Epoch 423/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5577 - mse: 3.2381 - mae: 1.4450\n",
            "Epoch 424/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5963 - mse: 3.2767 - mae: 1.4461\n",
            "Epoch 425/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5892 - mse: 3.2696 - mae: 1.4367\n",
            "Epoch 426/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.6030 - mse: 3.2836 - mae: 1.4639\n",
            "Epoch 427/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7540 - mse: 3.4347 - mae: 1.4907\n",
            "Epoch 428/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4772 - mse: 3.1579 - mae: 1.4043\n",
            "Epoch 429/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.8598 - mse: 3.5406 - mae: 1.5293\n",
            "Epoch 430/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8648 - mse: 3.5458 - mae: 1.4793\n",
            "Epoch 431/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.0536 - mse: 3.7348 - mae: 1.5383\n",
            "Epoch 432/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3294 - mse: 3.0108 - mae: 1.3889\n",
            "Epoch 433/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6739 - mse: 3.3554 - mae: 1.4943\n",
            "Epoch 434/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5829 - mse: 3.2647 - mae: 1.4534\n",
            "Epoch 435/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3572 - mse: 3.0393 - mae: 1.3750\n",
            "Epoch 436/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8586 - mse: 3.5409 - mae: 1.4815\n",
            "Epoch 437/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.3239 - mse: 3.0065 - mae: 1.3821\n",
            "Epoch 438/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5369 - mse: 3.2198 - mae: 1.4468\n",
            "Epoch 439/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7171 - mse: 3.4003 - mae: 1.4535\n",
            "Epoch 440/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3960 - mse: 3.0795 - mae: 1.3849\n",
            "Epoch 441/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.7401 - mse: 3.4238 - mae: 1.4551\n",
            "Epoch 442/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5959 - mse: 3.2798 - mae: 1.4404\n",
            "Epoch 443/550\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.7168 - mse: 3.4009 - mae: 1.4628\n",
            "Epoch 444/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.0790 - mse: 2.7632 - mae: 1.3142\n",
            "Epoch 445/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6071 - mse: 3.2914 - mae: 1.4681\n",
            "Epoch 446/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4509 - mse: 3.1353 - mae: 1.4167\n",
            "Epoch 447/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6813 - mse: 3.3658 - mae: 1.4309\n",
            "Epoch 448/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5034 - mse: 3.1882 - mae: 1.4209\n",
            "Epoch 449/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4882 - mse: 3.1732 - mae: 1.4256\n",
            "Epoch 450/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5213 - mse: 3.2064 - mae: 1.3994\n",
            "Epoch 451/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6535 - mse: 3.3388 - mae: 1.4473\n",
            "Epoch 452/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4649 - mse: 3.1504 - mae: 1.4439\n",
            "Epoch 453/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2119 - mse: 2.8977 - mae: 1.3591\n",
            "Epoch 454/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6092 - mse: 3.2951 - mae: 1.4688\n",
            "Epoch 455/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6500 - mse: 3.3361 - mae: 1.4292\n",
            "Epoch 456/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6929 - mse: 3.3793 - mae: 1.4389\n",
            "Epoch 457/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4229 - mse: 3.1097 - mae: 1.4117\n",
            "Epoch 458/550\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.7362 - mse: 3.4231 - mae: 1.4771\n",
            "Epoch 459/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4330 - mse: 3.1201 - mae: 1.4071\n",
            "Epoch 460/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8166 - mse: 3.5039 - mae: 1.4898\n",
            "Epoch 461/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5146 - mse: 3.2019 - mae: 1.4818\n",
            "Epoch 462/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8529 - mse: 3.5404 - mae: 1.4834\n",
            "Epoch 463/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5712 - mse: 3.2588 - mae: 1.4661\n",
            "Epoch 464/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6037 - mse: 3.2914 - mae: 1.4580\n",
            "Epoch 465/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4102 - mse: 3.0981 - mae: 1.3733\n",
            "Epoch 466/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.3357 - mse: 3.0237 - mae: 1.3872\n",
            "Epoch 467/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6634 - mse: 3.3515 - mae: 1.4633\n",
            "Epoch 468/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6074 - mse: 3.2957 - mae: 1.4562\n",
            "Epoch 469/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2935 - mse: 2.9821 - mae: 1.3796\n",
            "Epoch 470/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.0980 - mse: 3.7867 - mae: 1.5530\n",
            "Epoch 471/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5253 - mse: 3.2142 - mae: 1.4411\n",
            "Epoch 472/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6239 - mse: 3.3130 - mae: 1.4254\n",
            "Epoch 473/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3528 - mse: 3.0420 - mae: 1.3961\n",
            "Epoch 474/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.3885 - mse: 3.0778 - mae: 1.3952\n",
            "Epoch 475/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5385 - mse: 3.2278 - mae: 1.4643\n",
            "Epoch 476/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2792 - mse: 2.9686 - mae: 1.3625\n",
            "Epoch 477/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5457 - mse: 3.2354 - mae: 1.4216\n",
            "Epoch 478/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7654 - mse: 3.4554 - mae: 1.5116\n",
            "Epoch 479/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.1183 - mse: 2.8085 - mae: 1.3331\n",
            "Epoch 480/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4872 - mse: 3.1777 - mae: 1.4431\n",
            "Epoch 481/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6679 - mse: 3.3587 - mae: 1.4791\n",
            "Epoch 482/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6009 - mse: 3.2920 - mae: 1.4100\n",
            "Epoch 483/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4334 - mse: 3.1246 - mae: 1.4088\n",
            "Epoch 484/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7947 - mse: 3.4861 - mae: 1.5046\n",
            "Epoch 485/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7118 - mse: 3.4035 - mae: 1.4834\n",
            "Epoch 486/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4939 - mse: 3.1858 - mae: 1.4114\n",
            "Epoch 487/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5540 - mse: 3.2462 - mae: 1.4414\n",
            "Epoch 488/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.9051 - mse: 3.5974 - mae: 1.4895\n",
            "Epoch 489/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2852 - mse: 2.9777 - mae: 1.4068\n",
            "Epoch 490/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.3329 - mse: 3.0256 - mae: 1.3956\n",
            "Epoch 491/550\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.0818 - mse: 2.7747 - mae: 1.3225\n",
            "Epoch 492/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6704 - mse: 3.3635 - mae: 1.4873\n",
            "Epoch 493/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7857 - mse: 3.4788 - mae: 1.4935\n",
            "Epoch 494/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4217 - mse: 3.1149 - mae: 1.4020\n",
            "Epoch 495/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.1899 - mse: 2.8831 - mae: 1.3647\n",
            "Epoch 496/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7354 - mse: 3.4287 - mae: 1.4848\n",
            "Epoch 497/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4465 - mse: 3.1398 - mae: 1.4057\n",
            "Epoch 498/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4037 - mse: 3.0971 - mae: 1.4183\n",
            "Epoch 499/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4698 - mse: 3.1633 - mae: 1.4170\n",
            "Epoch 500/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5221 - mse: 3.2158 - mae: 1.3952\n",
            "Epoch 501/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9511 - mse: 3.6450 - mae: 1.5166\n",
            "Epoch 502/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7081 - mse: 3.4022 - mae: 1.4820\n",
            "Epoch 503/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5664 - mse: 3.2608 - mae: 1.4327\n",
            "Epoch 504/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3995 - mse: 3.0941 - mae: 1.3786\n",
            "Epoch 505/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6114 - mse: 3.3061 - mae: 1.4596\n",
            "Epoch 506/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5137 - mse: 3.2087 - mae: 1.4095\n",
            "Epoch 507/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6280 - mse: 3.3233 - mae: 1.4260\n",
            "Epoch 508/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.2297 - mse: 2.9252 - mae: 1.3792\n",
            "Epoch 509/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.0593 - mse: 2.7550 - mae: 1.3249\n",
            "Epoch 510/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8925 - mse: 3.5884 - mae: 1.5273\n",
            "Epoch 511/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7249 - mse: 3.4210 - mae: 1.4679\n",
            "Epoch 512/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5565 - mse: 3.2527 - mae: 1.4359\n",
            "Epoch 513/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4703 - mse: 3.1668 - mae: 1.3896\n",
            "Epoch 514/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.6988 - mse: 3.3954 - mae: 1.4715\n",
            "Epoch 515/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6575 - mse: 3.3541 - mae: 1.4651\n",
            "Epoch 516/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3798 - mse: 3.0765 - mae: 1.3902\n",
            "Epoch 517/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5136 - mse: 3.2106 - mae: 1.4353\n",
            "Epoch 518/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4547 - mse: 3.1520 - mae: 1.4195\n",
            "Epoch 519/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4814 - mse: 3.1791 - mae: 1.4408\n",
            "Epoch 520/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.6050 - mse: 3.3031 - mae: 1.4413\n",
            "Epoch 521/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3467 - mse: 3.0451 - mae: 1.4034\n",
            "Epoch 522/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4706 - mse: 3.1691 - mae: 1.4207\n",
            "Epoch 523/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7905 - mse: 3.4890 - mae: 1.5254\n",
            "Epoch 524/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.5924 - mse: 3.2909 - mae: 1.4397\n",
            "Epoch 525/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4492 - mse: 3.1479 - mae: 1.4374\n",
            "Epoch 526/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6438 - mse: 3.3427 - mae: 1.4734\n",
            "Epoch 527/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5215 - mse: 3.2207 - mae: 1.4146\n",
            "Epoch 528/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4564 - mse: 3.1558 - mae: 1.4051\n",
            "Epoch 529/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5097 - mse: 3.2091 - mae: 1.4344\n",
            "Epoch 530/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5886 - mse: 3.2880 - mae: 1.4203\n",
            "Epoch 531/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.3911 - mse: 3.0905 - mae: 1.3981\n",
            "Epoch 532/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3339 - mse: 3.0334 - mae: 1.3919\n",
            "Epoch 533/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4482 - mse: 3.1478 - mae: 1.4504\n",
            "Epoch 534/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5561 - mse: 3.2560 - mae: 1.4542\n",
            "Epoch 535/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4969 - mse: 3.1971 - mae: 1.3959\n",
            "Epoch 536/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2780 - mse: 2.9784 - mae: 1.3705\n",
            "Epoch 537/550\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.4566 - mse: 3.1570 - mae: 1.4279\n",
            "Epoch 538/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5357 - mse: 3.2363 - mae: 1.4566\n",
            "Epoch 539/550\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.4173 - mse: 3.1181 - mae: 1.4024\n",
            "Epoch 540/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7931 - mse: 3.4942 - mae: 1.4816\n",
            "Epoch 541/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6218 - mse: 3.3231 - mae: 1.4781\n",
            "Epoch 542/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6026 - mse: 3.3041 - mae: 1.4614\n",
            "Epoch 543/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2021 - mse: 2.9038 - mae: 1.3706\n",
            "Epoch 544/550\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4829 - mse: 3.1846 - mae: 1.4209\n",
            "Epoch 545/550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.5764 - mse: 3.2783 - mae: 1.4515\n",
            "Epoch 546/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9270 - mse: 3.6291 - mae: 1.5398\n",
            "Epoch 547/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9150 - mse: 3.6173 - mae: 1.4964\n",
            "Epoch 548/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5248 - mse: 3.2273 - mae: 1.4272\n",
            "Epoch 549/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8491 - mse: 3.5517 - mae: 1.4920\n",
            "Epoch 550/550\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4370 - mse: 3.1400 - mae: 1.4228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f558c9d35d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "zFBQZ79ontDV",
        "outputId": "6aba0b5f-b53e-4e6e-dc65-8e928f8f9ede"
      },
      "source": [
        "plt.scatter(x_test, model.predict(x_test));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5595057f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gOvhyGHvpWKE",
        "outputId": "82876604-6281-4148-a00e-ed75fc1356cc"
      },
      "source": [
        "plt.scatter(x_test, y_test);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "Cpnr9saSvhVk",
        "outputId": "7a2a9e79-5f07-47d2-8895-8a7f448b162d"
      },
      "source": [
        "# Another way to visualize the mode\n",
        "from tensorflow.keras.utils import plot_model, Progbar\n",
        "plot_model(model, show_shapes = True, show_dtype = True, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAGVCAIAAABcpz4AAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdaUAUV9Y4/FvQTW90A8oqgrKIBIPbaAZQhklISJQBBSS2BiP6xAc1kcUlCIoioAnqIINCHKOSTExkk0GiEo0x6PgETSaKGpwoYpDFhUV2Gmig3g/3Tf1rGmiaprfC8/tkLX373OrmWH3r1imCJEkEAACAsfS0HQAAAIBRgTwOAADMBnkcAACYDfI4AAAwG4u+UFJSkpKSoq1QAAAAKMLd3X3jxo3U4n+dj1dXV+fl5Wk8JACGkZeXV1NTo+0o1OtF6CNC6Nq1a9euXdN2FMx27dq1kpIS+hrWwJ1yc3M1FQ8ACiEIIioq6u2339Z2IGr0IvQRIRQcHIwgyYwOPoZ0MD4OAADMBnkcAACYDfI4AAAwG+RxAABgNsjjAADAbJDHAWCwc+fOGRkZff3119oORMXWrl1L/C4kJIS+6eLFizExMadOnbK3t8c7rFixgr6Dj4+PUCjU19efNm3ajRs3NBv4f+nv7z9w4ICHhwd9ZWFhYXJycl9fH7WmoKCA6qypqakSbwR5HAAGG8P1SseNG1dUVHTv3r1jx45RK3fu3JmWlhYbGxsUFPTw4UMHB4fx48efOHHi7Nmz1D4XLlzIzc318/MrKyubPXu2NmJHCKHy8vI//elPGzdu7OzspK/39/fncrne3t7Nzc14zaJFi2pqaq5cubJw4ULl3gvyOAAM5uvr29LS4ufnp+43kkgkMueV6sbj8d566y0nJycOh4PXfPzxx1lZWTk5OUKhkNotLS1NT08vLCyspaVFk+HJd+vWra1bt65bt27mzJkDt0ZERMyYMWPhwoW9vb0IIYIgrK2tPT09p0yZotzbQR4HAAzv2LFjdXV1WgzgwYMHcXFxu3bt4nK59PUeHh6RkZG1tbWbN2/WVmwDzZgx49SpU++88w71n5CM+Pj40tLS1NRUlbwd5HEAmOrq1au2trYEQRw6dAghlJGRIRAI+Hz+6dOnFyxYIBKJJk6cePLkSbxzWloal8s1Nzdfu3atlZUVl8v18PC4fv063hoeHm5gYGBpaYkX33//fYFAQBBEQ0MDQigyMnLTpk0VFRUEQTg6OiKEvvnmG5FItHv3bo11Ni0tjSRJf3//gZuSkpKcnJyOHj168eLFQV9LkmRKSspLL73E4XBMTEwWL17866+/4k3yDxpCqK+vb8eOHba2tjweb/r06dnZ2SrpjomJiZeXV2pqqkpGxiCPA8BU8+fP/+GHH6jF9evXR0VFSSQSoVCYnZ1dUVFhb2+/Zs0aqVSKEAoPDw8NDe3s7IyIiKisrLxx40Zvb+8bb7xRXV2NEEpLS6OXBEhPT9+1axe1mJqa6ufn5+DgQJLkgwcPEEL4Ml1/f7/GOnv27NmpU6fy+fyBm3g83meffaanp7dmzZqOjo6BO8THx8fExGzbtq2uru7KlSvV1dWenp7Pnj1Dwx00hNDWrVv37t174MCBJ0+e+Pn5LV++/N///rdKejRr1qza2tpbt26NvinI4wCMNR4eHiKRyMzMTCwWd3R0VFVVUZtYLBY+LXVxccnIyGhra8vMzFTiLXx9fVtbW+Pi4lQXtTwdHR2//fabg4PDUDu4u7tHRUVVVlZu3bpVZpNEIklJSQkMDAwJCTEyMnJ1dT18+HBDQ8ORI0fouw160Lq6ujIyMgICAoKCgoyNjbdv385ms5U7YgPh0fA7d+6MvinI4wCMWQYGBggh6tRSxpw5c/h8PjXCoMvq6upIkhz0ZJySlJQ0derU9PT0q1ev0teXlZW1t7fPmTOHWjN37lwDAwNqTEkG/aDdu3evs7Pz5Zdfxpt4PJ6lpaWqjhjuDv5ZMEqQxwF4cXE4nPr6em1HMbyuri6E0FDXDDEul5uZmUkQxOrVqyUSCbUeT+8zNDSk72xsbNzW1jbs++JRmu3bt1Pzux89eiQzj1BpPB4P/d61UYI8DsALSiqVNjc3T5w4UduBDA+nPPq9M4PCT1coLy9PTEykVhobGyOEZLK2gh03MzNDCB04cICkkan9rbSenh70e9dGCfI4AC+o4uJikiTd3NzwIovFGmoERuvMzc0JglBkhnhiYqKzs/PNmzepNS+//LKhoSH94uT169d7enr+8Ic/DNuajY0Nl8stLS1VLmz5cHcsLCxG3xTkcQBeIP39/U1NTb29vbdv346MjLS1tQ0NDcWbHB0dnz9/XlBQIJVK6+vrHz16RH/huHHjHj9+XFlZ2dbWJpVKi4qKNDnvkM/n29vbK/K8JDy6oq+vT1+zadOm/Pz8EydOtLa23rlzZ926dVZWVmFhYYq0tmrVqpMnT2ZkZLS2tvb19dXU1Dx58gQhJBaLLSwsRnPfP+6Oq6ur0i1QII8DwFSHDh2aO3cuQig6OnrRokUZGRkHDhxACE2fPv3hw4effvrppk2bEEJvvfVWeXk5fklXV5erqyuPx/P09HRycvr++++pQef169e/+uqry5Ytmzp1amJiIv697+7ujicmrlu3ztzc3MXFZeHChc+fP9d8Z319fcvKyqiB73/+85+Ojo4VFRVz587dsGEDfU83Nzf6sysRQjt37tyzZ09CQoKpqamXl9fkyZOLi4sFAgFCaNiDlpqaGhUVlZycPH78eCsrq8jIyKamJoRQT09PXV3d6dOnB4322rVr8+fPnzBhwvXr12/dumVlZTVv3rwrV67Q9/npp5+sra2nT5+ugqNDH/fBU9xJAHQMQig7O1vbUaiXBvoYFhY2btw4tb7FsJYsWbJkyZJhdwsLC7O2tqavKS8vZ7FYX3zxhdpCG5m+vj5PT89jx44p9/KGhgYul7t//376yoiIiPHjxw/72oHHEM7HAXiBDHupUHdIJJLz58+Xl5fj64GOjo4JCQkJCQnt7e3aDg319fUVFBS0tbWJxWLlWoiPj585c2Z4eDhCiCTJx48fX716Fd9jpQTI4wAAXfT8+XNcJ2v16tV4TUxMTHBwsFgs1npJrOLi4lOnThUVFcmf0j6UlJSU0tLSc+fOsdlshNDp06dxnSx61cYRGXEep5f9tbS0lCkNrGGDlvcdlg6WbL527dpLL72kp6dHEISFhUVSUpLG3lqnPtBR6u7ujoiIsLS05PP5r7/+Op7kcPjwYRW+RXJysrOzM4/HEwgEzs7OcXFxra2t1NaEhAQXFxeRSMThcBwdHT/88ENdOHnEYmNjMzMzW1pa7Ozs8vLytB3OMA4fPkwNGpw4cYJav3v37vDw8I8++kiLsSGEvL29v/zyS6oczYicPn26u7u7uLjYxMQEr1m8eDF9vEWZgOiDLIqPjzs4OBgZGSmyp/rcv39/3rx5CKEZM2aM6IVnzpwRiUSFhYVqCkxpb775JkKoqalJ82+tCx+oHEixsePdu3c7OTk1NTX9/e9/z83NxdepPvnkExVG4uvru3///rq6ura2tpycHDab/cYbb1Bbvby80tPTGxsbW1tbs7Oz2Wz2W2+9pWDLCvaR6RQcHwdyjJ3xcfnlfeUbwyWbFaSzgY1SQUHBnDlzjI2N//d//3fJkiUqaVPmWBkYGLz//vtmZmaGhobBwcGLFy/+9ttv8UQ0hJChoSG+ligUCt9+++2AgIBvvvkGz/cAQH2YmseHLe+rC7ResnkoOhvYKNXU1OABRxWSOVb5+fn0+tfW1tYIIWrw5MyZM/SZy/gZXaq6jRuAoagrj//rX/9ycXExMjLicrmurq7nz59HCL333nt4HNbBwQHfcLVq1So+n29kZFRYWIiGKPW7d+9ePp8vFArr6uo2bdpkbW197949pQNjSslmTQamCJ39QLFvv/3W0dHxyZMnn3/+OUEQMsU0MHLoItRDdXDYY1VeXm5sbDxp0qRBo6qtreXxeHZ2dqPsHQDDoA+yqHB8PDc3Nz4+/vnz542NjW5ubtSkyKCgIH19/draWmrP5cuXU0PVmzdv5nA4eXl5TU1NsbGxenp6P/30E0mS27ZtQwhFREQcPHgwMDDwP//5D/XyP/7xjyMdH8e/cw8ePIgXcePfffddS0tLXV2dp6enQCDo6enBW8PCwgQCwd27d7u6usrKyubOnSsUCquqqvDWd955x8LCgmp53759CKH6+nqqs7hkM3bmzBmhUJiQkDBUYDLj4xoLjNSlD3RQSLGxYwsLi5UrV1KLMuPjO3bsMDAw+OKLL5qbm2/fvj179mxTU9OnT58O20GZY0WSZE9PT01NzcGDBzkczlAzmjs6OoRCYXh4+LBhj6iPTAfj46M38Bhq4jrnnj170O+VJ/EDO5KSkvCmlpaWKVOm9Pb2kiQpkUj4fL5YLMabOjs7ORzO+vXryd//7CUSycDGVZXHqcbT09MRQg8ePMCLYWFh9J7+9NNPCKFdu3bhxZGmS/kGzeOaCUx3PtBBjT6Pd3Z2GhoaUsGQJPnjjz8ihAb9b5XewUE/RFwTY/z48X/729+o/1llbNu2zcnJqbW1dfjukSQJeRwoTDvXOfGQJb4B4bXXXnNycjp+/DhJkgihrKwssViMhxTVWupXcTpbsll3AmPWB4qNqAg1vYODqq6urqur++qrrz7//PNZs2YNvNiQn5+fk5Nz/vx5+hOBh7V06VJirMvLy8vLy9N2FMw2cNooS/Ev2YicPXt23759ZWVlra2t9NRDEMTatWs3btz43Xffvf766//4xz++/PJLvIkq9bt9+3ZqfysrKzVFqDSdLdms1sCY/oEOW4R6qA4Ois1mm5mZ+fj42NnZOTk57dmzh/7A3KysrJSUlOLi4gkTJowoyMjISHd39xG9hHFwMZOoqChtB8Jg+BjSqTKPX7ly5eeff46KiqqqqgoICAgMDDx+/PiECRMOHjz44YcfUruFhobGxsYePXrUxsZGJBJR14ioUr+RkZEqjEq1dLZkszoCG0sfqPwi1PI7KIejo6O+vn5ZWRm15uDBg+fPn7906dKg11rlc3d3pz8kc0zKzc1FCI35bqoVPoZ0qszjP//8My4hdufOHalUun79ent7e4QQQRD03UxMTJYuXZqVlSUUCtesWUOtV2upX1XR2ZLN6ghsLH2g8otQy+8gpbGxccOGDV999RW1pry8vK+vz8bGBiFEkuTWrVubmpoKCgpYLHX90gVgINWMj0ul0mfPnlGlIG1tbRFCFy9e7OrqKi8vHzgEuW7duu7u7jNnztBvxpFT6le7dLZks6oCG9jy2PtA5RehltNB+rEyMDC4cOHCpUuX8NjLzZs3V65cKRAIcJXUu3fv7t2799NPP2Wz2fTRzP3792uly+AFQr/oqch8lfz8fDlPrc7Pz8e7RUdHjxs3ztjYODg4GM/UdnBwoGbFkSQ5a9asmJgYmca7u7ujo6NtbW1ZLJaZmVlQUFBZWVlycjIuhWxjY0PN8SopKZk3bx412Gppaenh4XH58uVhL/UePHgQT6zm8/n+/v7p6em40s2UKVMqKiqOHDkiEokQQpMmTbp//z5JkmFhYWw229ramsViiUSixYsXV1RUUK01Nja++uqrXC7Xzs5uw4YNW7ZsQQg5Ojrint64cWPSpEk8Hm/+/PlPnz49d+6cUCikpnbQXbt2bdq0aXp6ergvu3fv1lhgn3zyiS58oPKh4eZyVFZWzpo1CyHEYrFmz56dl5f317/+Fc8qEQgEgYGBJEn29/fv27dvypQpbDbbxMQkICDg3r17VAtDdVDmQ/T397ezszM0NORwOA4ODmKx+M6dO7iFoR58vm/fPpX0cWyA+Sqjp7J5h6O3cOHChw8faua9RkMXSjYPStcCU+sH+iLkuBehjyTkcVXQcn0V6if87du38amiJt9daTpbslnrgTH0AwVgjNFoHo+Oji4vL79///6qVavoD7RWoV9//VXOvEuli76DQWngAwUvprVr11J/tjK1lC9evBgTE0Ovt7xixQr6Dj4+PkKhUF9ff9q0aaN5fuboDVpYu7CwMDk5mX4SVlBQQHUW1+QZMfrJubrHVbZt26anp2djY6ODNWMHFRMTg+++mTx5cm5urrbD+X90JDCNfaDoBRhzeBH6SI7kuW7jxo0rKiq6d+9eV1cXtX7Hjh1+fn7UXbIODg7jx49HCJ05c4b+8qKiokWLFqk28pGSU1g7NTXVy8uLunO7v7+/pqbmypUrCxcuVO65bvB8TsAAL0KOU3cfOzs73d3dtd6U0s/nJEnyo48+cnJyopdzcHBw+PLLL/X09KytrZubm6n1Ws/jpaWlgYGBJ06cmDlz5qCFQ8LDw93d3aVSKX0lPJ8TACCPCosVa6Xu8YMHD+Li4nbt2kWvG4wQ8vDwiIyMrK2t3bx5s4ZDkmPYwtrx8fGlpaX024BHA/I4AIxBDl16d0TFirVYkFlpaWlpJEn6+/sP3JSUlOTk5HT06FFctW0gOcdNfoFoNETt5dEzMTHx8vJKTU0lSXL0rUEeB4Ax4uPjY2Jitm3bVldXd+XKlerqak9Pz2fPniGE0tLS6De7p6en79q1i1pMTU318/PDhRsfPHgQHh4eGhra2dkZERFRWVl548aN3t7eN954A5cCHVFT6Pd5U/39/Wrt+9mzZ6dOnTroc415PN5nn32mp6e3Zs0aXNVHhpzjtn79+qioKIlEIhQKs7OzKyoq7O3t16xZQ83F2rp16969ew8cOPDkyRM/P7/ly5fT7woejVmzZtXW1t66dWv0TUEeB4AZJBJJSkpKYGBgSEiIkZGRq6vr4cOHGxoajhw5olyDLBYLn6K6uLhkZGS0tbVlZmYq0Y6vr29ra2tcXJxyYSiio6Pjt99+k3PDmru7e1RUVGVl5datW2U2KXjcPDw8RCKRmZmZWCzu6OioqqpCCHV1dWVkZAQEBAQFBRkbG2/fvp3NZit3lAaaMmUKQmio28dGBPI4AMwwotK7I6XFgsyKwLXgBz0ZpyQlJU2dOjU9Pf3q1av09SM9bvQC0WqtvYy7g38WjBLkcQCYYdjSu6OkswWZEUJdXV0IIfkP4+VyuZmZmQRBrF69WiKRUOtHc9yo2svU/O5Hjx6p6oGruDoF7tooQR4HgBnkl94dJZ0tyIzhlDfsDczu7u4bN24sLy+n35U2muNG1V6mT/IrKSlRogsD9fT0oN+7NkqQxwFgBvmld9HoihXrbEFmzNzcnCCIlpaWYfdMTEx0dnbGT/3Ghj1ucqi19jLuDq7mNkqQxwFgBvmld9HIixXrbEHmgfh8vr29fU1NzbB74tEV/GRBao384ya/taFqL4vFYgsLi9Hc94+74+rqqnQLFMjjADDGzp079+zZk5CQYGpq6uXlNXnyZKpGPEJo/fr1r7766rJly6ZOnZqYmIh/sLu7u+PZhOvWrTM3N3dxcVm4cOHz588RQl1dXa6urjwez9PT08nJ6fvvv6cGoEfalAb4+vqWlZVRA9///Oc/HR0dKyoq5s6du2HDBvqebm5uuCI8Rc5xy8jIwI9Jmz59+sOHDz/99NNNmzYhhN566y38nO7U1NSoqKjk5OTx48dbWVlFRkY2NTUhhHp6eurq6k6fPj1otNeuXZs/f/6ECROuX79+69YtKyurefPmXblyhb7PTz/9ZG1tPX36dBUcHfq4D9yXD3QTgvvyVU1bdY+Vvi+/vLycxWIpWLBeA/r6+jw9PY8dO6bcyxsaGrhc7v79++kr4b58AMDIaL3usXwSieT8+fPl5eX4eqCjo2NCQkJCQkJ7e7u2Q0N9fX0FBQVtbW1Kl1CNj4+fOXNmeHg4QogkycePH1+9ehXfV6UEyOMAAF30/Pnzt956y8nJafXq1XhNTExMcHCwWCxW5IKnWhUXF586daqoqEj+lPahpKSklJaWnjt3js1mI4ROnz5tbW3t6el59uxZ5eKBPA7ACyc2NjYzM7OlpcXOzi4vL0/b4Qzi8OHD1KDBiRMnqPW7d+8ODw//6KOPtBgbQsjb2/vLL7+kStCMyOnTp7u7u4uLi01MTPCaxYsX08dblGgTnuoNwAtnz549e/bs0XYUSvLx8fHx8dF2FMpbtGjRokWLVNsmnI8DAACzQR4HAABmgzwOAADMBnkcAACYbZDrnDk5OZqPAwD5VFWcSJe9CH3EN6NDkhmNmpoa2SJf9JuCVPXIIgAAAOojcz8nQari6XAA6CyCILKzs+kPKgNgjIHxcQAAYDbI4wAAwGyQxwEAgNkgjwMAALNBHgcAAGaDPA4AAMwGeRwAAJgN8jgAADAb5HEAAGA2yOMAAMBskMcBAIDZII8DAACzQR4HAABmgzwOAADMBnkcAACYDfI4AAAwG+RxAABgNsjjAADAbJDHAQCA2SCPAwAAs0EeBwAAZoM8DgAAzAZ5HAAAmA3yOAAAMBvkcQAAYDbI4wAAwGyQxwEAgNkgjwMAALNBHgcAAGaDPA4AAMwGeRwAAJgN8jgAADAb5HEAAGA2giRJbccAgCqFhYXdu3ePWrxx44adnZ2JiQle1NfX//zzzydOnKil6ABQPZa2AwBAxSwsLI4cOUJfc/v2berf9vb2kMTBGAPjKmCsWb58+VCbDAwMQkNDNRgLAJoA4ypgDHr55Zfv3r076Hf73r17Tk5Omg8JAPWB83EwBr377rv6+voyKwmCmDFjBiRxMPZAHgdj0LJly/r6+mRW6uvrr1y5UivxAKBWMK4CxiYPD4/r16/39/dTawiCqK6utra21mJUAKgDnI+DsWnFihUEQVCLenp68+fPhyQOxiTI42BsCg4Opi8SBPHuu+9qKxgA1AryOBibTE1Nvb29qaudBEEEBARoNyQA1ATyOBizQkJC8OUffX39N998c/z48dqOCAC1gDwOxqzAwEADAwOEEEmSISEh2g4HAHWBPA7GLIFA8Je//AUhZGBg4Ofnp+1wAFAXyONgLHvnnXcQQgEBAQKBQNuxAKAuujh/PDg4OC8vT9tRAADAIHQwZ+povUM3N7eoqChtRwEQQqikpCQ1NTU7O1vbgSjpxIkTYrGYxZL3VWd6HxW3dOnSyMhId3d3bQfCSPh7ou0oBqGj5+MIodzcXG0HAhBCKCcnZ+nSpTr4PVFQV1cXl8uVvw/T+6g4giCys7PffvttbQfCSDr7PYHxcTDGDZvEAWA6yOMAAMBskMcBAIDZII8DAACzQR4HAABmgzwOgJLOnTtnZGT09ddfazsQzbl48WJMTMypU6fs7e0JgiAIYsWKFfQdfHx8hEKhvr7+tGnTbty4oa04EUL9/f0HDhzw8PCgrywsLExOTh74jBGmgzwOgJJ0cP6ZWu3cuTMtLS02NjYoKOjhw4cODg7jx48/ceLE2bNnqX0uXLiQm5vr5+dXVlY2e/ZsbYVaXl7+pz/9aePGjZ2dnfT1/v7+XC7X29u7ublZW7GpA+RxAJTk6+vb0tKigcotEolE5rxS8z7++OOsrKycnByhUEitTEtL09PTCwsLa2lp0WJsMm7durV169Z169bNnDlz4NaIiIgZM2YsXLiwt7dX87GpCeRxAHTdsWPH6urqtBjAgwcP4uLidu3aJTMZ38PDIzIysra2dvPmzdqKbaAZM2acOnXqnXfe4XA4g+4QHx9fWlqqm3dmKgfyOADKuHr1qq2tLUEQhw4dQghlZGQIBAI+n3/69OkFCxaIRKKJEyeePHkS75yWlsblcs3NzdeuXWtlZcXlcvHjQ/HW8PBwAwMDS0tLvPj+++8LBAKCIBoaGhBCkZGRmzZtqqioIAjC0dERIfTNN9+IRKLdu3drrLNpaWkkSfr7+w/clJSU5OTkdPTo0YsXLw76WpIkU1JSXnrpJQ6HY2Jisnjx4l9//RVvkn/QEEJ9fX07duywtbXl8XjTp09XVeEEExMTLy+v1NTUMTMyBnkcAGXMnz//hx9+oBbXr18fFRUlkUiEQmF2dnZFRYW9vf2aNWukUilCKDw8PDQ0tLOzMyIiorKy8saNG729vW+88UZ1dTVCKC0tjX6jfHp6+q5du6jF1NRUPz8/BwcHkiQfPHiAEMKX6eiPkFa3s2fPTp06lc/nD9zE4/E+++wzPT29NWvWdHR0DNwhPj4+JiZm27ZtdXV1V65cqa6u9vT0fPbsGRruoCGEtm7dunfv3gMHDjx58sTPz2/58uX//ve/VdKjWbNm1dbW3rp1SyWtaR3kcQBUycPDQyQSmZmZicXijo6OqqoqahOLxcKnpS4uLhkZGW1tbZmZmUq8ha+vb2tra1xcnOqilqejo+O3335zcHAYagd3d/eoqKjKysqtW7fKbJJIJCkpKYGBgSEhIUZGRq6urocPH25oaDhy5Ah9t0EPWldXV0ZGRkBAQFBQkLGx8fbt29lstnJHbKApU6YghO7cuaOS1rQO8jgAaoEfRUSdWsqYM2cOn8+nRhh0WV1dHUmSg56MU5KSkqZOnZqenn716lX6+rKysvb29jlz5lBr5s6da2BgQI0pyaAftHv37nV2dr788st4E4/Hs7S0VNURw93BPwvGAMjjAGgHh8Opr6/XdhTD6+rqQggNdc0Q43K5mZmZBEGsXr1aIpFQ6/H0PkNDQ/rOxsbGbW1tw74vHqXZvn078btHjx7JzCNUGo/HQ793bQyAPA6AFkil0ubm5okTJ2o7kOHhlDfsvTPu7u4bN24sLy9PTEykVhobGyOEZLK2gh03MzNDCB04cICkKSkpUaILA/X09KDfuzYGQB4HQAuKi4tJknRzc8OLLBZrqBEYrTM3NycIQpEZ4omJic7Ozjdv3qTWvPzyy4aGhvSLk9evX+/p6fnDH/4wbGs2NjZcLre0tFS5sOXD3bGwsFBH45oHeRwADenv729qaurt7b19+3ZkZKStrW1oaCje5Ojo+Pz584KCAqlUWl9f/+jRI/oLx40b9/jx48rKyra2NqlUWlRUpMl5h3w+397evqamZtg98eiKvr4+fc2mTZvy8/NPnDjR2tp6586ddevWWVlZhYWFKdLaqlWrTp48mZGR0dra2tfXV1NT8+TJE4SQWCy2sLAYze2kXcMAACAASURBVH3/uDuurq5Kt6BbSN2zZMmSJUuWaDsK8P/Dk3a1HYV6KdHHgwcP4hnffD7f398/PT0dXzqbMmVKRUXFkSNHRCIRQmjSpEn3798nSTIsLIzNZltbW7NYLJFItHjx4oqKCqq1xsbGV199lcvl2tnZbdiwYcuWLQghR0fHqqoqkiRv3LgxadIkHo83f/78p0+fnjt3TigUJiUlKdFThFB2dvZIXxUeHs5mszs7O/Fifn4+nr5iamr6wQcfyOy8ZcuWRYsWUYv9/f379u2bMmUKm802MTEJCAi4d+8e3jTsQevu7o6Ojra1tWWxWGZmZkFBQWVlZSRJBgQEIIR27NgxaLQlJSXz5s2zsrLCKc7S0tLDw+Py5cv0fXx9fa2trfv7+0d0HHT2b0EXY4I8rlN09rurQhroY1hY2Lhx49T6FopQLo+Xl5ezWKwvvvhCHSEpoa+vz9PT89ixY8q9vKGhgcvl7t+/f6Qv1Nm/BRhXAUBDmFtmz9HRMSEhISEhob29XduxoL6+voKCgra2NrFYrFwL8fHxM2fODA8PV21gWsTUPE6vnGlpaRkSEqLFYAatkCkfPX7MwMDA3Nz8z3/+8759+5qamtQXrfp0d3dHRERYWlry+fzXX38dXx87fPiwCt8iOTnZ2dmZx+MJBAJnZ+e4uLjW1lZqa0JCgouLi0gk4nA4jo6OH374oS7knbEhJiYmODhYLBZrvSRWcXHxqVOnioqK5E9pH0pKSkppaem5c+fYbLbKY9Mabf8gGITi4yoODg5GRkbqjke++/fvz5s3DyE0Y8aMkb6Wih9fAfv+++9DQ0MJgrCysvrpp5/UEKwyFP8tuXv3bicnp6ampr///e+5ubnl5eUIoU8++USFwfj6+u7fv7+urq6trS0nJ4fNZr/xxhvUVi8vr/T09MbGxtbW1uzsbDab/dZbbynSrLp/L8fExOA7XCZPnpybm6u+NxoWUmpchXL+/Pno6GgVxqNhBQUFe/bs6e3tVe7lOjuuoosxMSiPl5aWBgYGnjhxYubMmaPJ43S5ubl6enrm5ubNzc0qCnNUFP/uzp07d/ny5dSiSvJ4Z2enu7s7tRgQECCRSKjF4OBghNDjx4/xoq+vL/1PFBctwZcK5dPZv0+VG2Uef8Hp7PeEqeMqOmLYCplKWLJkSWhoaF1dnWpHJDSgpqZG5b9VZUq25ufn00unWltbI4SowZMzZ87QJ72ZmpoihFR1ByAAOmuM5/F//etfLi4uRkZGXC7X1dX1/PnzCKH33nsPD0k7ODjgexZWrVrF5/ONjIwKCwvRENUy9+7dy+fzhUJhXV3dpk2brK2t7927J//dla4viqcVFxUV4cVB4xm25ufly5dfeeUVPp8vEolcXV3xOLKaCoF+++23jo6OT548+fzzzwmCkLkPGyOHrl+KhvikBpZslVFeXm5sbDxp0qRBo6qtreXxeHZ2dirpIwC6S9s/CAahwnGV3Nzc+Pj458+fNzY2urm5jR8/Hq8PCgrS19evra2l9ly+fHlhYSH+9+bNmzkcTl5eXlNTU2xsrJ6eHh6t3rZtG0IoIiLi4MGDgYGB//nPf6iX//GPfxw4rnLmzBmhUJiQkDDS+HHOtbGxUSSe7777rqWlpa6uztPTUyAQ9PT0kCTZ3t4uEomSk5MlEsnTp08DAwPr6+vlNCWH4r8lLSwsVq5cSS3KjKvs2LHDwMDgiy++aG5uvn379uzZs01NTZ8+fYq3yvmkcMlWup6enpqamoMHD3I4nKEmw3V0dAiFwvDwcEUi19nfyyqHYFxlFHT2e6KLMalpfHzPnj3o9+JtuOY9dSdFS0vLlClT8NCqRCLh8/lisRhv6uzs5HA469evJ3/Pm/TxWcqgeXw08RMEYWxsPKJ40tPTEUIPHjwgSfKXX35BCJ05c4beppym5FBJHu/s7DQ0NKTemiTJH3/8ESE06H9y9E9q0DyOb6ceP3783/72N/z/1kDbtm1zcnJqbW1VJHKd/ftUOcjjo6Gz3xOWJs/9tQsP3eI5vK+99pqTk9Px48djY2MJgsjKyhKLxXhoVa3VMhXU0dFBkiS+t03xeOg1P+3t7c3NzUNCQiIiIkJDQydPnjyiplRuRPVL6Z/UoKqrq5ubm2/evBkTE3PkyJFLly6Zm5vTd8jPz8/Jyblw4QL9YZLDysnJUXxn5lJVqakXkO4eOm3/RzIIFZ6PnzlzxsvLy9TU1MDAgCAIhNCTJ0/wppSUFITQt99+S5LkvHnzKisr8fr/+7//G3iU3NzcSA2ej+PCET4+PiOK59NPP0UIUaM9v/zyy1/+8hcWi0UQxNKlSzs7O+U0JYdKzse//fZbhNDhw4fp+5ubm//pT3/C/x7qkxr0fJxy//59hFBERAR95cmTJ+fOnUsfNBuWqq4TgBeB4t8rjRmD1zmvXLly4MABhFBVVVVAQIClpeX169dbWlqSk5Ppu4WGhnK53KNHj967d08kElHXytRaLVNB33zzDUJowYIFo4ln2rRpX3/99ePHj6Ojo7Ozs/fv36/FrsmvXyr/k5LD0dFRX1+/rKyMWnPw4METJ05cunRpwoQJIw1SE39w2oZgXGUUdPb/+zE4rvLzzz8LBAKE0J07d6RS6fr16+3t7RFC+CyPYmJisnTp0qysLKFQuGbNGmq9WqtlKuLp06cHDhyYOHHi6tWrlY7n8ePHzc3NLi4uZmZmH3300YULF+7evavFrsmvXyr/k6I0NjZu2LDhq6++otaUl5f39fXZ2NgghEiS3Lp1a1NTU0FBAYs1Br/YAAxlTJ2PS6XSZ8+eFRcX4zxua2uLELp48WJXV1d5efnAodh169Z1d3efOXPGz8+PWimnWuZIKVJflCTJ9vZ2XHetvr4+Ozt73rx5+vr6BQUFeHxcuXgeP368du3aX3/9taen5+bNm48ePXJzc1Nh10ZKfv1SOZ8UvWSrgYHBhQsXLl261NraKpVKb968uXLlSoFAsHHjRoTQ3bt39+7d++mnn7LZbHrBg/3792uggwBok5Z/qAxGkfFxqnLmoPLz8/Fu0dHR48aNMzY2Dg4OPnToEELIwcGBfoPfrFmzYmJiZBoftFpmcnIyfnqIjY0NNddNfoVMOfVFCwsLp0+fzufzDQwM9PT0EEJ4gsorr7ySkJDQ2Ng4bDzya35WVlZ6eHiYmJjo6+tPmDBh27ZteDbOUIVA5VBkfLyysnLWrFkIIRaLNXv27Ly8vL/+9a94VolAIAgMDCTl1i+V80nJlGz19/e3s7MzNDTkcDgODg5isfjOnTu4haGembtv3z75wSvYx7EBwbjKKOjs94QgSVJl/yeoCL7ZOjc3VwPv5evre+jQIbhVRI6cnJylS5fq4PdEhV6EPmIEQWRnZ+OKBWCkdPZ7MqbGVRREPUDr9u3buHK/duMBAIDReBEvB0VHR69bt44kyVWrVn3xxRfaDgcAAEblRTwf5/P5zs7Or7/+enx8vIuLi7bDAUBHXbx4MSYmhl4rf8WKFfQdfHx8hEKhvr7+tGnTRvO0zNFISkoi/ht1pxt29erVefPm8fl8Kyur6Ojo7u5uvL6wsDA5OZm5D/egexHzeFJSUl9fX1VVFX2aCgCAbufOnWlpabGxsUFBQQ8fPnRwcBg/fvyJEyfOnj1L7XPhwoXc3Fw/P7+ysrLZs2drMdqhlJWV+fj4eHt719fX5+fnHz9+fN26dXiTv78/l8v19vZubm7WbpCj9yLmcQA0TyKRjOiJUZppaigff/xxVlZWTk4OvbBBWlqanp5eWFiY1h8JJEOmVhouLoQlJiZaWlru2rVLIBC4u7tHR0d/9tlnVC2KiIiIGTNmLFy4sLe3V0uxqwbkcQA0QaaQuo40NagHDx7ExcXt2rWLXuodIeTh4REZGVlbW7t582b1vbsK9fb2nj171svLi7qzbMGCBSRJnj59mtonPj6+tLQ0NTVVSzGqBuRxABRFDl1CPTw83MDAwNLSEi++//77AoGAIIiGhgY0oJB6Wloal8s1Nzdfu3atlZUVl8v18PCg7n4aUVNoFGXuh5KWlkaSpL+//8BNSUlJTk5OR48exRVDR3SIhq2Yr/Li+A8fPmxvb8d3mWH4ppPbt29Ta0xMTLy8vFJTU3VwNuEIaHa6ukIUr5MFNEBn731QIQX7KL+E+jvvvGNhYUHtvG/fPoQQLvtODij4FRYWJhAI7t6929XVVVZWNnfuXKFQSN2hNqKmhi1zT4cUuA/I3t7excVFZqWDg8Nvv/1GkuQPP/ygp6c3efLk9vZ2kiSLiooWLVpE7Sb/EMmpmE8qVRyfJMnExMSJEycaGxuz2ezJkycvWrToxx9/xJsuX76MBtwIxuPxvL296WtiYmIQQjdv3hz2vXT2bwHOxwFQiEQiSUlJCQwMDAkJMTIycnV1PXz4cENDw5EjR5RrkMVi4fNWFxeXjIyMtra2zMxMJdrx9fVtbW2Ni4tTLgwZHR0dv/32m5ybpd3d3aOioiorK7du3SqzScFD5OHhIRKJzMzMxGJxR0dHVVUVQqirqysjIyMgICAoKMjY2Hj79u1sNluRA7Jy5crCwsLq6ur29vaTJ09WVVV5eXnh0ml4agr9UX8IITabLZFI6GumTJmCEBrqfmBGgDwOgEJGVEJ9pObMmcPn8zVc5n5Q+PEduOTDUJKSkqZOnZqenn716lX6+pEeInrFfKWL49vY2MyaNcvQ0NDAwMDNzS0zM1MikeBnquDxfZlrmD09PbjABgV39tmzZ8O+l86CPA6AQvDsNJlHjxobG8sU41Uah8Opr69XSVOj0dXVhYORsw+Xy83MzCQIYvXq1fRz29Ecoo6ODoTQ9u3bqWngjx49UuIZ2a6urvr6+rgwPb7GgJ+SiHV2dnZ1dVEFkTCc1nHHGQryOAAKkV9CfZSkUqmqmholnNSGvTvG3d1948aN5eXliYmJ1MrRHCJVFcfv7+/v7+/H/w/Z2dkJhcJHjx5RWx88eIAQmj59Ov0lPT096PeOMxTkcQAUIr+EOkKIxWJRpXtGqri4mCRJNze30Tc1Subm5gRBKDJDPDEx0dnZ+ebNm9SaYQ+RHEoXx3/zzTfpi/jSqLu7O0KIxWItXLjwypUr/f39eGtRURFBEDJTcXBncXlOhoI8DoBC5JdQRwg5Ojo+f/68oKBAKpXW19fTTwPRfxdSxzm6v7+/qampt7f39u3bkZGRtra2oaGhSjSlSJl7xfH5fHt7+5qaGkUOSGZmJv0q4rCHSH5rQxXHF4vFFhYWQ933X1tbm5WV1dzcLJVKS0pK3nvvPVtbW+qmzbi4uGfPnu3cubOjo6OkpGTfvn2hoaFTp06lt4A76+rqOmyQuksrs2Tkg3mHOkVn51qpkIJ9lF9CvbGx8dVXX8UVNDds2LBlyxaEkKOjI55NKFNIPSwsjM1mW1tbs1gskUi0ePHiiooK5ZqSU+Z+IKTAvMPw8HA2m93Z2YkXqVr/pqamH3zwgczOW7Zsoc87lHOI5FfMJ4cujh8QEIAQ2rFjx6DRbtq0ycHBQSAQsFisiRMnrlmz5vHjx/QdLl++/Morr3A4HCsrqy1btnR1dcm04Ovra21tjZ/lIp/O/i3oYkyQx3WKzn53VUjzfQwLCxs3bpwm3xFTJI+Xl5ezWCyZm921qK+vz9PT89ixY+povKGhgcvl7t+/X5GddfZvAcZVANAOna205+jomJCQkJCQ0N7eru1YUF9fX0FBQVtbm1gsVkf78fHxM2fODA8PV0fjGgN5HAAgKyYmJjg4WCwWa70kVnFx8alTp4qKiuRPaVdOSkpKaWnpuXPn2Gy2yhvXJMjjAGhabGxsZmZmS0uLnZ1dXl6etsMZ3O7du8PDwz/66CPthuHt7f3ll19S1WZU6PTp093d3cXFxSYmJipvXMNexOcBAaBde/bs2bNnj7ajGJ6Pj4+Pj4+2o1CXRYsWLVq0SNtRqAacjwMAALNBHgcAAGaDPA4AAMwGeRwAAJhNR69zXrt2LTg4WNtRAIR+v2t5bH8cL0IfKQcOHMjNzdV2FIykSLkCrSBI3XuaUUpKihJ1zgAYVFFR0axZs9QxcQ28mHTwf0FdzOMAqBBBENnZ2W+//ba2AwFAXWB8HAAAmA3yOAAAMBvkcQAAYDbI4wAAwGyQxwEAgNkgjwMAALNBHgcAAGaDPA4AAMwGeRwAAJgN8jgAADAb5HEAAGA2yOMAAMBskMcBAIDZII8DAACzQR4HAABmgzwOAADMBnkcAACYDfI4AAAwG+RxAABgNsjjAADAbJDHAQCA2SCPAwAAs0EeBwAAZoM8DgAAzAZ5HAAAmA3yOAAAMBvkcQAAYDbI4wAAwGyQxwEAgNkgjwMAALNBHgcAAGaDPA4AAMzG0nYAAKhYc3MzSZL0NR0dHU1NTdSioaEhm83WeFwAqAsh840HgOlee+2177//fqit+vr6tbW1FhYWmgwJALWCcRUw1ixbtowgiEE36enp/elPf4IkDsYYyONgrFmyZAmLNfiAIUEQ7777robjAUDdII+DscbExMTHx0dfX3/gJj09vYCAAM2HBIBaQR4HY1BISEh/f7/MShaL5evra2RkpJWQAFAfyONgDPL39+dwODIr+/r6QkJCtBIPAGoFeRyMQXw+PyAgQGZyIY/HW7hwobZCAkB9II+DsWn58uVSqZRaZLPZS5Ys4fF4WgwJADWBPA7GpjfffJM+FC6VSpcvX67FeABQH8jjYGxis9lisdjAwAAvGhsbe3t7azckANQE8jgYs5YtW9bT04MQYrPZISEhQ00qB4Dp4L58MGb19/dPmDDh2bNnCKGrV6/OmzdP2xEBoBZwPg7GLD09vRUrViCErKysPDw8tB0OAOqii780S0pKqqurtR0FGAtMTU0RQn/84x9zc3O1HQsYI95++21thyBLF8dVgoOD8/LytB0FAAAMQgdzpo6OqyxZsoQEuiE7OxshpO0olJebmzvsPkzvo+IQQtnZ2dqOgqnw90QH6WgeB0BVlixZou0QAFAvyOMAAMBskMcBAIDZII8DAACzQR4HAABmgzwOAADMBnkcACWdO3fOyMjo66+/1nYg6nLx4sWYmJhTp07Z29sTBEEQBL4/luLj4yMUCvX19adNm3bjxg2tBJmUlET8t5dffpm+Ay7JwOfzraysoqOju7u78frCwsLk5OS+vj5tRK1ikMcBUBKpe/eDqNDOnTvT0tJiY2ODgoIePnzo4OAwfvz4EydOnD17ltrnwoULubm5fn5+ZWVls2fP1mK0QykrK/Px8fH29q6vr8/Pzz9+/Pi6devwJn9/fy6X6+3t3dzcrN0gRw/yOABK8vX1bWlp8fPzU/cbSSQSDdeH+fjjj7OysnJycoRCIbUyLS1NT08vLCyspaVFk8EM64svvqDfrfPLL79QmxITEy0tLXft2iUQCNzd3aOjoz/77LNff/0Vb42IiJgxY8bChQt7e3u1FLtqQB4HQNcdO3asrq5OY2/34MGDuLi4Xbt2cblc+noPD4/IyMja2trNmzdrLJjR6O3tPXv2rJeXF0EQeM2CBQtIkjx9+jS1T3x8fGlpaWpqqpZiVA3I4wAo4+rVq7a2tgRBHDp0CCGUkZEhEAj4fP7p06cXLFggEokmTpx48uRJvHNaWhqXyzU3N1+7dq2VlRWXy/Xw8Lh+/TreGh4ebmBgYGlpiRfff/99gUBAEERDQwNCKDIyctOmTRUVFQRBODo6IoS++eYbkUi0e/duNXUtLS2NJEl/f/+Bm5KSkpycnI4ePXrx4sVBX0uSZEpKyksvvcThcExMTBYvXkyd/Mo/RAihvr6+HTt22Nra8ni86dOnj/4m+IcPH7a3t9va2lJrHBwcEEK3b9+m1piYmHh5eaWmpjJ6lAzyOADKmD9//g8//EAtrl+/PioqSiKRCIXC7OzsiooKe3v7NWvW4GeEhoeHh4aGdnZ2RkREVFZW3rhxo7e394033sB1PdPS0ugl9NLT03ft2kUtpqam+vn5OTg4kCT54MEDhBC+NNff36+mrp09e3bq1Kl8Pn/gJh6P99lnn+np6a1Zs6ajo2PgDvHx8TExMdu2baurq7ty5Up1dbWnpycuAS//ECGEtm7dunfv3gMHDjx58sTPz2/58uX//ve/FQk4JibGxMTEwMDAzs5u8eLFP/30E17/9OlThBB9aIjL5fJ4PBwPZdasWbW1tbdu3VLo6OgkyOMAqJKHh4dIJDIzMxOLxR0dHVVVVdQmFouFT1RdXFwyMjLa2toyMzOVeAtfX9/W1ta4uDjVRf3/dHR0/Pbbb/i8dVDu7u5RUVGVlZVbt26V2SSRSFJSUgIDA0NCQoyMjFxdXQ8fPtzQ0HDkyBH6boMeoq6uroyMjICAgKCgIGNj4+3bt7PZbEWOz8qVKwsLC6urq9vb20+ePFlVVeXl5VVWVoYQwlNT9PX16fuz2WyJREJfM2XKFITQnTt3hn0vnQV5HAC1wI8GpU42ZcyZM4fP51NjDrqjrq6OJMlBT8YpSUlJU6dOTU9Pv3r1Kn19WVlZe3v7nDlzqDVz5841MDCgRpBk0A/RvXv3Ojs7qSmDPB7P0tJSkeNjY2Mza9YsQ0NDAwMDNze3zMxMiUSSnp6OEMLj+zLXMHt6eng8Hn0N7qzMSTqzQB4HQDs4HE59fb22o5DV1dWFEOJwOHL24XK5mZmZBEGsXr2afm6LJ/AZGhrSdzY2Nm5raxv2ffEozfbt26lp4I8ePers7Bxp/K6urvr6+vfv30cI4UsOra2t1NbOzs6uri4rKyv6S3Baxx1nKMjjAGiBVCptbm6eOHGitgORhZPasHfHuLu7b9y4sby8PDExkVppbGyMEJLJ2gp208zMDCF04MAB+gzCkpKSkcbf39/f39+P/x+ys7MTCoWPHj2ituILDNOnT6e/BD+MW+YknVkgjwOgBcXFxSRJurm54UUWizXUCIyGmZubEwShyAzxxMREZ2fnmzdvUmtefvllQ0ND+sXJ69ev9/T0/OEPfxi2NRsbGy6XW1paOtKA33zzTfriTz/9RJKku7s7QojFYi1cuPDKlSvUNeGioiKCIGSm4uDOWlhYjPStdQfkcQA0pL+/v6mpqbe39/bt25GRkba2tqGhoXiTo6Pj8+fPCwoKpFJpfX09/RQSITRu3LjHjx9XVla2tbVJpdKioiL1zTvk8/n29vY1NTXD7olHV+hXEblc7qZNm/Lz80+cONHa2nrnzp1169ZZWVmFhYUp0tqqVatOnjyZkZHR2tra19dXU1Pz5MkThJBYLLawsBjqvv/a2tqsrKzm5mapVFpSUvLee+/Z2tpSN23GxcU9e/Zs586dHR0dJSUl+/btCw0NnTp1Kr0F3FlXV9dhg9RdGnkc0sgsWbIEnuumO16EZ54p0ceDBw/i4Vc+n+/v75+eno4vl02ZMqWiouLIkSMikQghNGnSpPv375MkGRYWxmazra2tWSyWSCRavHhxRUUF1VpjY+Orr77K5XLt7Ow2bNiwZcsWhJCjo2NVVRVJkjdu3Jg0aRKPx5s/f/7Tp0/PnTsnFAqTkpKU6ClS4Llu4eHhbDa7s7MTL+bn5+PpK6amph988IHMzlu2bFm0aBG12N/fv2/fvilTprDZbBMTk4CAgHv37uFNwx6i7u7u6OhoW1tbFotlZmYWFBRUVlZGkmRAQABCaMeOHYNGu2nTJgcHB4FAwGKxJk6cuGbNmsePH9N3uHz58iuvvMLhcKysrLZs2dLV1SXTgq+vr7W1dX9/v/zDQurw34IuxgR5XKfo7HdXhTTQx7CwsHHjxqn1LRShSB4vLy9nsVgyN7trUV9fn6en57Fjx9TReENDA5fL3b9/vyI76+zfAoyrAKAhTCmt5+jomJCQkJCQ0N7eru1YUF9fX0FBQVtbm1gsVkf78fHxM2fODA8PV0fjGsPUPE6vpWlpaRkSEqKVMBISElxcXEQiEYfDcXR0/PDDDxX86tPjxwwMDMzNzf/85z/v27evqalJ3ZGrQ3d3d0REhKWlJZ/Pf/311/EVs8OHD6vwLZKTk52dnXk8nkAgcHZ2jouLo88qU/rjADJiYmKCg4PFYrHWS2IVFxefOnWqqKhI/pR25aSkpJSWlp47d47NZqu8cY3S9g+CQSg+ruLg4GBkZKTueOTw8vJKT09vbGxsbW3Nzs5ms9lvvfWW4i+n4sdXwL7//vvQ0FCCIKysrPBld12g+G/J3bt3Ozk5NTU1/f3vf8/NzS0vL0cIffLJJyoMxtfXd//+/XV1dW1tbTk5OWw2+4033qC2Kv1xqPv3ckxMDL7nZfLkybm5uep7o2EhBcZVKOfPn4+OjlZrPFpUUFCwZ8+e3t5exV+is+MquhgTg/K4r68v/XuAq2Tga1OKGDT+3NxcPT09c3Pz5uZmlQU6Cop/d+fOnbt8+XJqUSV5vLOz093dnVoMCAiQSCTUYnBwMEKIuq6l9Mehs3+fKjeiPA5k6Oz3hKnjKjrizJkz9HlXpqamCCElbkKjW7JkSWhoaF1dnWpHJDSgpqZG5b9PZUq25ufn04upWltbI4SowRN1fBwA6L4xnsf/9a9/ubi4GBkZcblcV1fX8+fPI4Tee+89PCTt4OCA72JYtWoVn883MjIqLCxEQ9TP3Lt3L5/PFwqFdXV1mzZtsra2vnfvnszb1dbW8ng8Ozs7vKh0fVE8rbioqAgvDhrPsFVA8XQrPp8vEolcXV3xOLLKS4Ni3377raOj45MnTz7//HOCIGTuzMbIoSuaoiE+qYElW2WUl5cbGxtPmjRp0KhkPg4Axixt/yAYhArHVXJzc+Pj458/f97Y2Ojm5jZ+/Hi8PigoSF9fv7a2ltpz+fLlhYWF+N+bN2/mcDh5eXlNTU2xsbF6enp4tHrbtm0IoYiIiIMHDwYGBv7nP/+hv1dHR4dQKAwPD6fWnDlzRigUJiQkjDR+cU7TnAAAIABJREFUnHNtbGwUiee7775raWmpq6vz9PQUCAQ9PT0kSba3t4tEouTkZIlE8vTp08DAwPr6ejlNyaH4b0kLC4uVK1dSizLjKjt27DAwMPjiiy+am5tv3749e/ZsU1PTp0+f4q1yPilcspWup6enpqbm4MGDHA5nqOlxAz8OlfSR6RCMq4yCzn5PdDEmNY2P79mzB/1ezg1XwafupGhpaZkyZQoeWpVIJHw+XywW402dnZ0cDmf9+vXk73mTPj5Lt23bNicnp9bWVgXjkR8/QRDGxsYjigfXeHvw4AH5+6Otzpw5Q29TTlNyqCSPd3Z2GhoaUm9NkuSPP/6IEBr0Pzn6JzVoHse3UI8fP/5vf/sb/n9roBF9HDr796lykMdHQ2e/JyxNnvtrFx66xXN4X3vtNScnp+PHj8fGxhIEkZWVJRaL8dCqcvUz8/Pzc3JyLly4QC9ar7SOjg6SJPHdborHQ68Cam9vb25uHhISEhERERoaOnnyZKW7phIjqmhK/6QGVV1d3dzcfPPmzZiYmCNHjly6dMnc3Jy+g3IfB75qOuYdOHAgNzdX21EwkiLlCrRijI+Pnz179s9//rOZmRmHw/nwww+p9QRBrF279uHDh9999x1C6B//+Mf//M//4E1K1M/Mysr6+OOPi4uLcbocPVx109nZWbl4EEI8Hu/SpUvz58/fvXu3vb29WCyWSCSqKg2qhGErmg71SQ2KzWabmZn5+PhkZWWVlZXh83eKyj8OAHTcGDwfv3Llys8//xwVFVVVVRUQEBAYGHj8+PEJEyYcPHiQniBCQ0NjY2OPHj1qY2MjEomoa2VU/czIyEhF3u7gwYPnz5+/dOnSoBf3lPPNN98ghBYsWKBEPJRp06Z9/fXX9fX1KSkpH3/88bRp0/AdcUo0NXryK5rK/6TkcHR01NfXxw9/wUbzcbwIZ6kEQURFRdEfIwcUl5OTs3TpUm1HMYgxmMd//vlngUCAELpz545UKl2/fr29vT1CiHpmNmZiYrJ06dKsrCyhULhmzRpqveL1M0mS3Lp1a1NTU0FBAYulsiP59OnTAwcOTJw4cfXq1SOKh+7x48fNzc0uLi5mZmYfffTRhQsX7t69q3Rp0NGTX9FU/idFaWxs3LBhw1dffUWtKS8v7+vrs7GxQWr7OADQfWNqXEUqlT579qy4uBjncfyc7IsXL3Z1dZWXlw8cil23bl13d/eZM2f8/PyolXLqZ8q4e/fu3r17P/30UzabTb/Dfv/+/XgHReqLkiTZ3t6Oa63V19dnZ2fPmzdPX1+/oKAAj48rHg/d48eP165d++uvv/b09Ny8efPRo0dubm7KNaUS8iuayvmk6CVbDQwMLly4cOnSpdbWVqlUevPmzZUrVwoEgo0bNyIFPg4AxiytXmUdnCLzVahamoPKz8/Hu0VHR48bN87Y2Dg4OPjQoUMIIQcHB/oNfrNmzYqJiZFpfND6mcnJyfiJITY2Nniu21APZt23bx9uR0590cLCwunTp/P5fAMDAz09PYQQnqDyyiuvJCQkNDY2DhuP/CqglZWVHh4eJiYm+vr6EyZM2LZtG56NM1RpUDkUuUZfWVk5a9YshBCLxZo9e3ZeXt5f//pXPKtEIBAEBgaSciuayvmkZEq2+vv729nZGRoacjgcBwcHsVh8584d3MKwH8co+zg2IJivMgo6+z0hSJJU/j8B9cDTBjQzWOnr63vo0CG4VUQOPCaog98TFXoR+ogRBJGdnQ3j48rR2e/JmBpXURD1AK3bt2/jyv3ajQcAAEbjRczj0dHR5eXl9+/fX7VqFf0psQAAuosXL8bExNBrLK9YsYK+g4+Pj1Ao1NfXnzZt2lDPXVO3pKQk4r9Rd0hgV69enTdvHp/Pt7Kyio6O7u7uxusLCwuTk5OZUhRevhcxj/P5fGdn59dffz0+Pt7FxUXb4QCgi3bu3JmWlhYbGxsUFPTw4UMHB4fx48efOHHi7Nmz1D4XLlzIzc318/MrKyubPXu2FqMdSllZmY+Pj7e3d319fX5+/vHjx6lHd/r7+3O5XG9vb3xzA6O9iHk8KSmpr6+vqqqKPk0FALWSSCQeHh661tRQPv7446ysrJycHPoNsWlpaXp6emFhYVp/uIQMmRo7uCgFlpiYaGlpuWvXLoFA4O7uHh0d/dlnn1H3MEdERMyYMWPhwoW9vb1ail01XsQ8DoDmyRTg1ZGmBvXgwYO4uLhdu3bRSwQjhDw8PCIjI2trazdv3qy+d1eh3t7es2fPenl5UXckLFiwgCTJ06dPU/vEx8eXlpampqZqKUbVgDwOgKLIoUvvhoeHGxgYWFpa4sX3339fIBAQBNHQ0IAGFOBNS0vjcrnm5uZr1661srLicrkeHh7UrPkRNYVGUR55KGlpaSRJ+vv7D9yUlJTk5OR09OhRXGluRIdo2ErLKi+q/PDhw/b2dnx3AoYnK9++fZtaY2Ji4uXllZqaqoOzUEZAw/McFaF4vUOgATo7Z1aFFOyj/NK777zzjoWFBbXzvn37EEK4XDA5oHBjWFiYQCC4e/duV1dXWVnZ3LlzhUIhdWfDiJoatjwyHVJg/ri9vb2Li4vMSgcHh99++40kyR9++EFPT2/y5Mnt7e0kSRYVFS1atIjaTf4hklNpmVSqqDJJkomJiRMnTjQ2Nmaz2ZMnT160aNGPP/6IN12+fBkNuIGAx+N5e3vT18TExCCEbt68Oex76ezfApyPA6AQiUSSkpISGBgYEhJiZGTk6up6+PDhhoaGI0eOKNcgi8XC560uLi4ZGRltbW2ZmZlKtOPr69va2hoXF6dcGDI6Ojp+++03OTfZubu7R0VFVVZWbt26VWaTgofIw8NDJBKZmZmJxeKOjo6qqiqEUFdXV0ZGRkBAQFBQkLGx8fbt29lstiIHZOXKlYWFhdXV1e3t7SdPnqyqqvLy8sIld/DUFPojohBCbDZbIpHQ10yZMgUhNNR9ZIwAeRwAhYyo9O5IzZkzh8/na6aGsHy47Lv8h9MnJSVNnTo1PT396tWr9PUjPUT0SstKF1W2sbGZNWuWoaGhgYGBm5tbZmamRCLBtfjx+L7MNcyenh58YzYFd/bZs2fDvpfOgjwOgEKGLb07ShwOp76+XiVNjUZXVxcORs4+XC43MzOTIIjVq1fTz21Hc4hUVVTZ1dVVX18fV37G1xjw07Wwzs7Orq4uKysr+ktwWscdZyjI4wAoRH7p3VGSSqWqamqUcFIb9u4Yd3f3jRs3lpeX0++kG80houoz04d9S0pKRhp/f39/f38//n/Izs5OKBQ+evSI2vrgwQOE0PTp0+kv6enpQb93nKEgjwOgEPmldxFCLBaLKvkwUsXFxSRJurm5jb6pUTI3NycIQpEZ4omJic7OzvhJ5diwh0gOpYsqv/nmm/RFfGnU3d0dIcRisRYuXHjlypX+/n68taioiCAImak4uLO4rBtDQR4HQCHyS+8ihBwdHZ8/f15QUCCVSuvr6+mngei/C/DiHN3f39/U1NTb23v79u3IyEhbW9vQ0FAlmlKkPLLi+Hy+vb29Ig8ww6Mr9KuIwx4i+a0NVVRZLBZbWFgMdd9/bW1tVlZWc3OzVCotKSl57733bG1tqZs24+Linj17tnPnzo6OjpKSkn379oWGhk6dOpXeAu6sq6vrsEHqLq3MkpEP5h3qFJ2da6VCCvZRfundxsbGV199FVde27Bhw5YtWxBCjo6OeDahTAHesLAwNpttbW3NYrFEItHixYsrKiqUa0pOeeSBkALzDsPDw9lsdmdnJ16kakSbmpp+8MEHMjtv2bKFPu9QziGSX2mZHLqockBAAEJox44dg0a7adMmBwcHgUDAYrEmTpy4Zs2ax48f03e4fPnyK6+8wuFwrKystmzZ0tXVJdOCr6+vtbU1fgaAfDr7t6CLMUEe1yk6+91VIc33MSwsbNy4cZp8R0yRPF5eXs5isWRudteivr4+T0/PY8eOqaPxhoYGLpe7f/9+RXbW2b8FGFcBQDt0ttKeo6NjQkJCQkJCe3u7tmNBfX19BQUFbW1t+OmyKhcfHz9z5szw8HB1NK4xkMcBALJiYmKCg4PFYrHWS2IVFxefOnWqqKhI/pR25aSkpJSWlp47d47NZqu8cU2CPA6ApsXGxmZmZra0tNjZ2eXl5Wk7nMHt3r07PDz8o48+0m4Y3t7eX375JVVtRoVOnz7d3d1dXFxsYmKi8sY1DB4rDoCm7dmzZ8+ePdqOYng+Pj4+Pj7ajkJdFi1atGjRIm1HoRpwPg4AAMwGeRwAAJgN8jgAADAb5HEAAGA2yOMAAMBsBKl7TzMKDg7W2clYAIAXnA7mTF3M4yUlJdXV1dqOAowRS5cujYyMxAXwABi9t99+W9shyNLFPA6AChEEkZ2drYN/ewCoCoyPAwAAs0EeBwAAZoM8DgAAzAZ5HAAAmA3yOAAAMBvkcQAAYDbI4wAAwGyQxwEAgNkgjwMAALNBHgcAAGaDPA4AAMwGeRwAAJgN8jgAADAb5HEAAGA2yOMAAMBskMcBAIDZII8DAACzQR4HAABmgzwOAADMBnkcAACYDfI4AAAwG+RxAABgNsjjAADAbJDHAQCA2SCPAwAAs0EeBwAAZoM8DgAAzAZ5HAAAmA3yOAAAMBvkcQAAYDbI4wAAwGyQxwEAgNlY2g4AABU7efJkW1sbfc3Fixebm5upxYCAADMzM43HBYC6ECRJajsGAFQpNDT0888/Z7PZeBF/wwmCQAj19fUZGhrW1dVxOBxthgiASsG4Chhrli1bhhCS/q63t7e3txf/W19fPzg4GJI4GGPgfByMNb29vRYWFs+fPx9063fffffaa69pOCQA1ArOx8FYw2Kxli1bRo2r0Jmamnp5eWk+JADUCvI4GIOWLVsmlUplVrLZ7BUrVujr62slJADUB8ZVwBhEkqStrW1NTY3M+h9//HHu3LlaCQkA9YHzcTAGEQQREhIiM7RiY2MzZ84cbYUEgPpAHgdjk8zQCpvNDg0NxbMPARhjYFwFjFnOzs737t2jFn/55Zdp06ZpMR4A1ATOx8GYtWLFCmpoxcXFBZI4GKsgj4MxKyQkpLe3FyHEZrNXrlyp7XAAUBcYVwFj2Zw5c37++WeCICorK21tbbUdDgBqAefjYCx79913EUL/X3vnHtTU0f7xPZDLSUICQa4KWAgiFfFCtRUspQ6vvK8yoAgUxrYjdWrRtm9A1CIqiuHiBV9wsNjWamlHO8p10BaxlPLSvk5ppx1BKfYSFURQykUgXBKu5/fHvm9+p5GEQwg5J7if/87uZs+zy8nD5jnPfveFF15AThwxi2Gi3mFWVlZNTQ3dViBmAyqVCsOwoaGhyMhIum1BzBIKCwvpNkETJq7Ha2pqfvjhB7qtQPyXlpaWoqIiuq3QExzH7e3tnZycdDcz6TFOiaKioie3RyEowtjnhInxcbh0YuA/vaeTgoKCqKgoBj4nFLlz5467u7vuNqY+RupgGJafn//KK6/QbYhJwtjnhInrcQTCgEzqxBEIUwf5cQQCgTBtkB9HIBAI0wb5cQQCgTBtkB9HIBAI0wb5cQRCT65evWppafnFF1/QbchMUVlZmZSUVFxc7ObmhmEYhmGvv/46uUFQUJBQKDQ3N/fy8rpx4wYtRqalpWF/ZfHixeQG169fX716NZ/Pd3R0TExMHBoaguVXrlw5duzY2NgYHVYbGOTHEQg9YWD+mQE5dOhQTk7Ovn37wsPD7927J5FI5syZc+HChbKyMnWbioqKwsLCkJCQhoYGHx8fGq3VRkNDQ1BQUGBgYEdHR0lJySeffLJjxw5YFRoaiuN4YGBgT08PvUZOH+THEQg9CQ4O7u3tDQkJmekbKZVKPz+/mb4LmaNHj166dKmgoEAoFKoLc3JyzMzMYmNje3t7jWnMpJw/f54g8csvv6irUlNTHRwcDh8+LBAIfH19ExMTP/30099++w3WxsXFLV26dP369VBPzXRBfhyBYDrnzp1rb2832u3u3LmTnJx8+PBhHMfJ5X5+fvHx8a2trbt37zaaMdNhdHS0rKwsICBAfX7IunXrCIK4fPmyuk1KSkpdXd3JkydpstEwID+OQOjD9evXXVxcMAx7//33AQCnT58WCAR8Pv/y5cvr1q0TiUROTk4XL16EjXNycnAct7Oz2759u6OjI47jfn5+P/74I6yVSqUcDsfBwQFevvPOOwKBAMOwzs5OAEB8fPyuXbvu3r2LYRjc03Tt2jWRSJSenj5DQ8vJySEIIjQ09MmqtLQ0Dw+Ps2fPVlZWTvhZgiCysrKeffZZLpcrFos3btyoXvzqniIAwNjY2MGDB11cXHg83pIlS/Lz86c5kHv37vX395Ml0iQSCQDg1q1b6hKxWBwQEHDy5EmTjpIhP45A6MOLL774/fffqy/ffvvtnTt3KpVKoVCYn59/9+5dNze3bdu2wbPlpFJpTEzM4OBgXFxcU1PTjRs3RkdH165d++DBAwBATk4OeaN8bm7u4cOH1ZcnT54MCQmRSCQEQdy5cwcAAF/NjY+Pz9DQysrKFi5cyOfzn6zi8XiffvqpmZnZtm3bBgYGnmyQkpKSlJS0f//+9vb277777sGDB/7+/n/++SeYbIoAAHv37j1+/Hh2dvajR49CQkI2b978888/UzE4KSlJLBZzOBxXV9eNGzf+9NNPsLytrQ0AQA4N4TjO4/GgPWqWL1/e2tp68+ZNSrPDSJAfRyAMiZ+fn0gksrW1jY6OHhgYaG5uVlexWCy4UF20aNHp06f7+vry8vL0uEVwcLBCoUhOTjac1f/PwMBAY2MjXLdOiK+v786dO5uamvbu3atRpVQqs7KyNm3a9Nprr1laWnp7e3/44YednZ1nzpwhN5twilQq1enTp8PCwsLDw62srA4cOMBms6nMz5YtW65cufLgwYP+/v6LFy82NzcHBAQ0NDQAAGBqirm5Obk9m81WKpXkkgULFgAA6uvrJ70XY0F+HIGYETgcDgCAfNYzmRUrVvD5fHXMgTm0t7cTBDHhYlxNWlrawoULc3Nzr1+/Ti5vaGjo7+9fsWKFumTlypUcDkcdQdKAPEW///774OCgOmWQx+M5ODhQmR9nZ+fly5dbWFhwOJxVq1bl5eUplcrc3FwAAIzva7zDHB4e5vF45BI4WI1FummB/DgCQQ9cLrejo4NuKzRRqVQAAC6Xq6MNjuN5eXkYhm3dupW8toUJfBYWFuTGVlZWfX19k94XRmkOHDigTgO/f//+4ODgVO339vY2Nzf/448/AADwlYNCoVDXDg4OqlQqR0dH8kegW4cDN1GQH0cgaGBkZKSnp2dSYXTjA53apLtjfH19ExIS5HJ5amqqutDKygoAoOG1KQ7T1tYWAJCdnU3OINTjPJnx8fHx8XH4f8jV1VUoFN6/f19dC18wLFmyhPyR4eFh8L+BmyjIjyMQNFBdXU0QxKpVq+Ali8XSFoExMnZ2dhiGUckQT01N9fT0rK2tVZcsXrzYwsKC/HLyxx9/HB4efu655ybtzdnZGcfxurq6qRr897//nXz5008/EQTh6+sLAGCxWOvXr//uu+/U74TLy8sxDNNIxYGDtbe3n+qtmQPy4wiEkRgfH+/u7h4dHb1161Z8fLyLi0tMTAyscnd3f/z4cWlp6cjISEdHB3kJCQCwtrZ++PBhU1NTX1/fyMhIeXn5zOUd8vl8Nzc3KmcGwegK+S0ijuO7du0qKSm5cOGCQqGor6/fsWOHo6NjbGwsld7eeOONixcvnj59WqFQjI2NtbS0PHr0CAAQHR1tb2+vbd9/a2vrpUuXenp6RkZGampq3nzzTRcXF/WmzeTk5D///PPQoUMDAwM1NTWZmZkxMTELFy4k9wAH6+3tPamRzIVgHhEREREREXRbgfgvMI2XbitmFj3GeOrUKRh+5fP5oaGhubm58HXZggUL7t69e+bMGZFIBACYP3/+H3/8QRBEbGwsm82eN28ei8USiUQbN268e/euureurq41a9bgOO7q6vrPf/5zz549AAB3d/fm5maCIG7cuDF//nwej/fiiy+2tbVdvXpVKBSmpaXpMVIAQH5+vu42UqmUzWYPDg7Cy5KSEpi+YmNj8+6772o03rNnz4YNG9SX4+PjmZmZCxYsYLPZYrE4LCzs999/h1WTTtHQ0FBiYqKLiwuLxbK1tQ0PD29oaCAIIiwsDABw8ODBCa3dtWuXRCIRCAQsFsvJyWnbtm0PHz4kN/j222+ff/55Lpfr6Oi4Z88elUql0UNwcPC8efPGx8d1TwvB4O8CE21CfpxRMPbZNSBGGGNsbKy1tfWM3oIKVPy4XC5nsVgam91pZGxszN/f/9y5czPReWdnJ47jJ06coNKYsd8FFFdBIIyEqUjrubu7y2QymUzW399Pty1gbGystLS0r68vOjp6JvpPSUlZtmyZVCqdic6NBvLjCARCk6SkpMjIyOjoaNolsaqrq4uLi8vLy3WntOtHVlZWXV3d1atX2Wy2wTs3JibvxysrKyMiIpydnblcroWFhZeX186dOzVeEzEQsqYzhMPh2NnZvfzyy5mZmd3d3XQbqA9DQ0NxcXEODg58Pv9vf/sbzHz48MMPDXiLY8eOeXp68ng8gUDg6emZnJxMzg6WyWSLFi0SiURcLtfd3f29995jwooSALBv3768vLze3l5XV9eioiK6zaFEenq6VCo9cuQIvWYEBgZ+/vnnavEZA3L58uWhoaHq6mqxWGzwzo0N3YGdCaAeH09MTAQAvPHGG7W1tUqlsre399q1a88995xIJPrmm29m2s7pI5FILC0tCYKAmQz//ve/Y2JiMAxzdHSE6VNMgHpMMD093cPDo7u7+6OPPiosLJTL5QCADz74wIDGBAcHnzhxor29va+vr6CggM1mr127Vl0bEBCQm5vb1dWlUCjy8/PZbPY//vEPKt0yNu5pcACF+DhCG4x9TphoE0U/XlpaCgB46623NMr7+vo8PDzmzJnT2dlJ5XaDg4O+vr76GDrtrtR+nExhYaGZmZmdnV1PT49BrJom1J/dlStXbt68WX1pED+uMaVhYWFKpVJ9GRkZCQBQ5ycEBwePjo6qa6H4FEz50A1jv58GB/nx6cDY58SE4yonTpwAABw4cECj3MLCIiEhoaur6+zZs1T6MaC4s0G6ioiIiImJaW9vN2xEwgi0tLQYPM6oMaUlJSVkUex58+YBANTBky+//JKczmxjYwMA0GNvNwJhWpiqHx8cHPzhhx9cXFycnZ2frIW7ub7++mswRXFnhuhEw+0h5eXl8HJCXeZJ1Zxh2iyfzxeJRN7e3jCObHCJZ8jXX3/t7u7+6NGjzz77DMMwDYUNCKFdmRoA8J///GfRokWWlpY4jnt7e3/11VdgoinVQC6XW1lZzZ8/f0KrWltbeTyeq6urQcaIQDAXun8QTACVuMqvv/4KAFixYsWEtVC6zNXVFV6++uqr9vb26trMzEwAQEdHB7wMDw+H4s6Q2NhYgUBw+/ZtlUrV0NCwcuVKoVCo/m0+pa6+/PJLoVAok8m0jWLCuApBENDnOjs7w8vdu3dzudyioqLu7u59+/aZmZnB6Pn+/fsBAN98801vb297e7u/v79AIBgeHiYIor+/XyQSHTt2TKlUtrW1bdq0CRqprSsdUP8taW9vv2XLFvWlRlzl4MGDHA7n/PnzPT09t27d8vHxsbGxaWtrg7WFhYUpKSmPHz/u6upatWrVnDlzYLnGlEKGh4dbWlpOnTrF5XK1pTkPDAwIhUKpVErFcsb+XjY4AMVVpgFjnxNTXY/Dn9JwP9iTTKjXQx3adaKFQiGGYdD+SXWZJ1RzbmpqUigUXl5eOI7b29sXFxfb2NjoLfE8fSZVpo6IiDh06JBYLLa2tg4NDe3q6tKhBejs7Ozk5JSSknL8+PGoqKgJ22RkZDg6Oqalpc3IeBAIJsGi2wA9gWd8aDvo+vHjx0C7l58StOhEDwwMEAQB7aeuy0xWc3Zzc7Ozs3vttdfi4uJiYmKeeeaZKXVlcKakTA2D7Dp2zTx48KCnp6e2tjYpKenMmTNVVVV2dnbkBiUlJQUFBRUVFeSzYCZFfYrj7CYqKkrbPz+EiWKqfnz+/PlsNlub9Ds8zwke8zF9jK8TDdWTPT09AUmXmfxGV0NA+Ul4PF5VVdXevXvT09NlMtkrr7ySl5enX1cGYVJl6rKysszMzIaGBoVCManyH5vNtrW1DQoKcnV19fDwyMjIIJ+Te+nSpaysrOrq6rlz507JSEO9LWAyUVFR8fHx8AUSYqrU1NQw80RmU/XjOI77+/tXVVU1NjY++SILHlOiIWipH7ToRF+7dg0AsG7dOkDSZY6Pj59SJ15eXl988UVHR0dWVtbRo0e9vLzgzmY9upo+upWpm5ubw8LCNm3a9Mknn8ydO/fUqVPvvfcelW7d3d3Nzc3hIV6QU6dOffXVV1VVVRO+a9UN+ZDM2UpUVJSvr+/TMNIZgpl+3FTj4wAAeDygTCbTKFcoFNnZ2XZ2dlu3boUl0xF3Nr5OdFtbW3Z2tpOTE7RfP13mhw8f3r59GwBga2t75MgRHx+f27dv6y3xPH10K1PX19ePjIy8/fbbbm5uOI5ri290dXVt3ryZXCKXy8fGxmDOEkEQiYmJ9fX1paWlejhxBMJ0MWE/vnbt2iNHjnz22WcxMTE3b95UqVQKhaKiomLNmjXd3d1FRUWWlpaw5ZTEnYFxdaIJgujv74eamR0dHfn5+atXrzY3Ny8tLYXxcR26zDp4+PDh9u3bf/vtt+Hh4dra2vv3769atUq/rgyCbmVqFxcXAEBlZaVKpZLL5eSgOXlKORxORUVFVVUVjL3U1tZu2bJFIBAkJCQAAG7fvn38+PGPP/6YzWaTBQ/gPgMEYjZDa7bMxExJt7ampmbz5s0uLi4cDkcgECxevHjXrl0tLS3kNlMSdzach3lxAAAGCklEQVSOTvSVK1eWLFnC5/M5HI6ZmRkAAMMwKyur559/XiaTdXV1kRtPqMusW825qanJz89PLBabm5vPnTt3//79cKOjNolnHVDJtWpqalq+fDkAgMVi+fj4FBUV/etf/4IHrAgEgk2bNhE6lakJgkhMTLS2traysoqMjHz//fcBABKJpLm5WWNKQ0NDXV1dLSwsuFyuRCKJjo6ur6+HPWg77zwzM1O38RTHODsAKO9wGjD2OcEIgjDCf4spATdbFxYW0nL37du3FxYWdnV10XJ3BlJQUBAVFcXA58SAPA1jhGAYlp+fj+Lj+sHY58SE4yozh6noRCMQCARAfhyBQFCnsrIyKSmJrLr8+uuvkxsEBQUJhUJzc3MvLy9tJ2oah/Hx8ezsbD8/P3LhlStXjh07NvsWasiP/wVT1IlGIIzDoUOHcnJy9u3bFx4efu/ePYlEMmfOnAsXLpSVlanbVFRUFBYWhoSENDQ0+Pj40GWqXC5/6aWXEhISNFTSQkNDcRwPDAzUtoXQREF+/C9kZGQMDQ0RBNHY2BgREUG3OYjZg1Kp1FgbMqEr6hw9evTSpUsFBQXkLbI5OTlmZmaxsbG0HxtE5ubNm3v37t2xY8eyZcuerI2Li1u6dOn69etHR0eNb9sMgfw4AmEMmCaPPCXu3LmTnJx8+PBhsmgwAMDPzy8+Pr61tXX37t3GtEc3S5cuLS4ufvXVV7lc7oQNUlJS6urqmLmjRz+QH0cgqEJol941RXlk6uTk5BAEERoa+mRVWlqah4fH2bNnKysrJ/ysjkmbVHt5hmSWxWJxQEDAyZMnGZh5oie0ZTxqZ0r544iZhrE5swaE4hh1S+8yVh6ZDNArf9zNzW3RokUahRKJpLGxkSCI77//3szM7Jlnnunv7ycIory8fMOGDepmuidNh/YyoZfMMpkXXnhh6dKlE1YlJSUBAGpra6n3RjD4u4DW4wgEJSaV3p0qtMsjU2RgYKCxsVEikWhr4Ovru3PnzqamJiiVQYbipE2ovTyjMstQRE/b3jGTA/lxBIISU5LenSq0yCNTpL29nSAIuHlYG2lpaQsXLszNzYUSdWqmOmlk7eUZlVmGw9EmmGpyID+OQFBiUundaWJ8eWSKqFQqAIC2d4YQHMfz8vIwDNu6datSqVSXT2fS1DLLaqmc+/fvG+q0VR6PB/43tFkA8uMIBCV0S+9OE1rkkSkCXd6ke2d8fX0TEhLkcnlqaqq6cDqTplZsJgeCa2pq9BjCkwwPD4P/DW0WgPw4AkEJ3dK7wNTkkaljZ2eHYRiVDPHU1FRPT8/a2lp1yaSTpoMZlVmGw4FSbrMA5McRCErolt4FzJZHng58Pt/Nza2lpWXSljC6Ym5uTi7RPWm6e9MmsxwdHW1vbz+dff9wON7e3nr3wCzoSZPRCco7ZBSMzbUyIBTHqFt6l4HyyE8C9Mo7lEqlbDZ7cHAQXpaUlMD0FRsbm3fffVej8Z49e8h5hzomTbf2MqFdZjksLAwAcPDgwQmtrampWb16tfrAQgcHBz8/v2+//ZbcJjg4eN68eVD3nzqM/S4w0SbkxxkFY59dA2L8McbGxlpbWxvzjhD9/LhcLmexWOfPn58Jk/RgbGzM39//3Llz+n28s7MTx/ETJ05M9YOM/S6guAoCQQ8mpLrn7u4uk8lkMll/fz/dtoCxsbHS0tK+vj543qwepKSkLFu2TCqVGtYwGkF+HIFATE5SUlJkZGR0dDTtkljV1dXFxcXl5eW6U9q1kZWVVVdXd/XqVTabbXDb6AL5cQTC2JioPHJ6erpUKj1y5Ai9ZgQGBn7++edq/Zkpcfny5aGhoerqarFYbHDDaIRFtwEIxFNHRkZGRkYG3VboQ1BQUFBQEN1W6M+GDRs2bNhAtxWGB63HEQgEwrRBfhyBQCBMG+THEQgEwrRBfhyBQCBMG4a+52xpaSkoKKDbCgQAAEBlotn953gaxqjGUFJTTyGMnTqMYN7JRpGRkSaUjIVAIJ4qGOgzmejHEQgEAkEdFB9HIBAI0wb5cQQCgTBtkB9HIBAI0wb5cQQCgTBt/g9RzKHxQZjQ2AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsNbS_Fnx8fk"
      },
      "source": [
        "### Visualizing Model's Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToRAMsj8ystn"
      },
      "source": [
        "To visualize predictions, it's a good idea to plot them against the ground truth labels. \n",
        "\n",
        "Often you'll see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus our model's predictions). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j07A0_pmFV9m",
        "outputId": "0d3a8dfa-a9c2-435c-e1b1-8a417e700e09"
      },
      "source": [
        "# Make some predictions\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.018944 ,  6.7575703,  9.205224 ,  9.05406  ,  5.308652 ,\n",
              "         4.626414 ,  6.5623927,  6.5572686,  6.5624437, 23.555267 ,\n",
              "         6.800959 ,  9.477144 ,  8.5488405,  7.153636 ,  4.2891984,\n",
              "         7.6400847,  4.3919516,  4.464624 ,  4.112087 ,  5.288908 ,\n",
              "        15.581341 ,  6.312966 ,  7.309915 ,  5.752566 ,  4.1096497,\n",
              "         9.23577  ,  5.2430296,  4.825238 ,  4.3158793,  7.280054 ,\n",
              "         4.3345203,  5.639849 ,  5.194246 ,  4.2399487, 14.697645 ,\n",
              "         7.0753274,  6.6604266,  5.5616107,  4.2506666,  8.07337  ,\n",
              "         4.4199386,  4.776226 ,  6.521178 ,  8.135127 ,  4.9993825,\n",
              "         4.2538857,  4.1091623,  4.241768 , 12.738414 ,  6.1540365]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxHD2vYSFn7p"
      },
      "source": [
        "def plot_predictions(train_data, train_labels, test_data, test_labels, predictions):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions to ground truth labels.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize = (10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c = 'b', label = 'Train data')\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c = 'g', label = 'Test data')\n",
        "  # Plot model's predictions\n",
        "  plt.scatter(test_data, predictions, c = 'r', label = 'Predictions')\n",
        "  # show the legend\n",
        "  plt.legend()\n",
        "  return plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "-kojgwQoG2-Z",
        "outputId": "9a743d55-0a7d-4449-ee6f-0b98f0931bd8"
      },
      "source": [
        "plot_predictions(x_train, y_train, x_test, y_test, y_pred);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLOZqq7CG7Vn"
      },
      "source": [
        "### Evaluating the Model with Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ipaQfBoHhfn"
      },
      "source": [
        "Depending on the problem we are working on, there will be different evaluation metrics to evaluate the model's performance.\n",
        "\n",
        "In the regression problems, three most frequently used metrics are:\n",
        "\n",
        "\n",
        "*   Mean Absolute Error (MAE)\n",
        "*   Mean Squared Error (MSE)\n",
        "*   Huber (combination of MAE and MSE; less sensitive to outliers)\n",
        "  *  Huber approaches MSE when $\\delta$ aproaches 0, while it approaches MAE when $\\delta\\$ approaches infinity \n",
        "\n",
        "\n",
        "The MAE is given by:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "MAE = \\frac{1}{N}\\sum_{i = 1}^{N}|y_{i} - \\hat{y_{i}}|\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "The MSE is given by:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "MSE = \\frac{1}{N}\\sum_{i = 1}^{N}(y_{i} - \\hat{y_{i}})^{2}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "The Huber is given by:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "    L_{\\delta}(y, f(x)) =\n",
        "    \\left\\{\n",
        "        \\begin{array}{cc}\n",
        "                \\frac{1}{2}(y - f(x))^2 & \\mathrm{if\\ } |y - f(X)| \\le \\delta \\\\\n",
        "                \\delta|y - f(x)|-\\frac{1}{2}\\delta^2 & \\mathrm{otherwise\\ } \\\\\n",
        "        \\end{array} \n",
        "    \\right.\n",
        "\\end{equation}\n",
        "$$\n",
        "<br>\n",
        "MAE in TF is represented by `tf.keras.losses.MAE()` or `tf.metrics.mean_absolute_error()`. MSE is represented by `tf.keras.losses.MSE()` or `tf.metrics.mean_squared_error()`. Huber is represented by `tf.keras.losses.huber()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6FlhlfmJEhP",
        "outputId": "f9092f81-8236-4c69-8ca6-4443aa4eb1fd"
      },
      "source": [
        "# Evaluate the model on the test set the quick way\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 4.9634 - mse: 4.6664 - mae: 1.6783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.963352203369141, 4.666411399841309, 1.6782803535461426]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8jP8jaFLbDs",
        "outputId": "1dac25b6-2323-467c-95c9-eabd8fb5cc0a"
      },
      "source": [
        "model_mae = tf.keras.losses.MAE(y_test, tf.squeeze(y_pred)) # you need to squeeze the predictions because of the dimensions problem\n",
        "model_mse = tf.keras.losses.MSE(y_test, tf.squeeze(y_pred))\n",
        "model_huber = tf.keras.losses.huber(y_test, tf.squeeze(y_pred), delta = 1.0)\n",
        "\n",
        "for i in [model_mae, model_mse, model_huber]:\n",
        "  print(i)\n",
        "  print(i.numpy())\n",
        "  print('--------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1.6782802, shape=(), dtype=float32)\n",
            "1.6782802\n",
            "--------\n",
            "tf.Tensor(4.6664114, shape=(), dtype=float32)\n",
            "4.6664114\n",
            "--------\n",
            "tf.Tensor(1.2569238, shape=(), dtype=float32)\n",
            "1.2569238\n",
            "--------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_90o9UZNOmV"
      },
      "source": [
        "### Experimenting with the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVJiibXRijHg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3SMpmT0inva"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}